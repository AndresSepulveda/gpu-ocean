{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting cluster\n",
    "\n",
    "## Prerequisites\n",
    "First, you need to install MPI, on windows use MS-MPI:\n",
    "https://msdn.microsoft.com/en-us/library/bb524831(v=vs.85).aspx\n",
    "\n",
    "\n",
    "## With a profile (not working)\n",
    "In theory, you should be able to create a profile using\n",
    "```\n",
    "ipython profile create --parallel --profile=myprofile\n",
    "```\n",
    "and then set\n",
    "```\n",
    "c.IPClusterEngines.engine_launcher_class = 'MPIEngineSetLauncher'\n",
    "```\n",
    "in ```<IPYTHON-DIR>/profile_myprofile/ipcluster_config.py```. This should then enable you to start a cluster using\n",
    "```\n",
    "ipcluster start --profile=myprofile\n",
    "```\n",
    "or alternatively through the Clusters tab in Jupyter\n",
    "\n",
    "\n",
    "## Without a profile (not working)\n",
    "An alternative is to run\n",
    "```\n",
    "ipcluster start --engines=MPI\n",
    "```\n",
    "\n",
    "\n",
    "## Manual start (working)\n",
    "This, however, does *not* work for me on Windows. What does work is the following:\n",
    "\n",
    "Start a controller using\n",
    "```\n",
    "ipcontroller --ip='*'\n",
    "```\n",
    "and then start several engines using mpiexec:\n",
    "```\n",
    "mpiexec -n 4 ipengine --mpi\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile: default\n",
      "Number of ids: 4\n",
      "IDs: [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import ipyparallel\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../')))\n",
    "\n",
    "from SWESimulators import IPythonMagic, Common\n",
    "\n",
    "# attach to a running cluster\n",
    "#cluster = ipyparallel.Client()#profile='mpi')\n",
    "\n",
    "# start cluster\n",
    "%setup_mpi mpi_context --num_engines 4\n",
    "cluster = mpi_context.cluster\n",
    "\n",
    "print('profile:', cluster.profile)\n",
    "print('Number of ids:', len(cluster.ids))\n",
    "print(\"IDs:\", cluster.ids) # Print process id numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] Hello! I'm rank 0 from 4 running in total...\n",
      "[stdout:1] Hello! I'm rank 1 from 4 running in total...\n",
      "[stdout:2] Hello! I'm rank 2 from 4 running in total...\n",
      "[stdout:3] Hello! I'm rank 3 from 4 running in total...\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "\n",
    "print(\"Hello! I'm rank %d from %d running in total...\" % (comm.rank, comm.size))\n",
    "\n",
    "comm.Barrier()   # wait for everybody to synchronize _here_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Starting\n",
      "0: sent data to 1: [37 28 42 62 87 22 45  4 19 13  8 39 10 99 52 81  2 41 64 58 50  0 32 95\n",
      " 98 49 84 31 75 93 43 73 70 54 21 82 83 29 68 35 26 23 59 74 86 47 88 12\n",
      " 72  5  7 85 76 34 94 24 90 38 80 57 89 51 46 56 20 30 16  3 71 27 61 96\n",
      " 66 65  9 92 33 77 63 36 25 91 18 11 67 14  6 55 15 17 60 40 44 78 69 79\n",
      " 53  1 48 97]\n",
      "[stdout:1] \n",
      "Starting\n",
      "1: received data from 0: [37 28 42 62 87 22 45  4 19 13  8 39 10 99 52 81  2 41 64 58 50  0 32 95\n",
      " 98 49 84 31 75 93 43 73 70 54 21 82 83 29 68 35 26 23 59 74 86 47 88 12\n",
      " 72  5  7 85 76 34 94 24 90 38 80 57 89 51 46 56 20 30 16  3 71 27 61 96\n",
      " 66 65  9 92 33 77 63 36 25 91 18 11 67 14  6 55 15 17 60 40 44 78 69 79\n",
      " 53  1 48 97]\n",
      "[stdout:2] \n",
      "Starting\n",
      "2: idle\n",
      "[stdout:3] \n",
      "Starting\n",
      "3: idle\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "from mpi4py import MPI\n",
    "import numpy\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "print(\"Starting\")\n",
    "# passing MPI datatypes explicitly\n",
    "if rank == 0:\n",
    "    data = numpy.arange(100, dtype='i')\n",
    "    numpy.random.shuffle(data)\n",
    "    comm.Send([data, MPI.INT], dest=1, tag=77)\n",
    "    print(\"{0}: sent data to 1: {1}\".format(rank, data))\n",
    "elif rank == 1:\n",
    "    data = numpy.empty(100, dtype='i')\n",
    "    comm.Recv([data, MPI.INT], source=0, tag=77)\n",
    "    print(\"{0}: received data from 0: {1}\".format(rank, data))\n",
    "else:\n",
    "    print(\"{0}: idle\".format(rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "#Lets have matplotlib \"inline\"\n",
    "%matplotlib inline\n",
    "\n",
    "#Import packages we need\n",
    "import numpy as np\n",
    "from matplotlib import animation, rc\n",
    "from matplotlib import pyplot as plt\n",
    "#import mpld3\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import datetime\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../')))\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "#Finally, import our simulator\n",
    "from SWESimulators import Common, CTCS, PlotHelper, IPythonMagic\n",
    "#Import initial condition and bathymetry generating functions:\n",
    "from SWESimulators.BathymetryAndICs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[stderr:0] \n",
      "Console logger using level INFO\n",
      "File logger using level DEBUG to mpitest.log\n",
      "Python version 3.7.2 (default, Mar 13 2019, 14:18:46) \n",
      "[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]\n",
      "Registering gpu_ctx in user workspace\n",
      "PyCUDA version 2018.1.1\n",
      "CUDA version (10, 1, 0)\n",
      "Driver version 10010\n",
      "Using 'Tesla P100-PCIE-12GB' GPU\n",
      "Created context handle <33843312>\n",
      "[stderr:1] \n",
      "Console logger using level INFO\n",
      "File logger using level DEBUG to mpitest.log\n",
      "Python version 3.7.2 (default, Mar 13 2019, 14:18:46) \n",
      "[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]\n",
      "Registering gpu_ctx in user workspace\n",
      "PyCUDA version 2018.1.1\n",
      "CUDA version (10, 1, 0)\n",
      "Driver version 10010\n",
      "Using 'Tesla P100-PCIE-12GB' GPU\n",
      "Created context handle <48828240>\n",
      "[stderr:2] \n",
      "Console logger using level INFO\n",
      "File logger using level DEBUG to mpitest.log\n",
      "Python version 3.7.2 (default, Mar 13 2019, 14:18:46) \n",
      "[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]\n",
      "Registering gpu_ctx in user workspace\n",
      "PyCUDA version 2018.1.1\n",
      "CUDA version (10, 1, 0)\n",
      "Driver version 10010\n",
      "Using 'Tesla P100-PCIE-12GB' GPU\n",
      "Created context handle <27594048>\n",
      "[stderr:3] \n",
      "Console logger using level INFO\n",
      "File logger using level DEBUG to mpitest.log\n",
      "Python version 3.7.2 (default, Mar 13 2019, 14:18:46) \n",
      "[GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]\n",
      "Registering gpu_ctx in user workspace\n",
      "PyCUDA version 2018.1.1\n",
      "CUDA version (10, 1, 0)\n",
      "Driver version 10010\n",
      "Using 'Tesla P100-PCIE-12GB' GPU\n",
      "Created context handle <38745280>\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "%setup_logging --out mpitest.log\n",
    "%cuda_context_handler gpu_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "def run_benchmark(simulator):\n",
    "    with Common.Timer(simulator.__class__.__name__ + \"_\" + str(sim_args[\"nx\"])) as timer:\n",
    "        t = sim.step(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "reload(Common)\n",
    "reload(CTCS)\n",
    "\n",
    "# Set initial conditions common to all simulators\n",
    "sim_args = {\n",
    "\"gpu_ctx\": gpu_ctx,\n",
    "\"nx\": 100, \"ny\": 200,\n",
    "\"dx\": 200.0, \"dy\": 200.0,\n",
    "\"dt\": 1,\n",
    "\"g\": 9.81,\n",
    "\"f\": 0.0,\n",
    "\"r\": 0.0,\n",
    "\"write_netcdf\": True,\n",
    "\"comm\": comm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "ghosts = [1,1,1,1] # north, east, south, west\n",
    "dataShape = (sim_args[\"ny\"] + ghosts[0]+ghosts[2], \n",
    "             sim_args[\"nx\"] + ghosts[1]+ghosts[3])\n",
    "\n",
    "h0 = np.ones(dataShape, dtype=np.float32) * 60.0;\n",
    "eta0 = np.zeros(dataShape, dtype=np.float32);\n",
    "u0 = np.zeros((dataShape[0], dataShape[1]+1), dtype=np.float32);\n",
    "v0 = np.zeros((dataShape[0]+1, dataShape[1]), dtype=np.float32);       \n",
    "\n",
    "#Create bump in to lower left of domain for testing\n",
    "addCentralBump(eta0, sim_args[\"nx\"], sim_args[\"ny\"], sim_args[\"dx\"], sim_args[\"dy\"], ghosts)\n",
    "\n",
    "#Initialize simulator\n",
    "ctcs_args = {\"H\": h0, \"eta0\": eta0, \"hu0\": u0, \"hv0\": v0, \"A\": 1.0}\n",
    "sim = CTCS.CTCS(**ctcs_args, **sim_args)\n",
    "\n",
    "#Run a simulation and plot it\n",
    "run_benchmark(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] Closing file netcdf_2019_11_07/CTCS_2019_11_07-09_02_05_0.nc ...\n",
      "[stdout:1] Closing file netcdf_2019_11_07/CTCS_2019_11_07-09_02_05_1.nc ...\n",
      "[stdout:2] Closing file netcdf_2019_11_07/CTCS_2019_11_07-09_02_05_2.nc ...\n",
      "[stdout:3] Closing file netcdf_2019_11_07/CTCS_2019_11_07-09_02_05_3.nc ...\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "\n",
    "sim.cleanUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
