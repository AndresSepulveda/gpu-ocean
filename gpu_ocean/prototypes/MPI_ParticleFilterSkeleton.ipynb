{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "This notebook sets up and runs a set of benchmarks to compare\n",
    "different numerical discretizations of the SWEs\n",
    "\n",
    "Copyright (C) 2016  SINTEF ICT\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPI Skeleton for basic particle filter with SIR\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import animation, rc\n",
    "from scipy.special import lambertw\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../')))\n",
    "\n",
    "#Set large figure sizes\n",
    "rc('figure', figsize=(16.0, 12.0))\n",
    "rc('animation', html='html5')\n",
    "matplotlib.rcParams['contour.negative_linestyle'] = 'solid'\n",
    "\n",
    "#Import our simulator\n",
    "from SWESimulators import CDKLM16, PlotHelper, Common, IPythonMagic\n",
    "\n",
    "from SWESimulators import BathymetryAndICs as BC\n",
    "from SWESimulators import OceanStateNoise\n",
    "from SWESimulators import OceanNoiseEnsemble\n",
    "from SWESimulators import BaseOceanStateEnsemble\n",
    "from SWESimulators import GPUDrifterCollection\n",
    "from SWESimulators import DataAssimilationUtils as dautils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cuda_context_handler gpu_ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "\n",
    "Some basic assumptions and notes on what has to be redesigned in the future:\n",
    "\n",
    "\n",
    "### Local vs global ensemble\n",
    "The local ensemble is the ensemble owned by one process. The global ensemble is the combined ensemble from all processes. Only the \"master\" (rank 0) will care about the global ensemble in this skeleton.\n",
    "\n",
    "### Code sections requiring MPI is clearly marked\n",
    "Clearly marked with \n",
    "```\n",
    "# MPI START -----------------------------\n",
    "if self.rank == 0:\n",
    "    ...\n",
    "# MPI END -----------------------------\n",
    "\n",
    "```\n",
    "The keyword `pass` is used where there currently would be an empty block (or just a comment), so that it is valid python code.\n",
    "\n",
    "### Initial states\n",
    "\n",
    "The ensemble is initialized based on one simulator instance, and the ocean state in this simulator instance is completely random. The initialization method therefore requires some exchange of data so that all MPI proccesses has the same initial data to create a \"local\" ensemble from. \n",
    "\n",
    "My suggestion is that rank 0 will share its initialization input (eta, hu, hv) with the other proccesses before entering the loop that creates the ensemble members. \n",
    "\n",
    "**In the future** we will start the ensemble based on predefined set of initial states (e.g. large ensemble created from a small ensemble of ROMS models), and therefore the initialization will need to be different in the future.\n",
    "\n",
    "\n",
    "### Initialization of the ensemble\n",
    "This has been a mess in the class OceanStateEnsemble class. In the below skeleton I've tried to clean up this, so that the standard constructor is the only required function.\n",
    "\n",
    "I've removed the option to choose between different observation operators, etc. This can be re-introduced later.\n",
    "\n",
    "### Short cuts where there should have been some more options\n",
    "We assume \n",
    "* Direct observation of underlying flow at drifter positions only\n",
    "* CDKLM simulator only\n",
    "* periodic boundary conditions only\n",
    "* Total num particles **MUST** be a multiple of number of MPI processes (in the below version)\n",
    "\n",
    "\n",
    "### Syntethic truth\n",
    "The truth should only be a model realization in the master process. Currently all processes has a truth model, so that as much of the old code can be reused. For all processes with rank > 0, the simulator in self.particles[self.obs_index] should never be used.\n",
    "\n",
    "\n",
    "### Too much communication\n",
    "Because I want to be able to copy-paste as much code as possible, this version will most likely contain too much communication (or communication of information that has already been communicated before). This can be fixed in the future, since the most important thing in short term is correctness.\n",
    "\n",
    "### Synchronous sends only\n",
    "All communication showed below assumes synchronous sends. Nothing else happens before a send/receive is complete.\n",
    "\n",
    "\n",
    "### No resampling of drifter positions \n",
    "The only drifters that are used for anything are the drifters in the syntethic truth. We keep the drifters in all the particles also (in fear of breaking something), but we ignore them. There are therefore no reason to why we should resample drifter positions, and therefore we don't.  \n",
    "\n",
    "# How to follow the code?\n",
    "\n",
    "There are very few functions of MPIOceanEnsemble that are used from the outside.\n",
    "\n",
    "**First of all**, it is **the constructor** of course. It uses no other functions\n",
    "\n",
    "**Step** is used to run the ensemble forward in time.\n",
    "\n",
    "**And then**, the functions **getGaussianWeights** and **resample** is called **via the function DataAssimilationUtilities.residualSampling** function.\n",
    "\n",
    "That's it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MPIOceanEnsemble():\n",
    "    \n",
    "    \"\"\"\n",
    "    Initilization of ensemble - lots of boiler plate code to read parameters etc...\n",
    "    \"\"\"\n",
    "    def __init__(self, gpu_ctx, numParticles, sim, \\\n",
    "                 driftersPerOceanModel=1, \\\n",
    "                 observation_variance = None, \\\n",
    "                 small_scale_perturbation_amplitude = 0.0, \\\n",
    "                 initialization_variance_factor_ocean_field = 0.0):\n",
    "    \n",
    "        self.gpu_ctx = gpu_ctx\n",
    "        self.numParticles = numParticles\n",
    "        self.driftersPerOceanModel = driftersPerOceanModel\n",
    "                \n",
    "        # MPI START -----------------------------\n",
    "        # Obtain my rank and number of other processes\n",
    "        self.rank = 0\n",
    "        self.num_procs = 1\n",
    "        \n",
    "        self.local_numParticles = self.numParticles/self.num_procs \n",
    "        # What if num_procs is not a factor of numParticles? \n",
    "        \n",
    "        # MPI END -----------------------------\n",
    "        \n",
    "        self.particles = [None]*(self.numParticles + 1)\n",
    "        self.obs_index = self.numParticles\n",
    "        \n",
    "        self.simType = 'CDKLM16'\n",
    "        \n",
    "        self.t = 0.0\n",
    "    \n",
    "        self.observation_type = dautils.ObservationType.DirectUnderlyingFlow\n",
    "        self.prev_observation = None\n",
    "        \n",
    "        \n",
    "        #-------------------------------------------------        \n",
    "        ### ----- Stochastic parameters\n",
    "        #-------------------------------------------------\n",
    "        \n",
    "        self.observation_variance = observation_variance\n",
    "        if self.observation_variance is None:\n",
    "            # Just setting something related to drifter velocity\n",
    "            self.observation_variance = 0.01**2\n",
    "        \n",
    "        # Build observation covariance matrix:\n",
    "        self.observation_cov = None\n",
    "        self.observation_cov_inverse = None\n",
    "        if np.isscalar(self.observation_variance):\n",
    "            self.observation_cov = np.eye(2)*self.observation_variance\n",
    "            self.observation_cov_inverse = np.eye(2)*(1.0/self.observation_variance)\n",
    "        else:\n",
    "            # Assume that we have a correctly shaped matrix here\n",
    "            self.observation_cov = self.observation_variance\n",
    "            self.observation_cov_inverse = np.linalg.inv(self.observation_cov)\n",
    "         \n",
    "        self.small_scale_perturbation_amplitude = small_scale_perturbation_amplitude\n",
    "    \n",
    "        # When initializing an ensemble, each member should be perturbed so that they \n",
    "        # have slightly different starting point.\n",
    "        # This factor should be multiplied to the small_scale_perturbation_amplitude for that \n",
    "        # perturbation\n",
    "        self.initialization_variance_factor_ocean_field = initialization_variance_factor_ocean_field\n",
    "        \n",
    "        \n",
    "        \n",
    "        #-------------------------------------------------        \n",
    "        ### ---- -Read parameters from sim into self.*\n",
    "        #-------------------------------------------------\n",
    "        \n",
    "        self.nx = sim.nx\n",
    "        self.ny = sim.ny\n",
    "        self.dx = sim.dx\n",
    "        self.dy = sim.dy\n",
    "        self.dt = sim.dt\n",
    "        self.g = sim.g\n",
    "        self.f = sim.f\n",
    "        self.beta = sim.coriolis_beta\n",
    "        self.r = sim.r\n",
    "        self.wind = sim.wind_stress\n",
    "        self.boundaryConditions = sim.boundary_conditions\n",
    "        self.ghostCells = np.array([2,2,2,2])\n",
    "        \n",
    "        self.dataShape =  ( self.ny + self.ghostCells[0] + self.ghostCells[2], \n",
    "                            self.nx + self.ghostCells[1] + self.ghostCells[3]  )\n",
    "        \n",
    "        self.base_eta, self.base_hu, self.base_hv = sim.download(interior_domain_only=False)\n",
    "        self.base_H = sim.downloadBathymetry()[0]\n",
    "        \n",
    "        # MPI START -----------------------------\n",
    "        # sim's ocean state is random, and we must make rank 0 send its valid state to\n",
    "        # all the other processes.\n",
    "        if self.rank == 0:\n",
    "            for p in range(1, self.num_procs):\n",
    "                #mpisend self.base_eta of size self.dataShape to rank p\n",
    "                #mpisend self.base_hu  of size self.dataShape to rank p\n",
    "                #mpisend self.base_hv  of size self.dataShape to rank p\n",
    "                pass\n",
    "        else:\n",
    "            #mpirecieve self.base_eta of size self.dataShape from rank 0\n",
    "            #mpirecieve self.base_hu  of size self.dataShape from rank 0\n",
    "            #mpirecieve self.base_hv  of size self.dataShape from rank 0\n",
    "            pass\n",
    "        # MPI END -----------------------------\n",
    "        \n",
    "        \n",
    "        \n",
    "        #-------------------------------------------------\n",
    "        ### ---- Create the local ensemble\n",
    "        #-------------------------------------------------\n",
    "        \n",
    "        # MPI START -----------------------------\n",
    "        # Mapping of particle indices from local ensemble to global ensemble\n",
    "        self.global_particle_indices = np.array(range(self.rank, \\\n",
    "                                                      self.rank + self.local_numParticles))\n",
    "        # MPI END -----------------------------\n",
    "        \n",
    "        # Define mid-points for the different drifters \n",
    "        # Decompose the domain, so that we spread the drifters as much as possible\n",
    "        sub_domains_y = np.int(np.round(np.sqrt(self.driftersPerOceanModel)))\n",
    "        sub_domains_x = np.int(np.ceil(1.0*self.driftersPerOceanModel/sub_domains_y))\n",
    "        self.midPoints = np.empty((driftersPerOceanModel, 2))\n",
    "        for sub_y in range(sub_domains_y):\n",
    "            for sub_x in range(sub_domains_x):\n",
    "                drifter_id = sub_y*sub_domains_x + sub_x\n",
    "                if drifter_id >= self.driftersPerOceanModel:\n",
    "                    break\n",
    "                self.midPoints[drifter_id, 0]  = (sub_x + 0.5)*self.nx*self.dx/sub_domains_x\n",
    "                self.midPoints[drifter_id, 1]  = (sub_y + 0.5)*self.ny*self.dy/sub_domains_y\n",
    "              \n",
    "        \n",
    "        for i in range(self.local_numParticles+1):\n",
    "            self.particles[i] = CDKLM16.CDKLM16(self.gpu_ctx, \\\n",
    "                                                self.base_eta, self.base_hu, self.base_hv, \\\n",
    "                                                self.base_H, \\\n",
    "                                                self.nx, self.ny, self.dx, self.dy, self.dt, \\\n",
    "                                                self.g, self.f, self.r, \\\n",
    "                                                boundary_conditions=self.boundaryConditions, \\\n",
    "                                                write_netcdf=False, \\\n",
    "                                                small_scale_perturbation=True, \\\n",
    "                                                small_scale_perturbation_amplitude=self.small_scale_perturbation_amplitude)\n",
    "            \n",
    "            if self.initialization_variance_factor_ocean_field != 0.0:\n",
    "                self.particles[i].perturbState(q0_scale=self.initialization_variance_factor_ocean_field)\n",
    "            \n",
    "            drifters = GPUDrifterCollection.GPUDrifterCollection(self.gpu_ctx, driftersPerOceanModel,\n",
    "                                                                 observation_variance=self.observation_variance,\n",
    "                                                                 boundaryConditions=self.boundaryConditions,\n",
    "                                                                 domain_size_x=self.nx*self.dx, domain_size_y=self.ny*self.dy)\n",
    "            \n",
    "            drifters.setDrifterPositions(self.midPoints)\n",
    "            self.particles[i].attachDrifters(drifters)\n",
    "   \n",
    "    def cleanUp(self):\n",
    "        for oceanState in self.particles:\n",
    "            if oceanState is not None:\n",
    "                oceanState.cleanUp()\n",
    "    \n",
    "    def step(self, sub_t):\n",
    "        \"\"\"\n",
    "        Function which makes all particles step until time t.\n",
    "        apply_stochastic_term: Boolean value for whether the stochastic\n",
    "            perturbation (if any) should be applied.\n",
    "        \"\"\"\n",
    "        for p in self.particles:\n",
    "            self.t = p.step(sub_t)\n",
    "        return self.t\n",
    "    \n",
    "    \n",
    "    def observeTrueState(self):\n",
    "        \"\"\"\n",
    "        Applying the observation operator on the syntetic true state.\n",
    "\n",
    "        Returns a numpy array with D drifter positions and drifter velocities\n",
    "        [[x_1, y_1, u_1, v_1], ... , [x_D, y_D, u_D, v_D]]\n",
    "        \n",
    "        Only rank 0 obtains the true state and spreads them to the other ranks\n",
    "        \n",
    "        MPI: All processes MUST call this function similtaneously \n",
    "        \"\"\"\n",
    "\n",
    "        # MPI START -----------------------------\n",
    "        if self.rank == 0:\n",
    "            trueDrifterPositions = self.particles[self.obs_index].drifters.getDrifterPositions()\n",
    "            \n",
    "            trueState = np.empty((self.driftersPerOceanModel, 4))\n",
    "            \n",
    "            for d in range(self.driftersPerOceanModel):\n",
    "                x = trueDrifterPositions[d,0]\n",
    "                y = trueDrifterPositions[d,1]\n",
    "                id_x = np.int(np.floor(x/self.dx))\n",
    "                id_y = np.int(np.floor(y/self.dy))\n",
    "\n",
    "                # Skipping interpolation\n",
    "                depth = self.particles[self.obs_index].downloadBathymetry()[1][id_y, id_x]\n",
    "\n",
    "                # Downloading ocean state without ghost cells\n",
    "                eta, hu, hv = self.particles[self.obs_index].download(interior_domain_only=True)\n",
    "                u = hu[id_y, id_x]/(depth + eta[id_y, id_x])\n",
    "                v = hv[id_y, id_x]/(depth + eta[id_y, id_x])\n",
    "\n",
    "                trueState[d,:] = np.array([x, y, u, v])\n",
    "                \n",
    "            # Share true state with other processes:\n",
    "            # mpisend trueState, size (driftersPerOceanModel, 4) to rank p \n",
    "        \n",
    "        else:\n",
    "            # trueState = mpirecieve trueState, size (driftersPerOceanModel, 4) from rank 0\n",
    "            pass\n",
    "        \n",
    "        return trueState    \n",
    "        \n",
    "        \n",
    "        \n",
    "    def observeParticles(self):\n",
    "        \"\"\"\n",
    "        Applying the observation operator on each particle.\n",
    "\n",
    "        Structure on the output:\n",
    "        [\n",
    "        particle 1:  [u_1, v_1], ... , [u_D, v_D],\n",
    "        particle 2:  [u_1, v_1], ... , [u_D, v_D],\n",
    "        particle Ne: [u_1, v_1], ... , [u_D, v_D]\n",
    "        ]\n",
    "        numpy array with dimensions (particles, drifters, 2)\n",
    "        \n",
    "        MPI: All processes MUST call this function similtaneously\n",
    "        \"\"\"\n",
    "        local_observedState = np.empty((self.local_numParticles, \\\n",
    "                                        self.driftersPerOceanModel, 2))\n",
    "\n",
    "        trueState = self.observeTrueState()\n",
    "        # trueState structure: [[x1, y1, u1, v1], ..., [xD, yD, uD, vD]]\n",
    "\n",
    "        for p in range(self.local_numParticles):\n",
    "            # Downloading ocean state without ghost cells\n",
    "            Hi = self.particles[p].downloadBathymetry()[1]\n",
    "            eta, hu, hv = self.particles[p].download(interior_domain_only=True)\n",
    "\n",
    "            for d in range(self.driftersPerOceanModel):\n",
    "                id_x = np.int(np.floor(trueState[d,0]/self.dx))\n",
    "                id_y = np.int(np.floor(trueState[d,1]/self.dy))\n",
    "\n",
    "                depth = Hi[id_y, id_x]\n",
    "                local_observedState[p,d,0] = hu[id_y, id_x]/(depth + eta[id_y, id_x])\n",
    "                local_observedState[p,d,1] = hv[id_y, id_x]/(depth + eta[id_y, id_x])\n",
    "        \n",
    "        \n",
    "        # MPI START -----------------------------\n",
    "        # Gather all observed states on rank 0\n",
    "        \n",
    "        if self.rank == 0:\n",
    "            observedState = np.empty((self.numParticles, \\\n",
    "                                      self.driftersPerOceanModel, 2))\n",
    "\n",
    "            observedState[0:self.local_numParticles, :, :] = local_observedState\n",
    "            for p in range(1, self.num_procs):\n",
    "                # remote_observedState = mpireceive local_observedState, size (see above) from rank p \n",
    "                observedState[p*self.local_numParticles:(p+1)*self.local_numParticles, :, :] = remote_observedState\n",
    "            \n",
    "            return observedState\n",
    "            \n",
    "        else:\n",
    "            # mpisend local_observedState, size (see above) to rank 0\n",
    "            \n",
    "            return local_drifterPositions\n",
    "        \n",
    "        ## CHALLENGE!!! All processes needs to enter functions that are structured as this one.\n",
    "        #  But what should all other processes than rank 0 return???\n",
    "        #  Does it matter what they return?\n",
    "        \n",
    "        # MPI END -----------------------------\n",
    "        \n",
    "    def getInnovations(self, obs=None):\n",
    "        \"\"\"\n",
    "        Obtaining the innovation vectors, y^m - H(\\psi_i^m)\n",
    "\n",
    "        Returns a numpy array with dimensions (particles, drifters, 2)\n",
    "\n",
    "        MPI: All processors must enter this function (even though we only care about the output from rank 0)!!!\n",
    "        \"\"\"\n",
    "        if obs is None:\n",
    "            trueState = self.observeTrueState()[:, 2:]\n",
    "            # Only select the velocities, not the positions.\n",
    "            \n",
    "        innovations = trueState - self.observeParticles()\n",
    "        return innovations\n",
    "    \n",
    "    def getInnovationNorms(self, obs=None):\n",
    "        \n",
    "        # Innovations have the structure \n",
    "        # [ particle: [drifter: [x, y] ] ], or\n",
    "        # [ particle: [drifter: [u, v] ] ]\n",
    "        # We simply gather find the norm for each particle:\n",
    "        innovations = self.getInnovations(obs=obs)\n",
    "        return np.linalg.norm(np.linalg.norm(innovations, axis=2), axis=1)\n",
    "    \n",
    "    \n",
    "    def getGaussianWeight(self, innovations=None, normalize=True):\n",
    "        \"\"\"\n",
    "        Calculates a weight associated to every particle, based on its innovation vector, using \n",
    "        Gaussian uncertainty for the observation.\n",
    "        \n",
    "        MPI: All processors must enter this function (even though we only care about the output from rank 0)!!!\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        if innovations is None:\n",
    "            innovations = self.getInnovations()\n",
    "            \n",
    "            # MPI: Now, rank 0 will have all innovations, and rank > 0 will have their local innovations\n",
    "            \n",
    "        # MPI START -----------------------------\n",
    "        \n",
    "        ## Suggestion: We only care about rank 0, and return some non-invalid (but bogus) weights for rank > 0 \n",
    "        \n",
    "        if self.rank == 0:\n",
    "            observationVariance = self.getObservationVariance()\n",
    "            Rinv = None\n",
    "\n",
    "            weights = np.zeros(innovations.shape[0])\n",
    "            if len(innovations.shape) == 1:\n",
    "                weights = (1.0/np.sqrt(2*np.pi*observationVariance))* \\\n",
    "                        np.exp(- (innovations**2/(2*observationVariance)))\n",
    "\n",
    "            else:\n",
    "                Ne = self.getNumParticles()\n",
    "                Nd = innovations.shape[1] # number of drifters per particle\n",
    "                Ny = innovations.shape[2]\n",
    "\n",
    "                Rinv = self.observation_cov_inverse\n",
    "                R = self.observation_cov\n",
    "\n",
    "                for i in range(Ne):\n",
    "                    w = 0.0\n",
    "                    for d in range(Nd):\n",
    "                        inn = innovations[i,d,:]\n",
    "                        w += np.dot(inn, np.dot(Rinv, inn.transpose()))\n",
    "\n",
    "                    ## TODO: Restructure to do the normalization before applying\n",
    "                    # the exponential function. The current version is sensitive to overflows.\n",
    "                    weights[i] = (1.0/((2*np.pi)**Nd*np.linalg.det(R)**(Nd/2.0)))*np.exp(-0.5*w)\n",
    "            if normalize:\n",
    "                return weights/np.sum(weights)\n",
    "            return weights\n",
    "        \n",
    "        else: # if rank > 0\n",
    "            return np.ones(innovations.shape[0])/(1.0*self.local_numParticles)\n",
    "        \n",
    "        # MPI END  -----------------------------\n",
    "\n",
    "        \n",
    "    def resample(self, newSampleIndices, reinitialization_variance):\n",
    "        \"\"\"\n",
    "        Resampling the particles given by the newSampleIndicies input array.\n",
    "        Here, the reinitialization_variance input is ignored, meaning that exact\n",
    "        copies only are resampled.\n",
    "        \n",
    "        \n",
    "        \n",
    "        MPI: MUST be called by all processes.\n",
    "        newSampleIndices is a valid input for rank 0 only. For rank > 0 it is only bogus.\n",
    "        \n",
    "        MPI: It is very important that we don't overwrite particles that still needs to be copied.\n",
    "        Here is a highly stupid, brute force resampling scheme, but it should be safe as long as we\n",
    "        don't run out of memory on a single node...\n",
    "        \"\"\"\n",
    "        newOceanStates = [None]*self.getNumParticles()\n",
    "                \n",
    "        # MPI START -----------------------------\n",
    "        \n",
    "        # Create an array containing the process id in charge of each global particle\n",
    "        particle_owner = [None]*self.getNumParticles()\n",
    "        for p in range(self.getNumParticles()):\n",
    "            particle_owner[p] = p//self.local_numParticles  # integer division\n",
    "\n",
    "            \n",
    "        # Share the global ID's to all processes\n",
    "        if self.rank == 0:\n",
    "            for p in range(self.num_procs):\n",
    "                # mpisend newSampleIndices size (numParticles) to rank p \n",
    "                pass\n",
    "        else:\n",
    "            #mpirecv newSampleIndices size (numParticles) from rank 0\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Resample the all particles onto rank 0\n",
    "        for i in range(self.getNumParticles()):\n",
    "            index = newSampleIndices[i]\n",
    "            owner = particle_owner[index]\n",
    "            \n",
    "            # Send state index to rank 0 from rank owner:\n",
    "            if self.rank == 0:\n",
    "                if owner == 0:\n",
    "                    eta0, hu0, hv0 = self.particles[index].download()\n",
    "                    eta1, hu1, hv1 = self.particles[index].downloadPrevTimestep()\n",
    "                    newOceanStates[i] = (eta0, hu0, hv0, eta1, hu1, hv1)\n",
    "                else:\n",
    "                    #mpi_recv eta0, hu0, hv0, eta1, hu1, hv1 from rank owner\n",
    "                    # all these arrays should have size self.dataShape (interior + ghost cells)\n",
    "                    newOceanStates[i] = (eta0, hu0, hv0, eta1, hu1, hv1)\n",
    "                    pass\n",
    "                \n",
    "            \n",
    "            elif self.rank == owner:\n",
    "                # Download index's ocean state:\n",
    "                eta0, hu0, hv0 = self.particles[index].download()\n",
    "                eta1, hu1, hv1 = self.particles[index].downloadPrevTimestep()\n",
    "                \n",
    "                #mpi_send eta0, hu0, hv0, eta1, hu1, hv1 to rank 0\n",
    "                # all these arrays should have size self.dataShape (interior + ghost cells)\n",
    "\n",
    "                \n",
    "                \n",
    "        # New loop for transferring the correct ocean states back up to its owner, and to the GPU\n",
    "        for i in range(self.getNumParticles()):\n",
    "            owner = particle_owner[i]\n",
    "            \n",
    "            if self.rank == 0:\n",
    "                if owner == 0:\n",
    "                    self.particles[i].upload(newOceanStates[i][0],\n",
    "                                             newOceanStates[i][1],\n",
    "                                             newOceanStates[i][2],\n",
    "                                             newOceanStates[i][3],\n",
    "                                             newOceanStates[i][4],\n",
    "                                             newOceanStates[i][5])\n",
    "                else:\n",
    "                    # mpi_send newOceanStates[i][0:5] to rank owner. \n",
    "                    # Each array size self.dataShape\n",
    "                    pass\n",
    "            elif self.rank == owner:\n",
    "                    # mpi_recv eta0, hu0, hv0, eta1, hu1, hv1 from rank 0.\n",
    "                    # Each array size self.dataShape\n",
    "                    local_index = i - self.rank*self.local_numParticles\n",
    "                    self.particles[local_index].upload(eta0, hu0, hv0,\n",
    "                                                       eta1, hu1, hv1)\n",
    "  \n",
    "\n",
    "        # MPI END -----------------------------\n",
    "\n",
    "                    \n",
    "    def getDomainSizeX(self):\n",
    "        return self.nx*self.dx\n",
    "    def getDomainSizeY(self):\n",
    "        return self.ny*self.dy\n",
    "    def getObservationVariance(self):\n",
    "        return self.observation_variance\n",
    "    def getNumParticles(self):\n",
    "        return self.numParticles\n",
    "    \n",
    "    \n",
    "    def plotDistanceInfo(self, title=None):\n",
    "        \"\"\"\n",
    "        MPI: Only rank 0 creates a figure. The others processors just help out with producing \n",
    "        required information\n",
    "        \"\"\"\n",
    "        \n",
    "        # All processes helps out with gathering info\n",
    "        innovations = self.getInnovationNorms()\n",
    "        obs_var = self.getObservationVariance()\n",
    "        range_x = np.sqrt(obs_var)*20\n",
    "        x = np.linspace(0, range_x, num=100)\n",
    "        gauss_pdf = self.getGaussianWeight(x, normalize=False)\n",
    "        gaussWeights = self.getGaussianWeight()\n",
    "        \n",
    "        # Only rank 0 creates a figure:\n",
    "        fig = None\n",
    "        if self.rank==0:\n",
    "            plotRows = 2\n",
    "            fig = plt.figure(figsize=(10, 6))\n",
    "            gridspec.GridSpec(plotRows, 3)\n",
    "\n",
    "\n",
    "            # PLOT DISCTRIBUTION OF PARTICLE DISTANCES AND THEORETIC OBSERVATION PDF\n",
    "            ax0 = plt.subplot2grid((plotRows,3), (0,0), colspan=3)\n",
    "            range_x = np.sqrt(obs_var)*20\n",
    "\n",
    "            # With observation \n",
    "            x = np.linspace(0, range_x, num=100)\n",
    "            plt.plot(x, gauss_pdf, 'g', label=\"pdf directly from innovations\")\n",
    "            plt.legend()\n",
    "            plt.title(\"Distribution of particle innovations\")\n",
    "\n",
    "            #hisograms:\n",
    "            ax1 = ax0.twinx()\n",
    "            ax1.hist(innovations, bins=30, \\\n",
    "                     range=(0, range_x),\\\n",
    "                     normed=True, label=\"particle innovations (norm)\")\n",
    "\n",
    "            # PLOT SORTED DISTANCES FROM OBSERVATION\n",
    "            ax0 = plt.subplot2grid((plotRows,3), (1,0), colspan=3)\n",
    "            indices_sorted_by_observation = innovations.argsort()\n",
    "            ax0.plot(gaussWeights[indices_sorted_by_observation]/np.max(gaussWeights),\\\n",
    "                     'g', label=\"Weight directly from innovations\")\n",
    "            ax0.set_ylabel('Weights directly from innovations', color='g')\n",
    "            ax0.grid()\n",
    "            ax0.set_ylim(0,1.4)\n",
    "            #plt.legend(loc=7)\n",
    "            ax0.set_xlabel('Particle ID')\n",
    "\n",
    "            ax1 = ax0.twinx()\n",
    "            ax1.plot(innovations[indices_sorted_by_observation], label=\"innovations\")\n",
    "            ax1.set_ylabel('Innovations', color='b')\n",
    "\n",
    "            plt.title(\"Sorted distances from observation\")\n",
    "\n",
    "            if title is not None:\n",
    "                plt.suptitle(title, fontsize=16)\n",
    "            #plt.tight_layout()\n",
    "            \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create the ensemble:\n",
    "\n",
    "1. Set parameters\n",
    "2. Create the simulator from which all ensemble members should be based on\n",
    "3. Create the ensemble \n",
    "4. Define observation times and run simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "# 1) Set parameters\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "nx = 40\n",
    "ny = 40\n",
    "\n",
    "dx = 4.0\n",
    "dy = 4.0\n",
    "\n",
    "dt = 0.05\n",
    "g = 9.81\n",
    "r = 0.0\n",
    "\n",
    "f = 0.05\n",
    "beta = 0.0\n",
    "\n",
    "ensemble_size = 40\n",
    "drifters = 3\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# 2) Create the simulator from which all ensemble members should be based on\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "ghosts = np.array([2,2,2,2]) # north, east, south, west\n",
    "validDomain = np.array([2,2,2,2])\n",
    "boundaryConditions = Common.BoundaryConditions(2,2,2,2)\n",
    "\n",
    "# Define which cell index which has lower left corner as position (0,0)\n",
    "x_zero_ref = 2\n",
    "y_zero_ref = 2\n",
    "\n",
    "dataShape = (ny + ghosts[0]+ghosts[2], \n",
    "             nx + ghosts[1]+ghosts[3])\n",
    "dataShapeHi = (ny + ghosts[0]+ghosts[2]+1, \n",
    "             nx + ghosts[1]+ghosts[3]+1)\n",
    "\n",
    "eta0 = np.zeros(dataShape, dtype=np.float32, order='C');\n",
    "hv0 = np.zeros(dataShape, dtype=np.float32, order='C');\n",
    "hu0 = np.zeros(dataShape, dtype=np.float32, order='C');\n",
    "waterDepth = 10.0\n",
    "Hi = np.ones(dataShapeHi, dtype=np.float32, order='C')*waterDepth\n",
    "\n",
    "\n",
    "if 'sim' in globals():\n",
    "    sim.cleanUp()\n",
    "if 'ensemble' in globals():\n",
    "    ensemble.cleanUp()\n",
    "\n",
    "# Choose a suitable amplitude for the model error.\n",
    "# This expression does not make sense (dimensionwise), but it gives a number\n",
    "# that fits well with all the other numbers (:\n",
    "q0 = 0.5*dt*f/(g*waterDepth)\n",
    "\n",
    "sim = CDKLM16.CDKLM16(gpu_ctx, eta0, hu0, hv0, Hi, \\\n",
    "                      nx, ny, dx, dy, dt, g, f, r, \\\n",
    "                      boundary_conditions=boundaryConditions, \\\n",
    "                      write_netcdf=False, \\\n",
    "                      small_scale_perturbation=True, \\\n",
    "                      small_scale_perturbation_amplitude=q0)\n",
    "\n",
    "# Create a random initial state \n",
    "sim.perturbState(q0_scale=100)\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# 3) Create the ensemble\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "ensemble = MPIOceanEnsemble(gpu_ctx, ensemble_size, sim, \\\n",
    "                            driftersPerOceanModel=drifters, \\\n",
    "                            observation_variance = 0.02**2, \\\n",
    "                            small_scale_perturbation_amplitude=q0, \\\n",
    "                            initialization_variance_factor_ocean_field=50)\n",
    "\n",
    "#print \"ensemble.observeTrueState()\", ensemble.observeTrueState()\n",
    "#print \"ensemble.observeParticles()\", ensemble.observeParticles()\n",
    "#print \"ensemble.getInnovations()\", ensemble.getInnovations()\n",
    "#print \"ensemble.getGaussianWeight()\", ensemble.getGaussianWeight()\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# 4) Define observation times and run simulation\n",
    "#    Here, we store a plot before and after each observation time step\n",
    "#    in order to inspect the results.\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "T = 50\n",
    "sub_t = 10*dt\n",
    "resampling_points = range(5, 100, 10)\n",
    "print \"Will resample at iterations: \", resampling_points\n",
    "infoPlots = []\n",
    "\n",
    "# Run particle filter:\n",
    "for it in range(T):\n",
    "    t = ensemble.step(sub_t)\n",
    "    \n",
    "    # Check if we are at an observation\n",
    "    for rp in resampling_points:\n",
    "        if it == rp:\n",
    "            print \"resampling at iteration \" + str(it)\n",
    "            infoFig = ensemble.plotDistanceInfo(title=\"it = \" + str(it) + \" before resampling\")\n",
    "            if ensemble.rank == 0:\n",
    "                plt.close(infoFig)\n",
    "                infoPlots.append(infoFig)\n",
    "            \n",
    "            dautils.residualSampling(ensemble)\n",
    "            \n",
    "            infoFig = ensemble.plotDistanceInfo(title=\"it = \" + str(it) + \" post resampling\")\n",
    "            if ensemble.rank == 0:\n",
    "                plt.close(infoFig)\n",
    "                infoPlots.append(infoFig)\n",
    "    \n",
    "    if (it%10 == 0):\n",
    "        print \"{:03.0f}\".format(100*it / T) + \" % => t=\" + str(t) \n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inspect results\n",
    "def show_figures(figs):\n",
    "    for f in figs:\n",
    "        dummy = plt.figure()\n",
    "        new_manager = dummy.canvas.manager\n",
    "        new_manager.canvas.figure = f\n",
    "        f.set_canvas(new_manager.canvas)\n",
    "        filename= f._suptitle.get_text().replace(\" \", \"_\").replace(\"=_\", \"\") + \".png\"\n",
    "        #plt.savefig(filename)\n",
    "        \n",
    "if ensemble.rank == 0:\n",
    "    show_figures(infoPlots)\n",
    "    fig = ensemble.plotDistanceInfo(title=\"Final ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}