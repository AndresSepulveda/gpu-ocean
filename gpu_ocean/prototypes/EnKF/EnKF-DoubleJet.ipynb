{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "This software is part of GPU Ocean. \n",
    "Copyright (C) 2019 SINTEF Digital\n",
    "\n",
    "This python program is used to set up and run a data-assimilation \n",
    "and drift trajectory forecasting experiment.\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import sys, os, json, datetime, time, shutil\n",
    "import numpy as np\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "if os.path.isdir(os.path.abspath(os.path.join(current_dir, '../../SWESimulators'))):\n",
    "        sys.path.insert(0, os.path.abspath(os.path.join(current_dir, '../../')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------\n",
    "# PARAMETERS\n",
    "#--------------------------------------------------------------\n",
    "ensemble_size = 10\n",
    "method = \"EnKF\" #\"iewpf2\"\n",
    "observation_interval = 1\n",
    "observation_variance = 1.0\n",
    "observation_type = \"bouys\"\n",
    "buoy_area = \"all\"\n",
    "media_dir = \"forecasting_results/\"\n",
    "\n",
    "num_days = 7\n",
    "num_hours = 24\n",
    "forecast_days = 3\n",
    "profiling = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input arguments:\n",
      "\n",
      "Path to initial conditions for ensemble:\n",
      "\tC:/Users/florianb/Documents/GPU-Ocean/data/ensemble_init/\n",
      "Path to true state:\n",
      "\tC:/Users/florianb/Documents/GPU-Ocean/data/true_state/\n",
      "destination folder:\n",
      "\tforecasting_results/da_experiment_2020_12_15-15_12_44/\n",
      "Path to particle info:\n",
      "\tforecasting_results/da_experiment_2020_12_15-15_12_44/particle_info_\n",
      "Path to forecast members:\n",
      "\tforecasting_results/da_experiment_2020_12_15-15_12_44/forecast_member_\n",
      " ----> Using EnKF\n"
     ]
    }
   ],
   "source": [
    "###-----------------------------------------\n",
    "## Define files for ensemble and truth.\n",
    "##\n",
    "ensemble_init_path = 'C:/Users/florianb/Documents/GPU-Ocean/data/ensemble_init/'\n",
    "assert len(os.listdir(ensemble_init_path)) == 100 or len(os.listdir(ensemble_init_path)) == 101, \\\n",
    "    \"Ensemble init folder has wrong number of files: \" + str(len(os.listdir(ensemble_init_path)))\n",
    "\n",
    "truth_path = 'C:/Users/florianb/Documents/GPU-Ocean/data/true_state/'\n",
    "assert len(os.listdir(truth_path)) == 2 or len(os.listdir(truth_path)) == 3, \\\n",
    "    \"Truth folder has wrong number of files\"\n",
    "\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "destination_dir = os.path.join(media_dir, \"da_experiment_\" +  timestamp + \"/\")\n",
    "os.makedirs(destination_dir)\n",
    "\n",
    "# Copy the truth into the destination folder\n",
    "shutil.copytree(truth_path, os.path.join(destination_dir, 'truth'))\n",
    "\n",
    "# Define misc filenames\n",
    "log_file = os.path.join(destination_dir, 'description.txt')\n",
    "\n",
    "particleInfoPrefix = os.path.join(destination_dir, 'particle_info_')\n",
    "forecastFileBase = os.path.join(destination_dir, 'forecast_member_')\n",
    "\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Data Assimilation experiment ' + timestamp + '\\n')\n",
    "    f.write('----------------------------------------------' + '\\n')\n",
    "\n",
    "def logParams():\n",
    "    log('Input arguments:')\n",
    "    #for arg in vars(args):\n",
    "    #    log('\\t' + str((arg, getattr(args, arg))))\n",
    "    log('\\nPath to initial conditions for ensemble:')\n",
    "    log('\\t' + ensemble_init_path)\n",
    "    log('Path to true state:')\n",
    "    log('\\t' + truth_path)\n",
    "    log('destination folder:')\n",
    "    log('\\t' + destination_dir)\n",
    "    log('Path to particle info:')\n",
    "    log('\\t' + particleInfoPrefix)\n",
    "    log('Path to forecast members:')\n",
    "    log('\\t' + forecastFileBase)\n",
    "\n",
    "def log(msg, screen=True):\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(msg + '\\n')\n",
    "    if screen:\n",
    "        print(msg)\n",
    "        \n",
    "logParams()\n",
    "        \n",
    "    \n",
    "# Reading and checking method\n",
    "method = str(method).lower()\n",
    "if method == 'iewpf2':\n",
    "    log(' ----> Using IEWPF 2 stage method')\n",
    "elif method == 'enkf':\n",
    "    log(' ----> Using EnKF')\n",
    "elif method == 'none':\n",
    "    log(' ----> No data assimilation')\n",
    "else:\n",
    "    log('Illegal method: ' + str(method))\n",
    "    sys.exit(-1)\n",
    "    \n",
    "    \n",
    "# Time parameters\n",
    "start_time      =  3*24*60*60 #  3 days in seconds\n",
    "simulation_time = 10*24*60*60 # 10 days in seconds (three days spin up is prior to this)fa\n",
    "end_time        = 13*24*60*60 # 13 days in seconds\n",
    "\n",
    "\n",
    "# Based on truth from June 25th 2019\n",
    "#drifterSet = [ 2, 7, 12, 24, 29, 35, 41, 48, 53, 60]\n",
    "drifterSet = [ 2, 24, 60]\n",
    "\n",
    "# Log extra information for the ensemble state for the following cells:\n",
    "extraCells = np.array([[254, 241], # Cross with two trajectories\n",
    "                       [249, 246], # northwest of above\n",
    "                       [259, 236], # southeast of above\n",
    "                       [343, 131], # Closed circle of same drifter\n",
    "                       [196,  245], # Middle of single trajectory\n",
    "                       [150,  250], # Middle of single trajectory, later than above\n",
    "                       [102, 252], # On the same trajectory as the above, but later, and also in a intersection\n",
    "                       [ 388, 100], # Unobserved area just north of southern jet\n",
    "                       [ 388, 80],  # Unobserved area in southern jet\n",
    "                       [ 388, 150], # Unobserved area in calm area\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9760 s: GPU Ocean packages imported\n",
      "0.1224 s: Created context on Quadro T2000\n"
     ]
    }
   ],
   "source": [
    "###--------------------------------\n",
    "# Import required packages\n",
    "#\n",
    "tic = time.time()\n",
    "# For GPU contex:\n",
    "from SWESimulators import Common\n",
    "# For the ensemble:\n",
    "from SWESimulators import EnsembleFromFiles, Observation\n",
    "# For data assimilation:\n",
    "from SWESimulators import IEWPFOcean\n",
    "import EnKFOcean\n",
    "# For forcasting:\n",
    "from SWESimulators import GPUDrifterCollection\n",
    "# For ObservationType:\n",
    "from SWESimulators import DataAssimilationUtils as dautils\n",
    "\n",
    "toc = time.time()\n",
    "log(\"\\n{:02.4f} s: \".format(toc-tic) + 'GPU Ocean packages imported', True)\n",
    "\n",
    "# Create CUDA context\n",
    "tic = time.time()\n",
    "gpu_ctx = Common.CUDAContext()\n",
    "device_name = gpu_ctx.cuda_device.name()\n",
    "toc = time.time()\n",
    "log(\"{:02.4f} s: \".format(toc-tic) + \"Created context on \" + device_name, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8978 s: Ensemble is loaded and created\n",
      "Using drifterSet:\n",
      "[2, 24, 60]\n"
     ]
    }
   ],
   "source": [
    "###--------------------------\n",
    "# Initiate the ensemble\n",
    "#\n",
    "\n",
    "observation_type = dautils.ObservationType.UnderlyingFlow\n",
    "if observation_type == 'buoys':\n",
    "    observation_type = dautils.ObservationType.StaticBuoys\n",
    "    log('Observation type changed to StaticBuoys!')\n",
    "elif observation_type == 'all_drifters':\n",
    "    drifterSet = 'all'\n",
    "    log('Using all drifters for DA experiment')\n",
    "\n",
    "    \n",
    "cont_write_netcdf = True and not profiling\n",
    "\n",
    "tic = time.time()\n",
    "ensemble = EnsembleFromFiles.EnsembleFromFiles(gpu_ctx, ensemble_size, \\\n",
    "                                               ensemble_init_path, truth_path, \\\n",
    "                                               observation_variance,\n",
    "                                               cont_write_netcdf = cont_write_netcdf,\n",
    "                                               use_lcg = True,\n",
    "                                               write_netcdf_directory = destination_dir,\n",
    "                                               observation_type=observation_type)\n",
    "\n",
    "# Configure observations according to the selected drifters:\n",
    "ensemble.configureObservations(drifterSet=drifterSet, \n",
    "                               observationInterval = observation_interval,\n",
    "                               buoy_area = buoy_area)\n",
    "ensemble.configureParticleInfos(extraCells)\n",
    "toc = time.time()\n",
    "log(\"{:02.4f} s: \".format(toc-tic) + \"Ensemble is loaded and created\", True)\n",
    "log(\"Using drifterSet:\\n\" + str(drifterSet))\n",
    "if observation_type == 'buoys':\n",
    "    log('buoys to read:')\n",
    "    log(str(ensemble.observations.read_buoy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000 s: Data assimilation class EnKFOcean initiated\n"
     ]
    }
   ],
   "source": [
    "### -------------------------------\n",
    "# Initialize IEWPF class (if needed)\n",
    "#\n",
    "tic = time.time()\n",
    "iewpf = None\n",
    "if method.startswith('iewpf'):\n",
    "    iewpf = IEWPFOcean.IEWPFOcean(ensemble)\n",
    "    toc = time.time()\n",
    "    log(\"{:02.4f} s: \".format(toc-tic) + \"Data assimilation class IEWPFOcean initiated\", True)\n",
    "elif method.startswith('enkf'):\n",
    "    enkf = EnKFOcean.EnKFOcean(ensemble)\n",
    "    toc = time.time()\n",
    "    log(\"{:02.4f} s: \".format(toc-tic) + \"Data assimilation class EnKFOcean initiated\", True)\n",
    "else:\n",
    "    toc = time.time()\n",
    "    log(\"{:02.4f} s: \".format(toc-tic) + \"Skipping creation of a DA class\", True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Starting simulation --------------\n",
      "--- numDays:       7\n",
      "--- numHours:      24\n",
      "--- forecast_days: 3\n",
      "---------------------------------------------\n",
      "-------- Starting day 0\n",
      "08.6 s:  Done simulating hour 1 of day 3\n",
      "17.6 s:  Done simulating hour 2 of day 3\n",
      "27.5 s:  Done simulating hour 3 of day 3\n",
      "36.3 s:  Done simulating hour 4 of day 3\n",
      "45.3 s:  Done simulating hour 5 of day 3\n",
      "54.1 s:  Done simulating hour 6 of day 3\n",
      "62.8 s:  Done simulating hour 7 of day 3\n",
      "71.4 s:  Done simulating hour 8 of day 3\n",
      "80.1 s:  Done simulating hour 9 of day 3\n",
      "88.8 s:  Done simulating hour 10 of day 3\n",
      "97.4 s:  Done simulating hour 11 of day 3\n",
      "106.1 s:  Done simulating hour 12 of day 3\n",
      "114.8 s:  Done simulating hour 13 of day 3\n",
      "123.4 s:  Done simulating hour 14 of day 3\n",
      "132.0 s:  Done simulating hour 15 of day 3\n",
      "140.7 s:  Done simulating hour 16 of day 3\n",
      "149.4 s:  Done simulating hour 17 of day 3\n",
      "158.0 s:  Done simulating hour 18 of day 3\n",
      "166.7 s:  Done simulating hour 19 of day 3\n",
      "175.3 s:  Done simulating hour 20 of day 3\n",
      "184.1 s:  Done simulating hour 21 of day 3\n",
      "192.8 s:  Done simulating hour 22 of day 3\n",
      "201.5 s:  Done simulating hour 23 of day 3\n",
      "210.2 s:  Done simulating hour 24 of day 3\n",
      "-------- Starting day 1\n",
      "220.7 s:  Done simulating hour 1 of day 4\n",
      "229.3 s:  Done simulating hour 2 of day 4\n",
      "238.0 s:  Done simulating hour 3 of day 4\n",
      "248.8 s:  Done simulating hour 4 of day 4\n",
      "257.6 s:  Done simulating hour 5 of day 4\n",
      "267.1 s:  Done simulating hour 6 of day 4\n",
      "276.3 s:  Done simulating hour 7 of day 4\n",
      "285.1 s:  Done simulating hour 8 of day 4\n",
      "294.9 s:  Done simulating hour 9 of day 4\n",
      "303.7 s:  Done simulating hour 10 of day 4\n",
      "312.6 s:  Done simulating hour 11 of day 4\n",
      "321.4 s:  Done simulating hour 12 of day 4\n",
      "332.0 s:  Done simulating hour 13 of day 4\n",
      "342.5 s:  Done simulating hour 14 of day 4\n",
      "351.9 s:  Done simulating hour 15 of day 4\n",
      "361.2 s:  Done simulating hour 16 of day 4\n",
      "370.3 s:  Done simulating hour 17 of day 4\n",
      "379.2 s:  Done simulating hour 18 of day 4\n",
      "388.3 s:  Done simulating hour 19 of day 4\n",
      "397.0 s:  Done simulating hour 20 of day 4\n",
      "406.0 s:  Done simulating hour 21 of day 4\n",
      "415.0 s:  Done simulating hour 22 of day 4\n",
      "423.9 s:  Done simulating hour 23 of day 4\n",
      "433.3 s:  Done simulating hour 24 of day 4\n",
      "-------- Starting day 2\n",
      "444.9 s:  Done simulating hour 1 of day 5\n",
      "454.5 s:  Done simulating hour 2 of day 5\n",
      "463.3 s:  Done simulating hour 3 of day 5\n",
      "471.9 s:  Done simulating hour 4 of day 5\n",
      "480.6 s:  Done simulating hour 5 of day 5\n",
      "489.3 s:  Done simulating hour 6 of day 5\n",
      "498.0 s:  Done simulating hour 7 of day 5\n",
      "506.6 s:  Done simulating hour 8 of day 5\n",
      "515.5 s:  Done simulating hour 9 of day 5\n",
      "525.5 s:  Done simulating hour 10 of day 5\n",
      "534.6 s:  Done simulating hour 11 of day 5\n",
      "544.0 s:  Done simulating hour 12 of day 5\n",
      "552.9 s:  Done simulating hour 13 of day 5\n",
      "562.2 s:  Done simulating hour 14 of day 5\n",
      "571.6 s:  Done simulating hour 15 of day 5\n",
      "580.4 s:  Done simulating hour 16 of day 5\n",
      "589.2 s:  Done simulating hour 17 of day 5\n",
      "599.0 s:  Done simulating hour 18 of day 5\n",
      "607.7 s:  Done simulating hour 19 of day 5\n",
      "616.7 s:  Done simulating hour 20 of day 5\n",
      "626.1 s:  Done simulating hour 21 of day 5\n",
      "635.7 s:  Done simulating hour 22 of day 5\n",
      "645.6 s:  Done simulating hour 23 of day 5\n",
      "654.8 s:  Done simulating hour 24 of day 5\n",
      "-------- Starting day 3\n",
      "665.7 s:  Done simulating hour 1 of day 6\n",
      "675.1 s:  Done simulating hour 2 of day 6\n",
      "684.2 s:  Done simulating hour 3 of day 6\n",
      "693.4 s:  Done simulating hour 4 of day 6\n",
      "702.4 s:  Done simulating hour 5 of day 6\n",
      "711.5 s:  Done simulating hour 6 of day 6\n",
      "720.4 s:  Done simulating hour 7 of day 6\n",
      "729.1 s:  Done simulating hour 8 of day 6\n",
      "738.2 s:  Done simulating hour 9 of day 6\n",
      "747.1 s:  Done simulating hour 10 of day 6\n",
      "756.0 s:  Done simulating hour 11 of day 6\n",
      "765.0 s:  Done simulating hour 12 of day 6\n",
      "773.8 s:  Done simulating hour 13 of day 6\n",
      "784.3 s:  Done simulating hour 14 of day 6\n",
      "794.1 s:  Done simulating hour 15 of day 6\n",
      "803.3 s:  Done simulating hour 16 of day 6\n",
      "812.1 s:  Done simulating hour 17 of day 6\n",
      "821.0 s:  Done simulating hour 18 of day 6\n",
      "829.9 s:  Done simulating hour 19 of day 6\n",
      "838.7 s:  Done simulating hour 20 of day 6\n",
      "847.7 s:  Done simulating hour 21 of day 6\n",
      "857.9 s:  Done simulating hour 22 of day 6\n",
      "867.5 s:  Done simulating hour 23 of day 6\n",
      "877.0 s:  Done simulating hour 24 of day 6\n",
      "-------- Starting day 4\n",
      "888.1 s:  Done simulating hour 1 of day 7\n",
      "897.2 s:  Done simulating hour 2 of day 7\n",
      "906.2 s:  Done simulating hour 3 of day 7\n",
      "915.4 s:  Done simulating hour 4 of day 7\n",
      "924.7 s:  Done simulating hour 5 of day 7\n",
      "935.6 s:  Done simulating hour 6 of day 7\n",
      "947.1 s:  Done simulating hour 7 of day 7\n",
      "957.2 s:  Done simulating hour 8 of day 7\n",
      "967.0 s:  Done simulating hour 9 of day 7\n",
      "976.5 s:  Done simulating hour 10 of day 7\n",
      "985.8 s:  Done simulating hour 11 of day 7\n",
      "995.0 s:  Done simulating hour 12 of day 7\n",
      "1004.2 s:  Done simulating hour 13 of day 7\n",
      "1013.2 s:  Done simulating hour 14 of day 7\n",
      "1022.3 s:  Done simulating hour 15 of day 7\n",
      "1031.7 s:  Done simulating hour 16 of day 7\n",
      "1040.9 s:  Done simulating hour 17 of day 7\n",
      "1050.1 s:  Done simulating hour 18 of day 7\n",
      "1059.5 s:  Done simulating hour 19 of day 7\n",
      "1068.6 s:  Done simulating hour 20 of day 7\n",
      "1077.8 s:  Done simulating hour 21 of day 7\n",
      "1086.9 s:  Done simulating hour 22 of day 7\n",
      "1096.0 s:  Done simulating hour 23 of day 7\n",
      "1105.4 s:  Done simulating hour 24 of day 7\n",
      "-------- Starting day 5\n",
      "1116.6 s:  Done simulating hour 1 of day 8\n",
      "1125.5 s:  Done simulating hour 2 of day 8\n",
      "1134.7 s:  Done simulating hour 3 of day 8\n",
      "1144.0 s:  Done simulating hour 4 of day 8\n",
      "1153.3 s:  Done simulating hour 5 of day 8\n",
      "1163.5 s:  Done simulating hour 6 of day 8\n",
      "1173.4 s:  Done simulating hour 7 of day 8\n",
      "1182.8 s:  Done simulating hour 8 of day 8\n",
      "1191.9 s:  Done simulating hour 9 of day 8\n",
      "1202.0 s:  Done simulating hour 10 of day 8\n",
      "1212.8 s:  Done simulating hour 11 of day 8\n",
      "1223.0 s:  Done simulating hour 12 of day 8\n",
      "1234.6 s:  Done simulating hour 13 of day 8\n",
      "1244.9 s:  Done simulating hour 14 of day 8\n",
      "1254.2 s:  Done simulating hour 15 of day 8\n",
      "1263.7 s:  Done simulating hour 16 of day 8\n",
      "1273.2 s:  Done simulating hour 17 of day 8\n",
      "1282.9 s:  Done simulating hour 18 of day 8\n",
      "1292.8 s:  Done simulating hour 19 of day 8\n",
      "1302.3 s:  Done simulating hour 20 of day 8\n",
      "1312.9 s:  Done simulating hour 21 of day 8\n",
      "1323.7 s:  Done simulating hour 22 of day 8\n",
      "1333.8 s:  Done simulating hour 23 of day 8\n",
      "1345.1 s:  Done simulating hour 24 of day 8\n",
      "-------- Starting day 6\n",
      "1357.2 s:  Done simulating hour 1 of day 9\n",
      "1367.0 s:  Done simulating hour 2 of day 9\n",
      "1376.8 s:  Done simulating hour 3 of day 9\n",
      "1388.8 s:  Done simulating hour 4 of day 9\n",
      "1398.3 s:  Done simulating hour 5 of day 9\n",
      "1407.6 s:  Done simulating hour 6 of day 9\n",
      "1416.9 s:  Done simulating hour 7 of day 9\n",
      "1426.2 s:  Done simulating hour 8 of day 9\n",
      "1435.5 s:  Done simulating hour 9 of day 9\n",
      "1444.8 s:  Done simulating hour 10 of day 9\n",
      "1454.2 s:  Done simulating hour 11 of day 9\n",
      "1463.4 s:  Done simulating hour 12 of day 9\n",
      "1472.7 s:  Done simulating hour 13 of day 9\n",
      "1482.1 s:  Done simulating hour 14 of day 9\n",
      "1491.4 s:  Done simulating hour 15 of day 9\n",
      "1502.6 s:  Done simulating hour 16 of day 9\n",
      "1514.2 s:  Done simulating hour 17 of day 9\n",
      "1524.7 s:  Done simulating hour 18 of day 9\n",
      "1534.6 s:  Done simulating hour 19 of day 9\n",
      "1546.0 s:  Done simulating hour 20 of day 9\n",
      "1557.4 s:  Done simulating hour 21 of day 9\n",
      "1568.9 s:  Done simulating hour 22 of day 9\n",
      "1580.1 s:  Done simulating hour 23 of day 9\n",
      "1591.6 s:  Done simulating hour 24 of day 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### ----------------------------------------------\n",
    "#   DATA ASSIMILATION\n",
    "#\n",
    "\n",
    "obstime = start_time # time in seconds (starting after spin-up phase)\n",
    "\n",
    "master_tic = time.time()\n",
    "\n",
    "numDays = num_days \n",
    "numHours = num_hours \n",
    "forecast_days = forecast_days\n",
    "\n",
    "\n",
    "log('---------- Starting simulation --------------') \n",
    "log('--- numDays:       ' + str(numDays))\n",
    "log('--- numHours:      ' + str(numHours))\n",
    "log('--- forecast_days: ' + str(forecast_days))\n",
    "log('---------------------------------------------') \n",
    "\n",
    "for day in range(numDays):\n",
    "    log('-------- Starting day ' + str(day))\n",
    "    \n",
    "    for hour in range(numHours):\n",
    "        \n",
    "        for fiveMin in range(12):\n",
    "            \n",
    "            drifter_cells = ensemble.getDrifterCells()\n",
    "            \n",
    "            for minute in range(5):\n",
    "                obstime += 60\n",
    "                ensemble.stepToObservation(obstime, model_error_final_step=(minute<4))\n",
    "\n",
    "                if minute == 4:\n",
    "                    if method == 'iewpf':\n",
    "                        iewpf.iewpf_2stage(ensemble, perform_step=False)\n",
    "                    elif method == 'enkf':\n",
    "                        enkf.EnKF(ensemble)\n",
    "\n",
    "                ensemble.registerStateSample(drifter_cells)\n",
    "                # Done minutes\n",
    "\n",
    "        # Done five minutes\n",
    "    \n",
    "        toc = time.time()\n",
    "        log(\"{:04.1f} s: \".format(toc-master_tic) + \" Done simulating hour \" + str(hour + 1) + \" of day \" + str(day + 3))\n",
    "    # Done hours\n",
    "\n",
    "    ensemble.dumpParticleInfosToFile(particleInfoPrefix)\n",
    "    \n",
    "    ensemble.writeEnsembleToNetCDF()\n",
    "    \n",
    "# Done days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "-----------   STARTING FORECAST              --------------\n",
      "-----------------------------------------------------------\n",
      "25.5 s:  Forecast for particle 0 done\n",
      "      Forecast written to forecasting_results/da_experiment_2020_12_15-15_12_44/forecast_member_0000.bz2\n",
      "25.6 s:  Forecast for particle 1 done\n",
      "      Forecast written to forecasting_results/da_experiment_2020_12_15-15_12_44/forecast_member_0001.bz2\n",
      "25.5 s:  Forecast for particle 2 done\n",
      "      Forecast written to forecasting_results/da_experiment_2020_12_15-15_12_44/forecast_member_0002.bz2\n",
      "25.6 s:  Forecast for particle 3 done\n",
      "      Forecast written to forecasting_results/da_experiment_2020_12_15-15_12_44/forecast_member_0003.bz2\n",
      "25.5 s:  Forecast for particle 4 done\n",
      "      Forecast written to forecasting_results/da_experiment_2020_12_15-15_12_44/forecast_member_0004.bz2\n",
      "25.5 s:  Forecast for particle 5 done\n",
      "      Forecast written to forecasting_results/da_experiment_2020_12_15-15_12_44/forecast_member_0005.bz2\n",
      "25.6 s:  Forecast for particle 6 done\n",
      "      Forecast written to forecasting_results/da_experiment_2020_12_15-15_12_44/forecast_member_0006.bz2\n",
      "25.6 s:  Forecast for particle 7 done\n",
      "      Forecast written to forecasting_results/da_experiment_2020_12_15-15_12_44/forecast_member_0007.bz2\n",
      "25.7 s:  Forecast for particle 8 done\n",
      "      Forecast written to forecasting_results/da_experiment_2020_12_15-15_12_44/forecast_member_0008.bz2\n",
      "25.8 s:  Forecast for particle 9 done\n",
      "      Forecast written to forecasting_results/da_experiment_2020_12_15-15_12_44/forecast_member_0009.bz2\n"
     ]
    }
   ],
   "source": [
    "### -------------------------------------------------\n",
    "#   Start forecast\n",
    "#\n",
    "\n",
    "\n",
    "log('-----------------------------------------------------------')\n",
    "log('-----------   STARTING FORECAST              --------------')\n",
    "log('-----------------------------------------------------------')\n",
    "\n",
    "forecast_start_time = obstime\n",
    "\n",
    "# Read all drifters (even those that are not used in the assimilation)\n",
    "drifter_start_positions = ensemble.observeTrueDrifters(applyDrifterSet=False, ignoreBuoys=True)\n",
    "num_drifters = len(drifter_start_positions)\n",
    "\n",
    "forecast_end_time = forecast_start_time + forecast_days*numHours*60*60\n",
    "\n",
    "observation_intervals = 5*60\n",
    "netcdf_intervals = numHours*60*60\n",
    "\n",
    "netcdf_iterations = int((forecast_end_time - forecast_start_time)/netcdf_intervals)\n",
    "observations_iterations = int(netcdf_intervals/observation_intervals)\n",
    "\n",
    "\n",
    "for particle_id in range(ensemble.getNumParticles()):\n",
    "    \n",
    "    if ensemble.particlesActive[particle_id]:\n",
    "\n",
    "        sim = ensemble.particles[particle_id]\n",
    "\n",
    "        tic = time.time()\n",
    "        next_obs_time = sim.t\n",
    "\n",
    "\n",
    "        drifters = GPUDrifterCollection.GPUDrifterCollection(gpu_ctx, num_drifters,\n",
    "                                                             boundaryConditions=ensemble.getBoundaryConditions(), \n",
    "                                                             domain_size_x=ensemble.getDomainSizeX(), domain_size_y=ensemble.getDomainSizeY())\n",
    "        drifters.setDrifterPositions(drifter_start_positions)\n",
    "        sim.attachDrifters(drifters)\n",
    "\n",
    "        forecast_file_name = forecastFileBase + str(particle_id).zfill(4) + \".bz2\"\n",
    "\n",
    "        observations = Observation.Observation()\n",
    "        observations.add_observation_from_sim(sim)\n",
    "\n",
    "        for netcdf_it in range(netcdf_iterations):\n",
    "\n",
    "            for obs_it in range(observations_iterations):\n",
    "                next_obs_time += observation_intervals\n",
    "\n",
    "                # Step until next observation \n",
    "                sim.dataAssimilationStep(next_obs_time, write_now=False)\n",
    "\n",
    "                # Store observation\n",
    "                observations.add_observation_from_sim(sim)\n",
    "\n",
    "            sim.writeState()\n",
    "\n",
    "        # Write forecast to file    \n",
    "        observations.to_pickle(forecast_file_name)\n",
    "\n",
    "        toc = time.time()\n",
    "        log(\"{:04.1f} s: \".format(toc-tic) + \" Forecast for particle \" + str(particle_id) + \" done\")\n",
    "        log(\"      Forecast written to \" + forecast_file_name)\n",
    "    \n",
    "    else:\n",
    "        log(\"Skipping forecast for particle \" + str(particle_id) + \", as this particle is dead\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing file forecasting_results/da_experiment_2020_12_15-15_12_44/ensemble_member_0000.nc ...\n",
      "Closing file forecasting_results/da_experiment_2020_12_15-15_12_44/ensemble_member_0001.nc ...\n",
      "Closing file forecasting_results/da_experiment_2020_12_15-15_12_44/ensemble_member_0002.nc ...\n",
      "Closing file forecasting_results/da_experiment_2020_12_15-15_12_44/ensemble_member_0003.nc ...\n",
      "Closing file forecasting_results/da_experiment_2020_12_15-15_12_44/ensemble_member_0004.nc ...\n",
      "Closing file forecasting_results/da_experiment_2020_12_15-15_12_44/ensemble_member_0005.nc ...\n",
      "Closing file forecasting_results/da_experiment_2020_12_15-15_12_44/ensemble_member_0006.nc ...\n",
      "Closing file forecasting_results/da_experiment_2020_12_15-15_12_44/ensemble_member_0007.nc ...\n",
      "Closing file forecasting_results/da_experiment_2020_12_15-15_12_44/ensemble_member_0008.nc ...\n",
      "Closing file forecasting_results/da_experiment_2020_12_15-15_12_44/ensemble_member_0009.nc ...\n",
      "\n",
      "5.2279 s: Clean up simulator done.\n",
      "Done! Only checking is left. There should be a \"yes, done\" in the next line\n",
      "Yes, done!\n"
     ]
    }
   ],
   "source": [
    "# Clean up simulation and close netcdf file\n",
    "tic = time.time()\n",
    "sim = None\n",
    "ensemble.cleanUp()\n",
    "toc = time.time()\n",
    "print(\"\\n{:02.4f} s: \".format(toc-tic) + \"Clean up simulator done.\")\n",
    "\n",
    "log('Done! Only checking is left. There should be a \"yes, done\" in the next line')\n",
    "\n",
    "if not profiling:\n",
    "    assert(numDays == 7), 'Simulated with wrong number of days!'\n",
    "    assert(numHours == 24), 'Simulated with wrong number of hours'\n",
    "    assert(forecast_end_time == 13*24*60*60), 'Forecast did not reach goal time'\n",
    "\n",
    "log('Yes, done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('gpuocean': conda)",
   "metadata": {
    "interpreter": {
     "hash": "33ed7ca3d490b1455ef8763b7de4f413d7a0b0dcbe44e1e5f95f5e2fe69a0829"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
