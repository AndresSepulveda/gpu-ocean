{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "This software is part of GPU Ocean. \n",
    "Copyright (C) 2019 SINTEF Digital\n",
    "\n",
    "This python program is used to set up and run a data-assimilation \n",
    "and drift trajectory forecasting experiment.\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import sys, os, json, datetime, time, shutil\n",
    "import numpy as np\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "if os.path.isdir(os.path.abspath(os.path.join(current_dir, '../../SWESimulators'))):\n",
    "        sys.path.insert(0, os.path.abspath(os.path.join(current_dir, '../../')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------\n",
    "# PARAMETERS\n",
    "#--------------------------------------------------------------\n",
    "# Read input parameters and check that they are good\n",
    "\"\"\"\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Generate an ensemble.')\n",
    "parser.add_argument('-N', '--ensemble_size', type=int, default=None)\n",
    "parser.add_argument('--method', type=str, default='iewpf2')\n",
    "parser.add_argument('--observation_interval', type=int, default=1)\n",
    "parser.add_argument('--observation_variance', type=float, default=1.0)\n",
    "parser.add_argument('--observation_type', type=str, default='drifters')\n",
    "parser.add_argument('--buoy_area', type=str, default='all')\n",
    "parser.add_argument('--media_dir', type=str, default='forecasting_results/')\n",
    "\n",
    "parser.add_argument('--num_days', type=int, default=7) \n",
    "parser.add_argument('--num_hours', type=int, default=24) \n",
    "parser.add_argument('--forecast_days', type=int, default=3)\n",
    "parser.add_argument('--profiling', action='store_true')\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Checking input args\n",
    "if args.ensemble_size is None:\n",
    "    print(\"Ensemble size missing, please provide a --ensemble_size argument.\")\n",
    "    sys.exit(-1)\n",
    "elif args.ensemble_size < 1:\n",
    "    parser.error(\"Illegal ensemble size \" + str(args.ensemble_size))\n",
    "\n",
    "profiling = args.profiling\n",
    "\"\"\"\n",
    "\n",
    "ensemble_size = 10\n",
    "method = \"iewpf2\"\n",
    "observation_interval = 1\n",
    "observation_variance = 1.0\n",
    "observation_type = \"drifters\"\n",
    "buoy_area = \"all\"\n",
    "media_dir = \"forecasting_results/\"\n",
    "\n",
    "num_days = 7\n",
    "num_hours = 24\n",
    "forecast_days = 3\n",
    "profiling = \"store_true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input arguments:\n\nPath to initial conditions for ensemble:\n\tC:/Users/florianb/Documents/GPU-Ocean/data/ensemble_init/\nPath to true state:\n\tC:/Users/florianb/Documents/GPU-Ocean/data/true_state/\ndestination folder:\n\tforecasting_results/da_experiment_2020_11_19-10_21_29/\nPath to particle info:\n\tforecasting_results/da_experiment_2020_11_19-10_21_29/particle_info_\nPath to forecast members:\n\tforecasting_results/da_experiment_2020_11_19-10_21_29/forecast_member_\n ----> Using IEWPF 2 stage method\n"
     ]
    }
   ],
   "source": [
    "###-----------------------------------------\n",
    "## Define files for ensemble and truth.\n",
    "##\n",
    "ensemble_init_path = 'C:/Users/florianb/Documents/GPU-Ocean/data/ensemble_init/'\n",
    "assert len(os.listdir(ensemble_init_path)) == 100 or len(os.listdir(ensemble_init_path)) == 101, \\\n",
    "    \"Ensemble init folder has wrong number of files: \" + str(len(os.listdir(ensemble_init_path)))\n",
    "\n",
    "truth_path = 'C:/Users/florianb/Documents/GPU-Ocean/data/true_state/'\n",
    "assert len(os.listdir(truth_path)) == 2 or len(os.listdir(truth_path)) == 3, \\\n",
    "    \"Truth folder has wrong number of files\"\n",
    "\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "destination_dir = os.path.join(media_dir, \"da_experiment_\" +  timestamp + \"/\")\n",
    "os.makedirs(destination_dir)\n",
    "\n",
    "# Copy the truth into the destination folder\n",
    "shutil.copytree(truth_path, os.path.join(destination_dir, 'truth'))\n",
    "\n",
    "# Define misc filenames\n",
    "log_file = os.path.join(destination_dir, 'description.txt')\n",
    "\n",
    "particleInfoPrefix = os.path.join(destination_dir, 'particle_info_')\n",
    "forecastFileBase = os.path.join(destination_dir, 'forecast_member_')\n",
    "\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Data Assimilation experiment ' + timestamp + '\\n')\n",
    "    f.write('----------------------------------------------' + '\\n')\n",
    "\n",
    "def logParams():\n",
    "    log('Input arguments:')\n",
    "    #for arg in vars(args):\n",
    "    #    log('\\t' + str((arg, getattr(args, arg))))\n",
    "    log('\\nPath to initial conditions for ensemble:')\n",
    "    log('\\t' + ensemble_init_path)\n",
    "    log('Path to true state:')\n",
    "    log('\\t' + truth_path)\n",
    "    log('destination folder:')\n",
    "    log('\\t' + destination_dir)\n",
    "    log('Path to particle info:')\n",
    "    log('\\t' + particleInfoPrefix)\n",
    "    log('Path to forecast members:')\n",
    "    log('\\t' + forecastFileBase)\n",
    "\n",
    "def log(msg, screen=True):\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(msg + '\\n')\n",
    "    if screen:\n",
    "        print(msg)\n",
    "        \n",
    "logParams()\n",
    "        \n",
    "    \n",
    "# Reading and checking method\n",
    "method = str(method).lower()\n",
    "if method == 'iewpf2':\n",
    "    log(' ----> Using IEWPF 2 stage method')\n",
    "elif method == 'none':\n",
    "    log(' ----> No data assimilation')\n",
    "else:\n",
    "    log('Illegal method: ' + str(method))\n",
    "    sys.exit(-1)\n",
    "    \n",
    "    \n",
    "# Time parameters\n",
    "start_time      =  3*24*60*60 #  3 days\n",
    "simulation_time = 10*24*60*60 # 10 days (three days spin up is prior to this)fa\n",
    "end_time        = 13*24*60*60 # 13 days\n",
    "\n",
    "\n",
    "# Based on truth from June 25th 2019\n",
    "#drifterSet = [ 2, 7, 12, 24, 29, 35, 41, 48, 53, 60]\n",
    "drifterSet = [ 2, 24, 60]\n",
    "\n",
    "# Log extra information for the ensemble state for the following cells:\n",
    "extraCells = np.array([[254, 241], # Cross with two trajectories\n",
    "                       [249, 246], # northwest of above\n",
    "                       [259, 236], # southeast of above\n",
    "                       [343, 131], # Closed circle of same drifter\n",
    "                       [196,  245], # Middle of single trajectory\n",
    "                       [150,  250], # Middle of single trajectory, later than above\n",
    "                       [102, 252], # On the same trajectory as the above, but later, and also in a intersection\n",
    "                       [ 388, 100], # Unobserved area just north of southern jet\n",
    "                       [ 388, 80],  # Unobserved area in southern jet\n",
    "                       [ 388, 150], # Unobserved area in calm area\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n0.0010 s: GPU Ocean packages imported\n0.0933 s: Created context on Quadro T2000\n"
     ]
    }
   ],
   "source": [
    "###--------------------------------\n",
    "# Import required packages\n",
    "#\n",
    "tic = time.time()\n",
    "# For GPU contex:\n",
    "from SWESimulators import Common\n",
    "# For the ensemble:\n",
    "from SWESimulators import EnsembleFromFiles, Observation\n",
    "# For data assimilation:\n",
    "from SWESimulators import IEWPFOcean\n",
    "# For forcasting:\n",
    "from SWESimulators import GPUDrifterCollection\n",
    "# For ObservationType:\n",
    "from SWESimulators import DataAssimilationUtils as dautils\n",
    "\n",
    "toc = time.time()\n",
    "log(\"\\n{:02.4f} s: \".format(toc-tic) + 'GPU Ocean packages imported', True)\n",
    "\n",
    "# Create CUDA context\n",
    "tic = time.time()\n",
    "gpu_ctx = Common.CUDAContext()\n",
    "device_name = gpu_ctx.cuda_device.name()\n",
    "toc = time.time()\n",
    "log(\"{:02.4f} s: \".format(toc-tic) + \"Created context on \" + device_name, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###--------------------------\n",
    "# Initiate the ensemble\n",
    "#\n",
    "\n",
    "observation_type = dautils.ObservationType.UnderlyingFlow\n",
    "if observation_type == 'buoys':\n",
    "    observation_type = dautils.ObservationType.StaticBuoys\n",
    "    log('Observation type changed to StaticBuoys!')\n",
    "elif observation_type == 'all_drifters':\n",
    "    drifterSet = 'all'\n",
    "    log('Using all drifters for DA experiment')\n",
    "\n",
    "    \n",
    "cont_write_netcdf = True and not profiling\n",
    "\n",
    "tic = time.time()\n",
    "ensemble = EnsembleFromFiles.EnsembleFromFiles(gpu_ctx, ensemble_size, \\\n",
    "                                               ensemble_init_path, truth_path, \\\n",
    "                                               observation_variance,\n",
    "                                               cont_write_netcdf = cont_write_netcdf,\n",
    "                                               use_lcg = True,\n",
    "                                               write_netcdf_directory = destination_dir,\n",
    "                                               observation_type=observation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.8812 s: Ensemble is loaded and created\nUsing drifterSet:\n[2, 24, 60]\n"
     ]
    }
   ],
   "source": [
    "# Configure observations according to the selected drifters:\n",
    "ensemble.configureObservations(drifterSet=drifterSet, \n",
    "                               observationInterval = observation_interval,\n",
    "                               buoy_area = buoy_area)\n",
    "ensemble.configureParticleInfos(extraCells)\n",
    "toc = time.time()\n",
    "log(\"{:02.4f} s: \".format(toc-tic) + \"Ensemble is loaded and created\", True)\n",
    "log(\"Using drifterSet:\\n\" + str(drifterSet))\n",
    "if observation_type == 'buoys':\n",
    "    log('buoys to read:')\n",
    "    log(str(ensemble.observations.read_buoy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0709 s: Data assimilation class initiated\n"
     ]
    }
   ],
   "source": [
    "### -------------------------------\n",
    "# Initialize IEWPF class (if needed)\n",
    "#\n",
    "tic = time.time()\n",
    "iewpf = None\n",
    "if method.startswith('iewpf'):\n",
    "    iewpf = IEWPFOcean.IEWPFOcean(ensemble)\n",
    "    toc = time.time()\n",
    "    log(\"{:02.4f} s: \".format(toc-tic) + \"Data assimilation class initiated\", True)\n",
    "else:\n",
    "    toc = time.time()\n",
    "    log(\"{:02.4f} s: \".format(toc-tic) + \"Skipping creation of IEWPF as the method is not used\", True)\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------- Starting simulation --------------\n--- numDays:       7\n--- numHours:      24\n--- forecast_days: 3\n---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### ----------------------------------------------\n",
    "#   DATA ASSIMILATION\n",
    "#\n",
    "\n",
    "obstime = 3*24*60*60\n",
    "\n",
    "master_tic = time.time()\n",
    "\n",
    "numDays = num_days \n",
    "numHours = num_hours \n",
    "forecast_days = forecast_days\n",
    "\n",
    "\n",
    "log('---------- Starting simulation --------------') \n",
    "log('--- numDays:       ' + str(numDays))\n",
    "log('--- numHours:      ' + str(numHours))\n",
    "log('--- forecast_days: ' + str(forecast_days))\n",
    "log('---------------------------------------------') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "drifter_cells = ensemble.getDrifterCells()\n",
    "\n",
    "for minute in range(5):\n",
    "    obstime += 60\n",
    "    ensemble.stepToObservation(obstime, model_error_final_step=(minute<4))\n",
    "\n",
    "    if minute == 4:\n",
    "        iewpf.iewpf_2stage(ensemble, perform_step=False)\n",
    "\n",
    "    ensemble.registerStateSample(drifter_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-By-Step EnKF in Square Root Formulation"
   ]
  },
  {
   "source": [
    "## Calculate $S = H X'_f$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "HX_f = ensemble.observeParticles()\n",
    "\n",
    "HX_f_mean = np.zeros_like(ensemble.observeParticles()[0,:,:])\n",
    "for i in range(ensemble_size):\n",
    "    HX_f_mean = 1/ensemble_size * ensemble.observeParticles()[i,:,:]\n",
    "\n",
    "HX_f_pert = HX_f - HX_f_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $SS^\\top = HPH^\\top$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "HX_f_pert_matrix = np.zeros((2*len(drifterSet),ensemble_size))\n",
    "for i in range(ensemble_size):\n",
    "    for j in range(len(drifterSet)):\n",
    "        HX_f_pert_matrix[2*j,i] = HX_f_pert[i,j,0]\n",
    "        HX_f_pert_matrix[2*j+1,i] = HX_f_pert[i,j,1]\n",
    "\n",
    "HPHT = 1/(ensemble_size-1) * np.dot(HX_f_pert_matrix,HX_f_pert_matrix.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $F = HPH^\\top + R$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 5 * np.eye(2*len(drifterSet))\n",
    "F = HPHT + R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Innovation $D = Y - HX_f$ \n",
    "## and perturb $D=D+Y'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "innovation = ensemble.getInnovations()[:,:,:]\n",
    "\n",
    "innovation_matrix = np.zeros((2*len(drifterSet),ensemble_size))\n",
    "for i in range(ensemble_size):\n",
    "    for j in range(len(drifterSet)):\n",
    "        innovation_matrix[2*j,i] = innovation[i,j,0]\n",
    "        innovation_matrix[2*j+1,i] = innovation[i,j,1]\n",
    "\n",
    "Y_pert = np.random.multivariate_normal(np.zeros(2*len(drifterSet)),R ,10).T\n",
    "\n",
    "D = innovation_matrix + Y_pert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $C = F^{-1}D$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finv = np.linalg.inv(F)\n",
    "C = np.dot(Finv,D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $E=S^\\top C$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.dot(HPHT.T,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $X'_f = X_f - \\overline{X_f}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_mean = np.zeros((ensemble.particles[0].ny,ensemble.particles[0].nx))\n",
    "hu_mean  = np.zeros((ensemble.particles[0].ny,ensemble.particles[0].nx))\n",
    "hv_mean  = np.zeros((ensemble.particles[0].ny,ensemble.particles[0].nx))\n",
    "for i in range(ensemble_size):\n",
    "    eta, hu, hv = ensemble.particles[i].download(interior_domain_only=True)\n",
    "    eta_mean += 1/ensemble_size * eta\n",
    "    hu_mean  += 1/ensemble_size * hu\n",
    "    hv_mean  += 1/ensemble_size * hv\n",
    "\n",
    "eta_pert = np.zeros((ensemble_size,ensemble.particles[0].ny,ensemble.particles[0].nx))\n",
    "hu_pert  = np.zeros((ensemble_size,ensemble.particles[0].ny,ensemble.particles[0].nx))\n",
    "hv_pert  = np.zeros((ensemble_size,ensemble.particles[0].ny,ensemble.particles[0].nx))\n",
    "\n",
    "for i in range(ensemble_size):\n",
    "    eta, hu, hv = ensemble.particles[i].download(interior_domain_only=True)\n",
    "    eta_pert[i,:,:] = eta - eta_mean\n",
    "    hu_pert [i,:,:] = hu  - hu_mean\n",
    "    hv_pert [i,:,:] = hv  - hv_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f_pert = np.zeros((3*ensemble.particles[0].ny*ensemble.particles[0].nx, ensemble_size))\n",
    "\n",
    "for i in range(ensemble_size):\n",
    "    for x in range(ensemble.particles[0].nx):\n",
    "        for y in range(ensemble.particles[0].ny):\n",
    "            idx = x*3*ensemble.particles[0].nx + y*3\n",
    "            print(\"x = \", x, \", y  = \", y, \", idx = \", idx)\n",
    "            X_f_pert[idx+0, i] = 0#eta_pert[i,y,x]\n",
    "            X_f_pert[idx+1, i] = 0#hu_pert[i,y,x]\n",
    "            X_f_pert[idx+2, i] = 0#hv_pert[i,y,x]\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3*300*300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit ('gpuocean': conda)",
   "metadata": {
    "interpreter": {
     "hash": "33ed7ca3d490b1455ef8763b7de4f413d7a0b0dcbe44e1e5f95f5e2fe69a0829"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}