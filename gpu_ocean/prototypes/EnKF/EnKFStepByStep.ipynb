{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "This software is part of GPU Ocean. \n",
    "Copyright (C) 2019 SINTEF Digital\n",
    "\n",
    "This python program is used to set up and run a data-assimilation \n",
    "and drift trajectory forecasting experiment.\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import sys, os, json, datetime, time, shutil\n",
    "import numpy as np\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "if os.path.isdir(os.path.abspath(os.path.join(current_dir, '../../SWESimulators'))):\n",
    "        sys.path.insert(0, os.path.abspath(os.path.join(current_dir, '../../')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------\n",
    "# PARAMETERS\n",
    "#--------------------------------------------------------------\n",
    "ensemble_size = 10\n",
    "method = \"iewpf2\"\n",
    "observation_interval = 1\n",
    "observation_variance = 1.0\n",
    "observation_type = \"drifters\"\n",
    "buoy_area = \"all\"\n",
    "media_dir = \"forecasting_results/\"\n",
    "\n",
    "num_days = 7\n",
    "num_hours = 24\n",
    "forecast_days = 3\n",
    "profiling = \"store_true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input arguments:\n\nPath to initial conditions for ensemble:\n\tC:/Users/florianb/Documents/GPU-Ocean/data/ensemble_init/\nPath to true state:\n\tC:/Users/florianb/Documents/GPU-Ocean/data/true_state/\ndestination folder:\n\tforecasting_results/da_experiment_2020_11_19-16_09_04/\nPath to particle info:\n\tforecasting_results/da_experiment_2020_11_19-16_09_04/particle_info_\nPath to forecast members:\n\tforecasting_results/da_experiment_2020_11_19-16_09_04/forecast_member_\n ----> Using IEWPF 2 stage method\n"
     ]
    }
   ],
   "source": [
    "###-----------------------------------------\n",
    "## Define files for ensemble and truth.\n",
    "##\n",
    "ensemble_init_path = 'C:/Users/florianb/Documents/GPU-Ocean/data/ensemble_init/'\n",
    "assert len(os.listdir(ensemble_init_path)) == 100 or len(os.listdir(ensemble_init_path)) == 101, \\\n",
    "    \"Ensemble init folder has wrong number of files: \" + str(len(os.listdir(ensemble_init_path)))\n",
    "\n",
    "truth_path = 'C:/Users/florianb/Documents/GPU-Ocean/data/true_state/'\n",
    "assert len(os.listdir(truth_path)) == 2 or len(os.listdir(truth_path)) == 3, \\\n",
    "    \"Truth folder has wrong number of files\"\n",
    "\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "destination_dir = os.path.join(media_dir, \"da_experiment_\" +  timestamp + \"/\")\n",
    "os.makedirs(destination_dir)\n",
    "\n",
    "# Copy the truth into the destination folder\n",
    "shutil.copytree(truth_path, os.path.join(destination_dir, 'truth'))\n",
    "\n",
    "# Define misc filenames\n",
    "log_file = os.path.join(destination_dir, 'description.txt')\n",
    "\n",
    "particleInfoPrefix = os.path.join(destination_dir, 'particle_info_')\n",
    "forecastFileBase = os.path.join(destination_dir, 'forecast_member_')\n",
    "\n",
    "\n",
    "with open(log_file, 'w') as f:\n",
    "    f.write('Data Assimilation experiment ' + timestamp + '\\n')\n",
    "    f.write('----------------------------------------------' + '\\n')\n",
    "\n",
    "def logParams():\n",
    "    log('Input arguments:')\n",
    "    #for arg in vars(args):\n",
    "    #    log('\\t' + str((arg, getattr(args, arg))))\n",
    "    log('\\nPath to initial conditions for ensemble:')\n",
    "    log('\\t' + ensemble_init_path)\n",
    "    log('Path to true state:')\n",
    "    log('\\t' + truth_path)\n",
    "    log('destination folder:')\n",
    "    log('\\t' + destination_dir)\n",
    "    log('Path to particle info:')\n",
    "    log('\\t' + particleInfoPrefix)\n",
    "    log('Path to forecast members:')\n",
    "    log('\\t' + forecastFileBase)\n",
    "\n",
    "def log(msg, screen=True):\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(msg + '\\n')\n",
    "    if screen:\n",
    "        print(msg)\n",
    "        \n",
    "logParams()\n",
    "        \n",
    "    \n",
    "# Reading and checking method\n",
    "method = str(method).lower()\n",
    "if method == 'iewpf2':\n",
    "    log(' ----> Using IEWPF 2 stage method')\n",
    "elif method == 'none':\n",
    "    log(' ----> No data assimilation')\n",
    "else:\n",
    "    log('Illegal method: ' + str(method))\n",
    "    sys.exit(-1)\n",
    "    \n",
    "    \n",
    "# Time parameters\n",
    "start_time      =  3*24*60*60 #  3 days\n",
    "simulation_time = 10*24*60*60 # 10 days (three days spin up is prior to this)fa\n",
    "end_time        = 13*24*60*60 # 13 days\n",
    "\n",
    "\n",
    "# Based on truth from June 25th 2019\n",
    "#drifterSet = [ 2, 7, 12, 24, 29, 35, 41, 48, 53, 60]\n",
    "drifterSet = [ 2, 24, 60]\n",
    "\n",
    "# Log extra information for the ensemble state for the following cells:\n",
    "extraCells = np.array([[254, 241], # Cross with two trajectories\n",
    "                       [249, 246], # northwest of above\n",
    "                       [259, 236], # southeast of above\n",
    "                       [343, 131], # Closed circle of same drifter\n",
    "                       [196,  245], # Middle of single trajectory\n",
    "                       [150,  250], # Middle of single trajectory, later than above\n",
    "                       [102, 252], # On the same trajectory as the above, but later, and also in a intersection\n",
    "                       [ 388, 100], # Unobserved area just north of southern jet\n",
    "                       [ 388, 80],  # Unobserved area in southern jet\n",
    "                       [ 388, 150], # Unobserved area in calm area\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n1.0712 s: GPU Ocean packages imported\n0.1116 s: Created context on Quadro T2000\n"
     ]
    }
   ],
   "source": [
    "###--------------------------------\n",
    "# Import required packages\n",
    "#\n",
    "tic = time.time()\n",
    "# For GPU contex:\n",
    "from SWESimulators import Common\n",
    "# For the ensemble:\n",
    "from SWESimulators import EnsembleFromFiles, Observation\n",
    "# For data assimilation:\n",
    "from SWESimulators import IEWPFOcean\n",
    "# For forcasting:\n",
    "from SWESimulators import GPUDrifterCollection\n",
    "# For ObservationType:\n",
    "from SWESimulators import DataAssimilationUtils as dautils\n",
    "\n",
    "toc = time.time()\n",
    "log(\"\\n{:02.4f} s: \".format(toc-tic) + 'GPU Ocean packages imported', True)\n",
    "\n",
    "# Create CUDA context\n",
    "tic = time.time()\n",
    "gpu_ctx = Common.CUDAContext()\n",
    "device_name = gpu_ctx.cuda_device.name()\n",
    "toc = time.time()\n",
    "log(\"{:02.4f} s: \".format(toc-tic) + \"Created context on \" + device_name, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###--------------------------\n",
    "# Initiate the ensemble\n",
    "#\n",
    "\n",
    "observation_type = dautils.ObservationType.UnderlyingFlow\n",
    "if observation_type == 'buoys':\n",
    "    observation_type = dautils.ObservationType.StaticBuoys\n",
    "    log('Observation type changed to StaticBuoys!')\n",
    "elif observation_type == 'all_drifters':\n",
    "    drifterSet = 'all'\n",
    "    log('Using all drifters for DA experiment')\n",
    "\n",
    "    \n",
    "cont_write_netcdf = True and not profiling\n",
    "\n",
    "tic = time.time()\n",
    "ensemble = EnsembleFromFiles.EnsembleFromFiles(gpu_ctx, ensemble_size, \\\n",
    "                                               ensemble_init_path, truth_path, \\\n",
    "                                               observation_variance,\n",
    "                                               cont_write_netcdf = cont_write_netcdf,\n",
    "                                               use_lcg = True,\n",
    "                                               write_netcdf_directory = destination_dir,\n",
    "                                               observation_type=observation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.2629 s: Ensemble is loaded and created\nUsing drifterSet:\n[2, 24, 60]\n"
     ]
    }
   ],
   "source": [
    "# Configure observations according to the selected drifters:\n",
    "ensemble.configureObservations(drifterSet=drifterSet, \n",
    "                               observationInterval = observation_interval,\n",
    "                               buoy_area = buoy_area)\n",
    "ensemble.configureParticleInfos(extraCells)\n",
    "toc = time.time()\n",
    "log(\"{:02.4f} s: \".format(toc-tic) + \"Ensemble is loaded and created\", True)\n",
    "log(\"Using drifterSet:\\n\" + str(drifterSet))\n",
    "if observation_type == 'buoys':\n",
    "    log('buoys to read:')\n",
    "    log(str(ensemble.observations.read_buoy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0416 s: Data assimilation class initiated\n"
     ]
    }
   ],
   "source": [
    "### -------------------------------\n",
    "# Initialize IEWPF class (if needed)\n",
    "#\n",
    "tic = time.time()\n",
    "iewpf = None\n",
    "if method.startswith('iewpf'):\n",
    "    iewpf = IEWPFOcean.IEWPFOcean(ensemble)\n",
    "    toc = time.time()\n",
    "    log(\"{:02.4f} s: \".format(toc-tic) + \"Data assimilation class initiated\", True)\n",
    "else:\n",
    "    toc = time.time()\n",
    "    log(\"{:02.4f} s: \".format(toc-tic) + \"Skipping creation of IEWPF as the method is not used\", True)\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------- Starting simulation --------------\n--- numDays:       7\n--- numHours:      24\n--- forecast_days: 3\n---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### ----------------------------------------------\n",
    "#   DATA ASSIMILATION\n",
    "#\n",
    "\n",
    "obstime = 3*24*60*60\n",
    "\n",
    "master_tic = time.time()\n",
    "\n",
    "numDays = num_days \n",
    "numHours = num_hours \n",
    "forecast_days = forecast_days\n",
    "\n",
    "\n",
    "log('---------- Starting simulation --------------') \n",
    "log('--- numDays:       ' + str(numDays))\n",
    "log('--- numHours:      ' + str(numHours))\n",
    "log('--- forecast_days: ' + str(forecast_days))\n",
    "log('---------------------------------------------') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "drifter_cells = ensemble.getDrifterCells()\n",
    "\n",
    "for minute in range(5):\n",
    "    obstime += 60\n",
    "    ensemble.stepToObservation(obstime, model_error_final_step=(minute<4))\n",
    "\n",
    "    if minute == 4:\n",
    "        iewpf.iewpf_2stage(ensemble, perform_step=False)\n",
    "\n",
    "    ensemble.registerStateSample(drifter_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-By-Step EnKF in Square Root Formulation"
   ]
  },
  {
   "source": [
    "## Calculate $S = H X'_f$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Particles are observed in the following form:\n",
    "[\n",
    "particle 1:  [hu_1, hv_1], ... , [hu_D, hv_D],\n",
    "...\n",
    "particle Ne: [hu_1, hv_1], ... , [hu_D, hv_D]\n",
    "]\n",
    "\n",
    "In order to bring it in accordance with later data structure we use the following format for the storage of the perturbation of the observation:\n",
    "[\n",
    "[hu_1 (particle 1), ..., hu_1 (particle Ne)],\n",
    "...\n",
    "[hu_D (particle 1), ..., hu_D (particle Ne)],\n",
    "[hv_1 (particle 1), ..., hv_1 (particle Ne)],\n",
    "...\n",
    "[hv_D (particle 1), ..., hv_D (particle Ne)],\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Number of observers\n",
    "n_D = len(drifterSet)\n",
    "\n",
    "# Observation \n",
    "HX_f_orig = ensemble.observeParticles()\n",
    "\n",
    "# Reshaping\n",
    "HX_f = np.zeros( (2*n_D, ensemble_size) )\n",
    "for e in range(ensemble_size):\n",
    "    for l in range(n_D):\n",
    "        HX_f[l,e]     = HX_f_orig[e,l,0]\n",
    "    for l in range(n_D):\n",
    "        HX_f[n_D+l,e] = HX_f_orig[e,l,1]\n",
    "\n",
    "HX_f_mean = np.zeros_like(HX_f)\n",
    "for e in range(ensemble_size):\n",
    "    HX_f_mean = 1/ensemble_size * HX_f[:,e]\n",
    "\n",
    "HX_f_pert = HX_f - HX_f_mean.reshape((2*n_D,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $SS^\\top = HPH^\\top$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HPHT = 1/(ensemble_size-1) * np.dot(HX_f_pert,HX_f_pert.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $F = HPH^\\top + R$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 5 * np.eye(2*len(drifterSet))\n",
    "F = HPHT + R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Innovation $D = Y - HX_f$ \n",
    "## and perturb $D=D+Y'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Particles yield innovations in the following form:\n",
    "[\n",
    "particle 1:  [hu_1, hv_1], ... , [hu_D, hv_D],\n",
    "...\n",
    "particle Ne: [hu_1, hv_1], ... , [hu_D, hv_D]\n",
    "]\n",
    "\n",
    "In order to bring it in accordance with later data structure we use the following format for the storage of the perturbation of the observation:\n",
    "[\n",
    "[d_hu_1 (particle 1), ..., d_hu_1 (particle Ne)],\n",
    "...\n",
    "[d_hu_D (particle 1), ..., d_hu_D (particle Ne)],\n",
    "[d_hv_1 (particle 1), ..., d_hv_1 (particle Ne)],\n",
    "...\n",
    "[d_hv_D (particle 1), ..., d_hv_D (particle Ne)],\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "innovation_orig = ensemble.getInnovations()[:,:,:]\n",
    "\n",
    "# Reshaping\n",
    "innovation = np.zeros( (2*n_D, ensemble_size) )\n",
    "for e in range(ensemble_size):\n",
    "    for l in range(n_D):\n",
    "        innovation[l,e]     = innovation_orig[e,l,0]\n",
    "    for l in range(n_D):\n",
    "        innovation[n_D+l,e] = innovation_orig[e,l,1]\n",
    "\n",
    "Y_pert = np.random.multivariate_normal(np.zeros(2*len(drifterSet)),R ,10).T\n",
    "\n",
    "D = innovation + Y_pert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $C = F^{-1}D$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Finv = np.linalg.inv(F)\n",
    "C = np.dot(Finv,D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $E=S^\\top C$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.dot(HX_f_pert.T,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate $X'_f = X_f - \\overline{X_f}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The download gives eta = \n",
    "[\n",
    "[eta(x0,y0),...,eta(xN,y0)],\n",
    "...,\n",
    "[eta(x0,yN),...,eta(xN,yN)]\n",
    "]\n",
    "as an array of size Ny x Nx\n",
    "and analog for hu and hv.\n",
    "we use those as an 1D array eta = \n",
    "[eta(x0,y0),...,eta(xN,y0),eta(x0,y1),...,eta(xN,y(N-1)),eta(x0,yN),...,eta(xN,yN)]\n",
    "and anlog for hu and hv \n",
    "\n",
    "For further calculations the indivdual dimensions of the state variable are concatinated X = \n",
    "[eta, hu, hv]\n",
    "\n",
    "Collecting the state perturbation for each ensemble member in a matrix Nx x Ne, where\n",
    "X_f_pert = \n",
    "[ \n",
    "[eta_pert(x0,y0) (particle 1),..., eta_pert],\n",
    "...\n",
    "particle 2: [eta_pert,hu_pert,hv_pert]\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "# Ghost cells added \n",
    "n_i = ensemble.particles[0].ny + 4 \n",
    "n_j = ensemble.particles[0].nx + 4\n",
    "\n",
    "X_f = np.zeros((3*n_i*n_j, ensemble_size))\n",
    "for e in range(ensemble_size):\n",
    "    eta, hu, hv = ensemble.particles[e].download(interior_domain_only=False)\n",
    "    eta = eta.reshape(n_i*n_j)\n",
    "    hu  = hu.reshape(n_i*n_j)\n",
    "    hv  = hv.reshape(n_i*n_j)\n",
    "    X_f[:,e] = np.append(eta, np.append(hu,hv))\n",
    "\n",
    "X_f_mean = np.zeros( 3*n_i*n_j )\n",
    "for e in range(ensemble_size):\n",
    "    X_f_mean += 1/ensemble_size * X_f[:,e]\n",
    "\n",
    "X_f_pert = np.zeros_like( X_f )\n",
    "for e in range(ensemble_size):\n",
    "    X_f_pert[:,e] = X_f[:,e] - X_f_mean\n",
    " "
   ]
  },
  {
   "source": [
    "## Calculate $X_a$\n"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a = X_f + 1/(ensemble_size-1) * np.dot(X_f_pert,E)"
   ]
  },
  {
   "source": [
    "## Reshape and upload analysis state"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(ensemble_size):\n",
    "    eta = X_a[0:n_i*n_j, e].reshape((n_i,n_j))\n",
    "    hu  = X_a[n_i*n_j:2*n_i*n_j, e].reshape((n_i,n_j))\n",
    "    hv  = X_a[2*n_i*n_j:3*n_i*n_j, e].reshape((n_i,n_j))\n",
    "    ensemble.particles[e].upload(eta,hu,hv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit ('gpuocean': conda)",
   "metadata": {
    "interpreter": {
     "hash": "33ed7ca3d490b1455ef8763b7de4f413d7a0b0dcbe44e1e5f95f5e2fe69a0829"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}