{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "This software is a part of GPU Ocean.\n",
    "\n",
    "Copyright (C) 2019  SINTEF Digital\n",
    "\n",
    "This notebook reads the data from the rank histogram experiments and\n",
    "creates the rank histogram.\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank histogram\n",
    "\n",
    "\n",
    "This notebook reads the data from the rank histogram experiments and\n",
    "creates the rank histogram.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "from importlib import reload\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../')))\n",
    "\n",
    "#Set large figure sizes\n",
    "rc('figure', figsize=(16.0, 12.0))\n",
    "rc('animation', html='html5')\n",
    "\n",
    "#Import our simulator\n",
    "from SWESimulators import IPythonMagic, SimReader, Observation\n",
    "from SWESimulators import DoubleJetCase\n",
    "from SWESimulators import DataAssimilationUtils as dautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cuda_context_handler gpu_ctx\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow3(eta, hu, hv, interpolation=\"None\", title=None, figsize=(12,3), interior=False):\n",
    "    fig, axs = plt.subplots(1,3, figsize=figsize)\n",
    "        \n",
    "    range_eta = np.max(np.abs(eta))\n",
    "    range_huv = max(np.max(np.abs(hu)), np.max(np.abs(hv)))\n",
    "    \n",
    "    eta_im = axs[0].imshow(eta, interpolation=interpolation, origin='lower', vmin=-range_eta, vmax=range_eta)\n",
    "    axs[0].set_title(\"$\\eta$\")\n",
    "    plt.colorbar(eta_im, ax=axs[0])\n",
    "    \n",
    "    if interior:\n",
    "        hu_im = axs[1].imshow(hu[2:-2,2:-2], interpolation=interpolation, origin='lower', vmin=-range_huv, vmax=range_huv)\n",
    "    else:\n",
    "        hu_im = axs[1].imshow(hu, interpolation=interpolation, origin='lower', vmin=-range_huv, vmax=range_huv)\n",
    "    axs[1].set_title(\"$hu$\")\n",
    "    plt.colorbar(hu_im, ax=axs[1])\n",
    "\n",
    "    if interior:\n",
    "        hv_im = axs[2].imshow(hv[2:-2,2:-2], interpolation=interpolation, origin='lower', vmin=-range_huv, vmax=range_huv)\n",
    "    else:\n",
    "        hv_im = axs[2].imshow(hv, interpolation=interpolation, origin='lower', vmin=-range_huv, vmax=range_huv)\n",
    "    axs[2].set_title(\"$hv$\")\n",
    "    plt.colorbar(hv_im, ax=axs[2])\n",
    "\n",
    "    if title is not None:\n",
    "        plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def plotDrifters(observations, sim_reader, t, ax=None):\n",
    "    drifter_positions = observations.get_drifter_position(t)\n",
    "\n",
    "    nx, ny = sim_reader.get('nx'), sim_reader.get('ny')\n",
    "    dx, dy = sim_reader.get('dx'), sim_reader.get('dy')\n",
    "\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "        ax = plt.subplot(111)\n",
    "        emptyData =np.ma.masked_where(np.zeros((ny,nx)) > 1, np.zeros((ny,nx)))\n",
    "        ax.imshow(emptyData, origin=\"lower\", extent=[0, nx*dx, 0, ny*dy], cmap='binary')\n",
    "\n",
    "    for i in range(drifter_positions.shape[0]):\n",
    "        color = 'xkcd:tomato red'\n",
    "        circ_end = matplotlib.patches.Circle((drifter_positions[i,0], drifter_positions[i,1]),\n",
    "                                             3000, fill=True, zorder=10, color=color)\n",
    "        ax.add_patch(circ_end)\n",
    "\n",
    "    \n",
    "def days_to_sec(days):\n",
    "    return days*24*60*60\n",
    "\n",
    "def truth_time_step(t):\n",
    "    t = t - days_to_sec(3)\n",
    "    return int(t/(60*60))\n",
    "\n",
    "def file_filter(path_to_dir, ext=None, prefix=None, abspath=True):\n",
    "    filtered_files = os.listdir(path_to_dir)\n",
    "    if prefix:\n",
    "        filtered_files = list(file for file in filtered_files if file.startswith(prefix))\n",
    "    if ext:\n",
    "        filtered_files = list(file for file in filtered_files if file.endswith(ext))\n",
    "    if abspath:\n",
    "        filtered_files= list(os.path.join(path_to_dir, file)  for file in filtered_files)\n",
    "\n",
    "    filtered_files.sort()\n",
    "    return filtered_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the truth\n",
    "\n",
    "Loading the truth to see which parts of the domain that can be relevant. \n",
    "\n",
    "We use buoys in order to assimilate the same data points for each round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_path = os.path.abspath('scripts/truth_2019_06_06-09_23_41/')\n",
    "assert len(os.listdir(truth_path)) == 4, \"Truth folder has wrong number of files\"\n",
    "\n",
    "media_dir = '/media/havahol/Seagate Backup Plus Drive/gpu_ocean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_state_filename = os.path.join(truth_path, \"double_jet_case_truth.nc\")\n",
    "observations_filename = os.path.join(truth_path, \"drifter_observations.pickle\")\n",
    "\n",
    "truth_reader = SimReader.SimNetCDFReader(truth_state_filename)\n",
    "\n",
    "observation_type = dautils.ObservationType.StaticBuoys\n",
    "nx = truth_reader.get('nx')\n",
    "ny = truth_reader.get('ny')\n",
    "dx = truth_reader.get('dx')\n",
    "dy = truth_reader.get('dy')\n",
    "domain_size_x = nx*dx\n",
    "domain_size_y = ny*dy\n",
    "\n",
    "observations = Observation.Observation(observation_type=observation_type,\n",
    "                                       domain_size_x=domain_size_x, domain_size_y=domain_size_y,\n",
    "                                       nx=nx, ny=ny)\n",
    "observations.read_pickle(observations_filename)\n",
    "observations.setBuoyReadingArea('west')\n",
    "\n",
    "x_index = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files\n",
    "#rank_histogram_paths = [\n",
    "#    os.path.join(media_dir, 'june_truth/rank_histogram_1_hour/rank_histogram_experiments_2019_06_06-16_40_27/')\n",
    "#]\n",
    "\n",
    "#dataset = 'june_truth/rank_histogram_72_hour/'\n",
    "#dataset = 'june_truth/rank_histogram_forecast_6_1_hour/'\n",
    "#dataset = 'june_truth/rank_histogram_curand_forecast_6_1_hour/'\n",
    "dataset = 'unique_truths/rank_histogram_tests/'\n",
    "dataset_path = os.path.join(media_dir, dataset)\n",
    "\n",
    "fig_path = os.path.join(dataset_path, 'figures_' + timestamp)\n",
    "if not os.path.exists(fig_path):\n",
    "    os.mkdir(fig_path)\n",
    "    print('created figure folder')\n",
    "    print(fig_path)\n",
    "\n",
    "rank_histogram_time = 6\n",
    "\n",
    "rank_histogram_paths = list(os.path.join(dataset_path, path) for path in os.listdir(dataset_path))\n",
    "print(rank_histogram_paths)\n",
    "\n",
    "rank_histogram_files = []\n",
    "for path in rank_histogram_paths:\n",
    "    rank_histogram_files.extend(file_filter(path, \n",
    "                                            ext='npz', \n",
    "                                            prefix='hour_' + str(rank_histogram_time).zfill(3)))\n",
    "\n",
    "print(len(rank_histogram_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the first obtained values\n",
    "first_experiment = np.load(rank_histogram_files[0])\n",
    "t_rank = float(first_experiment['t'])\n",
    "print(t_rank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_rank_index = truth_time_step(t_rank)\n",
    "eta_rank, hu_rank, hv_rank, t = truth_reader.getTimeStep(t_rank_index)\n",
    "print(t, t_rank_index)\n",
    "imshow3(eta_rank, hu_rank, hv_rank, title='State at rank histogram time')\n",
    "\n",
    "buoy_cell_indices = observations.buoy_indices[observations.read_buoy, :]\n",
    "print(buoy_cell_indices.shape)\n",
    "\n",
    "buoy_y = np.zeros(12)\n",
    "buoy_x = 100\n",
    "bouy_y_map = [False]*ny\n",
    "\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax.imshow(hu_rank, origin=\"lower\", extent=[0, nx, 0, ny])\n",
    "\n",
    "buoy_index = 0\n",
    "for i in range(buoy_cell_indices.shape[0]):\n",
    "    color = 'xkcd:tomato red'\n",
    "    if buoy_cell_indices[i,0] == buoy_x:\n",
    "        print(buoy_cell_indices[i,:])\n",
    "        color = 'xkcd:white'\n",
    "        buoy_y[buoy_index] = buoy_cell_indices[i,1]\n",
    "        buoy_index += 1\n",
    "        bouy_y_map[buoy_cell_indices[i,1]] = True\n",
    "    circ_end = matplotlib.patches.Circle((buoy_cell_indices[i,0], buoy_cell_indices[i,1]),\n",
    "                                         2, fill=True, zorder=10, color=color)\n",
    "    ax.add_patch(circ_end)\n",
    "    \n",
    "    \n",
    "plt.title('at rank hist time, with buoys')\n",
    "plt.savefig(os.path.join(fig_path, 'truth_with_buoys.png'))\n",
    "plt.savefig(os.path.join(fig_path, 'truth_with_buoys.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "observed_values = observations.get_observation(t_rank, None)\n",
    "\n",
    "rounded_t = round(t_rank)\n",
    "t_rank_index_obs = observations.obs_df[observations.obs_df[observations.columns[0]]==rounded_t].index.values[0]\n",
    "\n",
    "print(rounded_t)\n",
    "print('type of observations.buoy_indices: ', observations.buoy_indices.dtype)\n",
    "\n",
    "print('direct positions (type ' + str(observations.buoy_positions.copy()[observations.read_buoy, :].dtype) + ')')\n",
    "#print(observations.buoy_positions.copy()[observations.read_buoy, :])\n",
    "#print('direct hu hv:')\n",
    "#print(observations.obs_df.iloc[index][observations.columns[2]][observations.read_buoy, :])\n",
    "\n",
    "eta_rank, hu_rank, hv_rank, t = truth_reader.getTimeStep(t_rank_index)\n",
    "print(t, t_rank_index)\n",
    "eta_true = eta_rank[:, buoy_x]\n",
    "hu_true = hu_rank[:, buoy_x]\n",
    "hv_true = hv_rank[:, buoy_x]\n",
    "\n",
    "if 'true_hu' in first_experiment.files:\n",
    "    eta_true = first_experiment['true_eta']\n",
    "    hu_true = first_experiment['true_hu']\n",
    "    hv_true = first_experiment['true_hv']\n",
    "\n",
    "print(observed_values.shape)\n",
    "print(observed_values[4::10, 2])\n",
    "print(observed_values[4::10, 2]-hu_rank[bouy_y_map, buoy_x])\n",
    "\n",
    "# Plotting the cross section at the chosen buoy locations:\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12,12))\n",
    "\n",
    "\n",
    "axs[0].plot(np.arange(ny), hu_true, 'k', zorder=10)\n",
    "first_hu = first_experiment['hu']\n",
    "for p in range(first_hu.shape[1]):\n",
    "    axs[0].plot(np.arange(ny), first_hu[:,p], color='xkcd:light blue', alpha=0.2)\n",
    "axs[0].plot(buoy_y, hu_true[bouy_y_map], 'r*')\n",
    "axs[0].set_title('ensemble for eta at x_100')\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "first_hv = first_experiment['hv']\n",
    "for p in range(first_hu.shape[1]):\n",
    "    axs[1].plot(np.arange(ny), first_hv[:,p], color='xkcd:light blue', alpha=0.2)\n",
    "axs[1].plot(np.arange(ny), hv_true, 'k')\n",
    "axs[1].plot(buoy_y, hv_true[bouy_y_map], 'r*')\n",
    "axs[1].set_title('ensemble for hv at x_100')\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "first_eta = first_experiment['eta']\n",
    "for p in range(first_hu.shape[1]):\n",
    "    axs[2].plot(np.arange(ny), first_eta[:,p], color='xkcd:light blue', alpha=0.2)\n",
    "axs[2].plot(np.arange(ny), eta_true, 'k')\n",
    "axs[2].plot(buoy_y, eta_true[bouy_y_map], 'r*')\n",
    "axs[2].set_title('ensemble for eta at x_100')\n",
    "\n",
    "plt.savefig(os.path.join(fig_path, 'ensemble_cross_section_x_100.png'))\n",
    "plt.savefig(os.path.join(fig_path, 'ensemble_cross_section_x_100.pdf'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank histogram experiment\n",
    "\n",
    "Rank histograms are an established way to test the quality of data assimilation methods (see reference Hamill 2001 from Skauvold et al). Our rank histogram experiment is based on the buoy experiment in which we observe the western half of the domain with $R = \\mathrm{diag}(1)$ and assimilation windows of five minutes.  The ensemble size is sat to $N_e = 40$. For each experiment we store the cross section at $x = 100.5 \\Delta x$ (center of the 100'the cell in $x$-direction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def rankhistogram(dataset_path, hour, truth_reader, interesting_y_indices, perturb=True):\n",
    "    \n",
    "\n",
    "    rank_histogram_paths = list(os.path.join(dataset_path, path) for path in os.listdir(dataset_path))\n",
    "    #print(rank_histogram_paths)\n",
    "\n",
    "    rank_histogram_files = []\n",
    "    for path in rank_histogram_paths:\n",
    "        rank_histogram_files.extend(file_filter(path, \n",
    "                                                ext='npz', \n",
    "                                                prefix='hour_' + str(hour).zfill(3)))\n",
    "\n",
    "    print('Creating rank histogram from ' + str(len(rank_histogram_files)) + ' files')\n",
    "    \n",
    "    # Time in seconds is read from first file\n",
    "    first_experiment = np.load(rank_histogram_files[0])\n",
    "    t_rank = float(first_experiment['t'])\n",
    "    \n",
    "    # Index in the truth corresponding to the provided time\n",
    "    t_rank_index = truth_time_step(t_rank)\n",
    "    \n",
    "    \n",
    "    num_rank_experiments = len(rank_histogram_files)\n",
    "    Ne = 40\n",
    "    buoy_x = 100 # Index of buoy\n",
    "\n",
    "    true_eta, true_hu, true_hv, true_t = truth_reader.getTimeStep(t_rank_index)\n",
    "    ny = truth_reader.get('ny')\n",
    "\n",
    "    buckets_hu  = np.zeros((ny, Ne+1))\n",
    "    buckets_hv  = np.zeros((ny, Ne+1))\n",
    "    buckets_eta = np.zeros((ny, Ne+1))\n",
    "\n",
    "    interesting_y_indices = interesting_y_indices.astype(np.int32) # [0, 25, 50, 70, 75, 80, 100, 125, 150, 175]\n",
    "    \n",
    "    common_true_eta = true_eta[:,buoy_x]\n",
    "    common_true_hu  = true_hu[:, buoy_x]\n",
    "    common_true_hv  = true_hv[:, buoy_x]\n",
    "\n",
    "    exp_no = 0\n",
    "    for file in rank_histogram_files:\n",
    "        result = np.load(file)\n",
    "        eta = result['eta'] \n",
    "        hu  = result['hu']\n",
    "        hv  = result['hv'] \n",
    "        t = result['t']\n",
    "        assert(true_t == t)\n",
    "        \n",
    "        true_eta, true_hu, true_hv = None, None, None\n",
    "        if 'true_eta' in result.files:\n",
    "            true_eta = result['true_eta']\n",
    "            true_hu  = result['true_hu']\n",
    "            true_hv  = result['true_hv']\n",
    "        else:\n",
    "            true_eta = common_true_eta\n",
    "            true_hu  = common_true_hu\n",
    "            true_hv  = common_true_hv\n",
    "\n",
    "        for y in interesting_y_indices:\n",
    "            if perturb:\n",
    "                ensemble_hu  = hu[y, :] + np.random.normal(scale=1, size=Ne)\n",
    "                ensemble_hv  = hv[y, :] + np.random.normal(scale=1, size=Ne)\n",
    "            else:\n",
    "                ensemble_hu  = hu[y, :] \n",
    "                ensemble_hv  = hv[y, :] \n",
    "            ensemble_eta = eta[y, :] \n",
    "\n",
    "            ensemble_hu.sort()\n",
    "            ensemble_hv.sort()\n",
    "            ensemble_eta.sort()\n",
    "\n",
    "            bucket_hu  = np.searchsorted(ensemble_hu, true_hu[y])\n",
    "            bucket_hv  = np.searchsorted(ensemble_hv, true_hv[y])\n",
    "            bucket_eta = np.searchsorted(ensemble_eta, true_eta[y])\n",
    "\n",
    "            buckets_hu[y, bucket_hu] += 1\n",
    "            buckets_hv[y, bucket_hv] += 1\n",
    "            buckets_eta[y, bucket_eta] += 1\n",
    "\n",
    "        if num_rank_experiments > 99:\n",
    "            if (exp_no % int(num_rank_experiments/100) == 0):\n",
    "                print('.'+str(exp_no)+'.', end='')\n",
    "        exp_no += 1\n",
    "\n",
    "    accumulated_eta = np.zeros_like(buckets_eta[0,:])\n",
    "    accumulated_hu  = np.zeros_like(buckets_hu[0,:])\n",
    "    accumulated_hv  = np.zeros_like(buckets_hv[0,:])\n",
    "    \n",
    "    # Plot results\n",
    "    for y in interesting_y_indices:\n",
    "        \n",
    "        accumulated_eta += buckets_eta[y,:]\n",
    "        accumulated_hu  += buckets_hu[y,:]\n",
    "        accumulated_hv  += buckets_hv[y,:]\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15,3))\n",
    "\n",
    "        axs[0].bar(np.arange(Ne+1), buckets_eta[y,:], width=1)\n",
    "        axs[0].set_title('eta at cell (100, '+str(y)+')')\n",
    "\n",
    "        axs[1].bar(np.arange(Ne+1), buckets_hu[y,:], width=1)\n",
    "        axs[1].set_title('hu at cell (100, '+str(y)+')')\n",
    "\n",
    "        axs[2].bar(np.arange(Ne+1), buckets_hv[y,:], width=1)\n",
    "        axs[2].set_title('hv at cell (100, '+str(y)+')')\n",
    "        \n",
    "        plt.suptitle('Rank histogram at time hour ' + str(hour), fontsize=15)\n",
    "        #plt.tight_layout()\n",
    "        fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "        filename = 'rank_histogram_y_'+str(y).zfill(3)+'_hour_'+str(hour).zfill(3)+'.pdf'\n",
    "        plt.savefig(os.path.join(fig_path, filename))\n",
    "        plt.savefig(os.path.join(fig_path, filename).replace('.pdf', '.png'))\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15,3))\n",
    "\n",
    "    axs[0].bar(np.arange(Ne+1), accumulated_eta, width=1)\n",
    "    axs[0].set_title('accumulated eta')\n",
    "\n",
    "    axs[1].bar(np.arange(Ne+1), accumulated_hu, width=1)\n",
    "    axs[1].set_title('accumulated hu')\n",
    "\n",
    "    axs[2].bar(np.arange(Ne+1), accumulated_hv, width=1)\n",
    "    axs[2].set_title('accumulated hv')\n",
    "\n",
    "    plt.suptitle('Accumulated rank histogram at time hour ' + str(hour), fontsize=15)\n",
    "    #plt.tight_layout()\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    str_interesting_y_indices= str(interesting_y_indices).replace('[  ','').replace(']','').replace('  ', ' ').replace(' ', '_')\n",
    "    filename = 'rank_histogram_accumulated_'+str_interesting_y_indices+'_hour_'+str(hour).zfill(3)+'.pdf'\n",
    "    plt.savefig(os.path.join(fig_path, filename))\n",
    "    plt.savefig(os.path.join(fig_path, filename).replace('.pdf', '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hour = 7\n",
    "#interesting_y_indices = np.array([0, 25, 50, 70, 75, 80, 100, 125, 150, 175])\n",
    "interesting_y_indices = np.array([0, 50, 100, 150, 200, 250])\n",
    "print(dataset_path)\n",
    "rankhistogram(dataset_path, hour, truth_reader, interesting_y_indices, perturb=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = 7\n",
    "interesting_y_indices = np.array([0, 37, 50])\n",
    "rankhistogram(dataset_path, hour, truth_reader, interesting_y_indices, perturb=True)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time development of rank histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "hours = np.array([1, 6, 12, 18, 24, 48, 72])\n",
    "y = np.array([200])\n",
    "\n",
    "for hour in hours:\n",
    "    rankhistogram(dataset_path, hour, truth_reader, y, perturb=False)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = np.arange(10)\n",
    "print(files)\n",
    "np.random.choice(files, size=7, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_directory = 'double_jet_ensemble_init/'\n",
    "ensemble_init_nc_files = list(os.path.join(ensemble_directory, file) for file in os.listdir(ensemble_directory) if file.endswith('.nc'))\n",
    "print(len(ensemble_init_nc_files))\n",
    "np.random.choice(ensemble_init_nc_files, size=10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npload = np.load(rank_histogram_files[0])\n",
    "print(npload.files)\n",
    "if 'true_hu' in npload.files:\n",
    "    print('hei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('time (in days) for 1000 rank histogram experiments')\n",
    "print('40 west buoys', 37.5*24*1000/(60*60*24))\n",
    "print('40 10-drifters', 19*24*1000/(60*60*24))\n",
    "print('25 west buoys', 23*24*1000/(60*60*24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "670 / 60, 37.5*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_24h = 670\n",
    "exp_48h = exp_24h*2\n",
    "\n",
    "num_days_100_exp_24 = exp_24h*100/(60*60*24)\n",
    "print(\"100 experiments at 24 hours: \", num_days_100_exp_24)\n",
    "\n",
    "\n",
    "time_until_monday_at_work = (8 + 24 + 24 + 24 + 8)*3600\n",
    "num_24_hour_experiments_until_monday = time_until_monday_at_work/exp_24h\n",
    "print('num_24_hour_experiments_until_monday', num_24_hour_experiments_until_monday)\n",
    "num_48_hour_experiments_until_monday = time_until_monday_at_work/exp_48h\n",
    "print('num_48_hour_experiments_until_monday', num_48_hour_experiments_until_monday)\n"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": false
  },
  "kernelspec": {
   "display_name": "Python [conda env:gpuocean]",
   "language": "python",
   "name": "conda-env-gpuocean-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
