{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "This software is a part of GPU Ocean.\n",
    "\n",
    "Copyright (C) 2019  SINTEF Digital\n",
    "\n",
    "Producing plots of data assimilation experiments by post-processing the\n",
    "files produced by scripts/run_experiment.py\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast Error evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "from importlib import reload\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../')))\n",
    "\n",
    "#Set large figure sizes\n",
    "rc('figure', figsize=(16.0, 12.0))\n",
    "rc('animation', html='html5')\n",
    "\n",
    "#Import our simulator\n",
    "from SWESimulators import IPythonMagic, SimReader, Observation, ParticleInfo\n",
    "from SWESimulators import DataAssimilationUtils as dautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cuda_context_handler gpu_ctx\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create output directory for images\n",
    "#imgdir = 'double_jet'\n",
    "#filename_prefix = imgdir + \"/\" + datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\") + \"_\"\n",
    "#os.makedirs(imgdir, exist_ok=True)\n",
    "#print(\"Saving images to \" + imgdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the folder containing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_dir = os.path.abspath('scripts/da_experiment_2019_05_06-14_35_19_IEWPF2s_success/')\n",
    "root_folder = os.path.abspath('/media/havahol/Seagate Backup Plus Drive/gpu_ocean/june_25_truth/all_forecasts_2019_06_25-13_13_46/')\n",
    "result_dirs = [os.path.join(root_folder, \\\n",
    "                            'da_experiment_2019_06_25-13_13_48-dry_run'),\n",
    "               os.path.join(root_folder, \\\n",
    "                            'da_experiment_2019_06_25-14_35_13-10drifters'),\n",
    "               os.path.join(root_folder, \\\n",
    "                             'da_experiment_2019_06_25-16_05_17-alldrifters'),\n",
    "               os.path.join(root_folder, \\\n",
    "                             'da_experiment_2019_06_25-17_59_44-all-buoys'),\n",
    "               os.path.join(root_folder, \\\n",
    "                             'da_experiment_2019_06_25-21_08_44-western_buoys'),\n",
    "               os.path.join(root_folder, \\\n",
    "                             'da_experiment_2019_06_25-23_25_47-southern_buoys')\n",
    "              ]\n",
    "print(result_dirs)\n",
    "\n",
    "labels = [\"No DA\",\n",
    "          \"Ten drifters\",\n",
    "          \"All drifters\",\n",
    "          \"All buoys\",\n",
    "          \"West buoys\",\n",
    "          \"South buoys\"         \n",
    "         ]\n",
    "\n",
    "\n",
    "#truth_folder = \"double_jet_truth\"\n",
    "truth_folder = os.path.join(result_dirs[0], \"truth\")\n",
    "\n",
    "drifterSet = [ 2,  7, 12, 24, 29, 35, 41, 48, 53, 60]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def file_filter(path_to_dir, ext=None, prefix=None, abspath=True):\n",
    "    filtered_files = os.listdir(path_to_dir)\n",
    "    if prefix:\n",
    "        filtered_files = list(file for file in filtered_files if file.startswith(prefix))\n",
    "    if ext:\n",
    "        filtered_files = list(file for file in filtered_files if file.endswith(ext))\n",
    "    if abspath:\n",
    "        filtered_files= list(os.path.join(path_to_dir, file)  for file in filtered_files)\n",
    "\n",
    "    filtered_files.sort()\n",
    "    return filtered_files\n",
    "\n",
    "\n",
    "nc_files = [None]*6\n",
    "obs_files = [None]*6\n",
    "particle_info_files = [None]*6\n",
    "\n",
    "for i in range(6):\n",
    "    nc_files[i] = file_filter(result_dirs[i], ext='nc')\n",
    "    obs_files[i] = file_filter(result_dirs[i], ext='bz2', prefix='forecast')\n",
    "    particle_info_files[i] = file_filter(result_dirs[i], ext='bz2', prefix='particle_info')\n",
    "    print(\"number of nc_files:            \", len(nc_files[i]))\n",
    "    print(\"number of obs_files:           \", len(obs_files[i]))\n",
    "    print(\"number of particle_info_files: \", len(particle_info_files[i]))\n",
    "\n",
    "if False:\n",
    "    print(len(nc_files), nc_files)\n",
    "    print()\n",
    "    print(len(obs_files), obs_files)\n",
    "    print()\n",
    "    print(len(particle_info_files), particle_info_files)\n",
    "    \n",
    "# Truth:\n",
    "true_nc = truth_folder + \"/double_jet_case_truth.nc\"\n",
    "true_obs_file = truth_folder + \"/drifter_observations.pickle\"\n",
    "    \n",
    "ensemble_size = len(nc_files)\n",
    "num_drifters=64\n",
    "\n",
    "drifterSet = [ 2,  7, 12, 24, 29, 35, 41, 48, 53, 60]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read netCDF files\n",
    "reload(SimReader)\n",
    "\n",
    "truth_reader = SimReader.SimNetCDFReader(true_nc)\n",
    "\n",
    "equilibrium_depth = truth_reader.getH()[0,0]\n",
    "nx = truth_reader.get('nx')\n",
    "ny = truth_reader.get('ny')\n",
    "domain_size_x = nx*truth_reader.get('dx')\n",
    "domain_size_y = ny*truth_reader.get('dy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(im, interpolation=\"None\", title=None, figsize=(4,4), interior=False):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    if interior:\n",
    "        im = plt.imshow(im[2:-2,2:-2], interpolation=interpolation, origin='lower')\n",
    "    else:\n",
    "        im = plt.imshow(im, interpolation=interpolation, origin='lower')\n",
    "    \n",
    "    plt.colorbar()\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "        \n",
    "def imshow3(eta, hu, hv, interpolation=\"None\", title=None, figsize=(14,2.8), \n",
    "            color_bar_from_zero=False, save_filename=None, constant_range=False):\n",
    "    \n",
    "    fig, axs = plt.subplots(1,3, figsize=figsize)\n",
    "    \n",
    "    eta_max = np.max(np.abs(eta))\n",
    "    huv_max = max(np.max(np.abs(hu)), np.max(np.abs(hv)))\n",
    "    \n",
    "    if constant_range:\n",
    "        eta_max = 3.5\n",
    "        huv_max = 600\n",
    "    \n",
    "    eta_min = -eta_max\n",
    "    huv_min = -huv_max\n",
    "    if color_bar_from_zero:\n",
    "        eta_min, huv_min = 0, 0\n",
    "        \n",
    "    nx = truth_reader.get('nx')\n",
    "    ny = truth_reader.get('ny')\n",
    "    dx = truth_reader.get('dx')\n",
    "    dy = truth_reader.get('dy')\n",
    "    extent=np.array([0, nx*dx, 0, ny*dy]) / 1000\n",
    "    \n",
    "    \n",
    "    eta_im = axs[0].imshow(eta, interpolation=interpolation, origin='lower', \n",
    "                           vmin=eta_min, vmax=eta_max, extent=extent)\n",
    "    axs[0].set_title(\"$\\eta$ [m]\")\n",
    "    cbar_eta = plt.colorbar(eta_im, ax=axs[0])\n",
    "    #cbar_eta.set_label('$\\eta$ [m]')#,size=18)\n",
    "    \n",
    "    hu_im = axs[1].imshow(hu, interpolation=interpolation, origin='lower', \n",
    "                          vmin=huv_min, vmax=huv_max, extent=extent)\n",
    "    axs[1].set_title(\"$hu$ [m$^2$/s]\")\n",
    "    plt.colorbar(hu_im, ax=axs[1])\n",
    "    \n",
    "    hv_im = axs[2].imshow(hv, interpolation=interpolation, origin='lower',\n",
    "                          vmin=huv_min, vmax=huv_max, extent=extent)\n",
    "    axs[2].set_title(\"$hv$ [m$^2$/s]\")\n",
    "    plt.colorbar(hv_im, ax=axs[2])\n",
    "    \n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"$x$ [km]\")\n",
    "        ax.set_ylabel(\"$y$ [km]\")\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.suptitle(title, y=1.0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_filename is not None:\n",
    "        fig.savefig(result_dir + \"/\" + save_filename + \".png\")\n",
    "        fig.savefig(result_dir + \"/\" + save_filename + \".pdf\")\n",
    "        \n",
    "        \n",
    "    \n",
    "def days_to_sec(days):\n",
    "    return days*24*60*60\n",
    "\n",
    "def sec_to_days(secs):\n",
    "    return secs/(24*60*60)\n",
    "\n",
    "def truth_time_step(t):\n",
    "    t = t - days_to_sec(3)\n",
    "    return int(t/(60*60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast errors\n",
    "\n",
    "First, let the error in the ensemble forecast for drifter $d$ at time $t^n$ be defined as \n",
    "$$     E_{d}(t_n) = \\frac{1}{N_e} \\sum_{i=1}^{N_e} \\left[ \\left( x_{i,d}^n - x_{true, d}^n \\right)^2 + \\left(y_{i,d}^n - y_{true, d}^n \\right)^2 \\right].$$\n",
    "Further, let the forecast error be the mean of $E_d^n$ over all drifters,\n",
    "$$    E(t_n) = \\sqrt{ \\frac{1}{N_D} \\sum_{d=1}^{N_D} E_d(t^n)}.$$\n",
    "\n",
    "The root-mean-square errors are defined similarly, but using the ensemble mean rather than the true drifter positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Observation)\n",
    "\n",
    "start_time_forecast = days_to_sec(10)\n",
    "end_time_forecast = days_to_sec(13)\n",
    "\n",
    "# Read truth observation file:\n",
    "true_observations = Observation.Observation(domain_size_x=domain_size_x, \n",
    "                                            domain_size_y=domain_size_y, \n",
    "                                            nx=nx, ny=ny)\n",
    "true_observations.read_pickle(true_obs_file)\n",
    "\n",
    "# Read observation files from the ensemble:\n",
    "obs_files_buoys = obs_files[3]\n",
    "\n",
    "\n",
    "ensemble_observations = [None]*len(obs_files_buoys)\n",
    "for i in range(len(obs_files_buoys)):\n",
    "    ensemble_observations[i] = Observation.Observation(domain_size_x=domain_size_x, \n",
    "                                                       domain_size_y=domain_size_y, \n",
    "                                                       nx=nx, ny=ny)\n",
    "    ensemble_observations[i].read_pickle(obs_files_buoys[i])\n",
    "    print(\".\"+str(i)+\".\", end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aim for a time resolution of one per hour\n",
    "drifter_id = 1\n",
    "\n",
    "def getForecastError(ensemble_observations, drifter_id):\n",
    "    \"\"\"\n",
    "    returns the forecast errors per hour for the given drifter and ensemble.\n",
    "    True path can also represent the mean\n",
    "    \"\"\"\n",
    "    active_ensemble_size = len(ensemble_observations)\n",
    "    forecast_paths_old = [None]*active_ensemble_size\n",
    "    forecast_paths = np.zeros((active_ensemble_size, 72, 2))\n",
    "    for i in range(len(forecast_paths)):\n",
    "        forecast_path = ensemble_observations[i].get_drifter_path(drifter_id,  \n",
    "                                                                  start_time_forecast,\n",
    "                                                                  end_time_forecast,\n",
    "                                                                  keepDomainSize=False)\n",
    "        # Only one path per forecast, as we do not keep the domain size\n",
    "        # we therefore simplify the data structure, and filter for every hour only\n",
    "        # Starting at hour 1\n",
    "        forecast_paths_old[i] = forecast_path[0][11::12,:]\n",
    "\n",
    "        forecast_paths[i, :, :] = forecast_path[0][11::12,:]\n",
    "    \n",
    "    # And read the true path\n",
    "    true_path = true_observations.get_drifter_path(drifter_id,  \n",
    "                                                   start_time_forecast,\n",
    "                                                   end_time_forecast,\n",
    "                                                   keepDomainSize=False)\n",
    "    # Only one path per forecast, as we do not keep the domain size\n",
    "    # we therefore simplify the data structure, and filter for every hour only\n",
    "    # Starting at hour 1\n",
    "    true_path = true_path[0][11::12,:]\n",
    "    \n",
    "    # Find mean forecast_path\n",
    "    mean_path = np.nanmean(forecast_paths, axis=0)\n",
    "\n",
    "    drifter_error = np.zeros(72)\n",
    "    drifter_rmse  = np.zeros(72)\n",
    "    active_ensemble_size = len(forecast_paths)\n",
    "    for t in range(72):\n",
    "        actual_active_ensemble_size = active_ensemble_size\n",
    "        for i in range(active_ensemble_size):\n",
    "            if (np.isnan(forecast_paths[i][t,0])) or (np.isnan(forecast_paths[i][t,0])):\n",
    "                #print(\"(ensemble member, t)\", (i, t))\n",
    "                actual_active_ensemble_size -= 1\n",
    "                continue\n",
    "            drifter_error[t] += (forecast_paths[i][t,0] - true_path[t,0])**2 + (forecast_paths[i][t,1] - true_path[t,1])**2\n",
    "            drifter_rmse[t]  += (forecast_paths[i][t,0] - mean_path[t,0])**2 + (forecast_paths[i][t,1] - mean_path[t,1])**2\n",
    "        drifter_error[t] = drifter_error[t]/actual_active_ensemble_size\n",
    "        drifter_rmse[t]  = drifter_rmse[t]/actual_active_ensemble_size\n",
    "    return drifter_error, drifter_rmse\n",
    "\n",
    "\n",
    "def forecastErrorMean(ensemble_observations):\n",
    "    forecast_error_means = np.zeros(72)\n",
    "    forecast_error_means_drifter_set = np.zeros(72)\n",
    "    forecast_rmse_means = np.zeros(72)\n",
    "    forecast_rmse_means_drifter_set = np.zeros(72)\n",
    "    \n",
    "    print(\"obtaining forecastErrorMean\")\n",
    "    for drifter in range(64):\n",
    "        drifter_error, drifter_rmse = getForecastError(ensemble_observations, drifter)\n",
    "        if drifter in drifterSet:\n",
    "            forecast_error_means_drifter_set += drifter_error\n",
    "            forecast_rmse_means_drifter_set  += drifter_rmse\n",
    "        forecast_error_means += drifter_error\n",
    "        forecast_rmse_means  += drifter_rmse\n",
    "        print(\".\"+str(drifter)+\".\", end='')\n",
    "        \n",
    "    print('')\n",
    "    forecast_error_means = np.sqrt(forecast_error_means/num_drifters)\n",
    "    forecast_error_means_drifter_set = np.sqrt(forecast_error_means_drifter_set/len(drifterSet))\n",
    "    forecast_rmse_means = np.sqrt(forecast_rmse_means/num_drifters)\n",
    "    forecast_rmse_means_drifter_set = np.sqrt(forecast_rmse_means_drifter_set/len(drifterSet))\n",
    "    return forecast_error_means, forecast_error_means_drifter_set, forecast_rmse_means, forecast_rmse_means_drifter_set\n",
    "    \n",
    "def forecastMeanForFileSet(fileSet):\n",
    "    \"\"\"\n",
    "    fileSet is observationFiles\n",
    "    \"\"\"\n",
    "    \n",
    "    ensemble_observations = [None]*len(fileSet)\n",
    "    print('reading fileSet')\n",
    "    for i in range(len(fileSet)):\n",
    "        ensemble_observations[i] = Observation.Observation(domain_size_x=domain_size_x, \n",
    "                                                           domain_size_y=domain_size_y, \n",
    "                                                           nx=nx, ny=ny)\n",
    "        ensemble_observations[i].read_pickle(fileSet[i])\n",
    "        print(\".\"+str(i)+\".\", end='')\n",
    " \n",
    "    print('')\n",
    "    return forecastErrorMean(ensemble_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Obtain forecastErrorMeans from all experiments\n",
    "\n",
    "forecast_errors_drifter_sets = [[0]]*6\n",
    "forecast_errors_means = [[0]]*6\n",
    "forecast_rmse_means = [[0]]*6\n",
    "forecast_rmse_means_drifter_set = [[0]]*6\n",
    "\n",
    "for i in range(6):\n",
    "    print(labels[i])\n",
    "    forecast_errors_means[i], forecast_errors_drifter_sets[i], \\\n",
    "    forecast_rmse_means[i], forecast_rmse_means_drifter_set[i] \\\n",
    "        = forecastMeanForFileSet(obs_files[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    print(\"----- \" + str(i) + \" ------\")\n",
    "    print(forecast_errors_means[i][-3:])\n",
    "    print(forecast_rmse_means[i][-3:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "for i in range(6):\n",
    "    plt.plot(forecast_errors_drifter_sets[i], label=labels[i])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('$t$ (hours)')\n",
    "plt.ylabel('$E(t_n)$')\n",
    "plt.title('Ensemble forecast error (ten drifters)')\n",
    "plt.savefig(root_folder + '/forecast_mean_errors_drifter_set.png')\n",
    "plt.savefig(root_folder + '/forecast_mean_errors_drifter_set.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.plot(forecast_errors_means[i], label=labels[i])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('$t$ (hours)')\n",
    "plt.ylabel('$E(t_n)$')\n",
    "plt.title('Ensemble forecast error')\n",
    "plt.savefig(root_folder + '/forecast_mean_errors.png')\n",
    "plt.savefig(root_folder + '/forecast_mean_errors.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.plot(forecast_rmse_means[i], label=labels[i])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('$t$ (hours)')\n",
    "plt.ylabel('$RMSE(t_n)$')\n",
    "plt.title('Ensemble forecast RMSE')\n",
    "plt.savefig(root_folder + '/forecast_rmse.png')\n",
    "plt.savefig(root_folder + '/forecast_rmse.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.plot(forecast_rmse_means_drifter_set[i], label=labels[i])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('$t$ (hours)')\n",
    "plt.ylabel('$RMSE(t_n)$')\n",
    "plt.title('Ensemble forecast RMSE (ten drifters)')\n",
    "plt.savefig(root_folder + '/forecast_rmse_drifter_set.png')\n",
    "plt.savefig(root_folder + '/forecast_rmse_drifter_set.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_drifters, len(drifterSet), root_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdfghjkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Obtain forecastErrorMeans from all experiments\n",
    "\n",
    "forecast_error_means = [None]*6\n",
    "for i in range(6):\n",
    "    print(labels[i])\n",
    "    forecast_error_means[i] = forecastMeanForFileSet(obs_files[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drifter_error_1 = getForecastError(ensemble_observations, 1)\n",
    "drifter_error_2 = getForecastError(ensemble_observations, 2)\n",
    "drifter_error_3 = getForecastError(ensemble_observations, 3)\n",
    "mean_error = forecastErrorMean(ensemble_observations)\n",
    "mean_error_drifter_set = forecastErrorMean(ensemble_observations, drifterSet=drifterSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=)\n",
    "plt.plot(drifter_error_1, label='d1')\n",
    "plt.plot(drifter_error_2, label='d2')\n",
    "plt.plot(drifter_error_3, label='d3')\n",
    "plt.plot(mean_error, label='mean')\n",
    "plt.plot(mean_error_drifter_set, label='mean drifter set')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:gpuocean] *",
   "language": "python",
   "name": "conda-env-gpuocean-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}