{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "This software is a part of GPU Ocean.\n",
    "\n",
    "Copyright (C) 2019  SINTEF Digital\n",
    "\n",
    "Producing plots of data assimilation experiments by post-processing the\n",
    "files produced by scripts/run_experiment.py\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing of Data Assimilation experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "from importlib import reload\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../')))\n",
    "\n",
    "#Set large figure sizes\n",
    "rc('figure', figsize=(16.0, 12.0))\n",
    "rc('animation', html='html5')\n",
    "\n",
    "#Import our simulator\n",
    "from SWESimulators import IPythonMagic, SimReader, Observation, ParticleInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cuda_context_handler gpu_ctx\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create output directory for images\n",
    "#imgdir = 'double_jet'\n",
    "#filename_prefix = imgdir + \"/\" + datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\") + \"_\"\n",
    "#os.makedirs(imgdir, exist_ok=True)\n",
    "#print(\"Saving images to \" + imgdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the folder containing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_dir = os.path.abspath('scripts/da_experiment_2019_05_06-14_35_19_IEWPF2s_success/')\n",
    "result_dir = os.path.abspath('/media/havahol/Seagate Backup Plus Drive/gpu_ocean/' + \\\n",
    "                             #'da_experiment_2019_05_28-15_35_12_IEWPF2s_obsvar_1/')\n",
    "                             #'may_buoy_truth/da_experiment_2019_05_29-16_16_34_buoys_IEWPF')\n",
    "                             #'may_buoy_truth/da_experiment_2019_06_03-11_43_42_drifters_IEWPF_obsvar_1_N40')\n",
    "                             #'may_buoy_truth/da_experiment_2019_06_03-14_06_15_drifters_IEWPF_obsvar_1_N100')\n",
    "                             #'may_buoy_truth/da_experiment_2019_06_03-17_26_55_dry_run_N100')\n",
    "                             #'may_buoy_truth/da_experiment_2019_06_04-10_16_04_all_drifters_IEWPF_obsvar_1_N100')\n",
    "                             #'may_buoy_truth/da_experiment_2019_06_04-15_27_14_buoys_south_IEWPF')\n",
    "                             'may_buoy_truth/da_experiment_2019_06_04-22_55_06_buoys_west_IEWPF')\n",
    "                             #'da_experiment_2019_06_04-22_34_37')\n",
    "                             \n",
    "print(result_dir)\n",
    "\n",
    "#truth_folder = \"double_jet_truth\"\n",
    "truth_folder = os.path.join(result_dir, \"truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def file_filter(path_to_dir, ext=None, prefix=None, abspath=True):\n",
    "    filtered_files = os.listdir(path_to_dir)\n",
    "    if prefix:\n",
    "        filtered_files = list(file for file in filtered_files if file.startswith(prefix))\n",
    "    if ext:\n",
    "        filtered_files = list(file for file in filtered_files if file.endswith(ext))\n",
    "    if abspath:\n",
    "        filtered_files= list(os.path.join(path_to_dir, file)  for file in filtered_files)\n",
    "\n",
    "    filtered_files.sort()\n",
    "    return filtered_files\n",
    "\n",
    "\n",
    "nc_files = file_filter(result_dir, ext='nc')\n",
    "obs_files = file_filter(result_dir, ext='bz2', prefix='forecast')\n",
    "particle_info_files = file_filter(result_dir, ext='bz2', prefix='particle_info')\n",
    "print(\"number of nc_files:            \", len(nc_files))\n",
    "print(\"number of obs_files:           \", len(obs_files))\n",
    "print(\"number of particle_info_files: \", len(particle_info_files))\n",
    "\n",
    "if False:\n",
    "    print(len(nc_files), nc_files)\n",
    "    print()\n",
    "    print(len(obs_files), obs_files)\n",
    "    print()\n",
    "    print(len(particle_info_files), particle_info_files)\n",
    "    \n",
    "# Truth:\n",
    "true_nc = truth_folder + \"/double_jet_case_truth.nc\"\n",
    "true_obs_file = truth_folder + \"/drifter_observations.pickle\"\n",
    "    \n",
    "ensemble_size = len(nc_files)\n",
    "num_drifters=64\n",
    "\n",
    "drifterSet = [ 4,  9, 14, 29, 33, 39, 44, 50, 56, 54]\n",
    "if result_dir.find(\"april\") > -1:\n",
    "    drifterSet = [4, 12, 20, 28, 36, 44, 52, 60]\n",
    "elif result_dir.find(\"may_buoy\") > -1:\n",
    "    drifterSet = [ 4,  9, 14, 29, 33, 39, 44, 50, 56, 54]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(im, interpolation=\"None\", title=None, figsize=(4,4), interior=False):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    if interior:\n",
    "        im = plt.imshow(im[2:-2,2:-2], interpolation=interpolation, origin='lower')\n",
    "    else:\n",
    "        im = plt.imshow(im, interpolation=interpolation, origin='lower')\n",
    "    \n",
    "    plt.colorbar()\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "        \n",
    "def imshow3(eta, hu, hv, interpolation=\"None\", title=None, figsize=(12,3), \n",
    "            interior=False, color_bar_from_zero=False, save_filename=None):\n",
    "    \n",
    "    fig, axs = plt.subplots(1,3, figsize=figsize)\n",
    "    \n",
    "    eta_max = np.max(np.abs(eta))\n",
    "    huv_max = max(np.max(np.abs(hu)), np.max(np.abs(hv)))\n",
    "    eta_min = -eta_max\n",
    "    huv_min = -huv_max\n",
    "    if color_bar_from_zero:\n",
    "        eta_min, huv_min = 0, 0\n",
    "    \n",
    "    if interior:\n",
    "        eta_im = axs[0].imshow(eta[2:-2,2:-2], interpolation=interpolation, origin='lower', vmin=eta_min, vmax=eta_max)\n",
    "    else:\n",
    "        eta_im = axs[0].imshow(eta, interpolation=interpolation, origin='lower', vmin=eta_min, vmax=eta_max)\n",
    "    axs[0].set_title(\"$\\eta$\")\n",
    "    plt.colorbar(eta_im, ax=axs[0])\n",
    "    \n",
    "    if interior:\n",
    "        hu_im = axs[1].imshow(hu[2:-2,2:-2], interpolation=interpolation, origin='lower', vmin=huv_min, vmax=huv_max)\n",
    "    else:\n",
    "        hu_im = axs[1].imshow(hu, interpolation=interpolation, origin='lower', vmin=huv_min, vmax=huv_max)\n",
    "    axs[1].set_title(\"$hu$\")\n",
    "    plt.colorbar(hu_im, ax=axs[1])\n",
    "\n",
    "    if interior:\n",
    "        hv_im = axs[2].imshow(hv[2:-2,2:-2], interpolation=interpolation, origin='lower', vmin=huv_min, vmax=huv_max)\n",
    "    else:\n",
    "        hv_im = axs[2].imshow(hv, interpolation=interpolation, origin='lower', vmin=huv_min, vmax=huv_max)\n",
    "    axs[2].set_title(\"$hv$\")\n",
    "    plt.colorbar(hv_im, ax=axs[2])\n",
    "\n",
    "    if title is not None:\n",
    "        plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_filename is not None:\n",
    "        fig.savefig(result_dir + \"/\" + save_filename + \".png\")\n",
    "        fig.savefig(result_dir + \"/\" + save_filename + \".pdf\")\n",
    "        \n",
    "        \n",
    "    \n",
    "def days_to_sec(days):\n",
    "    return days*24*60*60\n",
    "\n",
    "def sec_to_days(secs):\n",
    "    return secs/(24*60*60)\n",
    "\n",
    "def truth_time_step(t):\n",
    "    t = t - days_to_sec(3)\n",
    "    return int(t/(60*60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean and variance for different timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read netCDF files\n",
    "reload(SimReader)\n",
    "\n",
    "truth_reader = SimReader.SimNetCDFReader(true_nc)\n",
    "sim_readers = [None]*ensemble_size\n",
    "for particle_id in range(ensemble_size):\n",
    "    sim_readers[particle_id] = SimReader.SimNetCDFReader(nc_files[particle_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the timestamps for particle zero:\n",
    "example_sim_reader = sim_readers[0]\n",
    "times = example_sim_reader.getTimes()\n",
    "print(sec_to_days(times.data))\n",
    "print('Hopefully these values are only full days')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def plotStatisticalFields(t, truth_reader, sim_readers, save=True):\n",
    "\n",
    "    day_string = str(int(sec_to_days(t))).zfill(2)\n",
    "    print('plotting statistical features at day ' + day_string)\n",
    "    \n",
    "    \n",
    "    true_eta, true_hu, true_hv, t_tmp = truth_reader.getStateAtTime(t)\n",
    "    #imshow3(true_eta, true_hu, true_hv, title='True state after ' + str(sec_to_days(t)) + ' days')\n",
    "    \n",
    "    mean_eta, mean_hu, mean_hv = np.zeros_like(true_eta), np.zeros_like(true_hu), np.zeros_like(true_hv)\n",
    "    var_eta, var_hu, var_hv = np.zeros_like(true_eta), np.zeros_like(true_hu), np.zeros_like(true_hv)\n",
    "    #rmse_eta, rmse_hu, rmse_hv = np.zeros_like(true_eta), np.zeros_like(true_hu), np.zeros_like(true_hv)\n",
    "    actual_ensemble_size = 0\n",
    "    for particle in sim_readers:\n",
    "        try:\n",
    "            eta, hu, hv, t_tmp = particle.getStateAtTime(t)\n",
    "            if np.any(np.isnan(eta)):\n",
    "                print(\"Found nan for particle \" + str(actual_ensemble_size))\n",
    "                raise RuntimeError()\n",
    "            mean_eta += eta\n",
    "            mean_hu += hu\n",
    "            mean_hv += hv\n",
    "            #var_eta += eta*eta\n",
    "            #var_hu += hu*hu\n",
    "            #var_hv += hv*hv\n",
    "            actual_ensemble_size += 1\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "            # Ignore not found RuntimeError\n",
    "    mean_eta /= actual_ensemble_size\n",
    "    mean_hu /= actual_ensemble_size\n",
    "    mean_hv /= actual_ensemble_size\n",
    "    \n",
    "    #var_eta = var_eta/actual_ensemble_size - mean_eta*mean_eta\n",
    "    #var_hu  = var_hu/actual_ensemble_size -mean_hu*mean_hu\n",
    "    #var_hv  = var_hv/actual_ensemble_size -mean_hv*mean_hv\n",
    "    \n",
    "    \n",
    "    imshow3(mean_eta, mean_hu, mean_hv, title='Ensemble mean after ' + str(sec_to_days(t)) + ' days',\n",
    "            save_filename='ensemble_mean_day_' + day_string)\n",
    "    \n",
    "    if True:\n",
    "        actual_ensemble_size = 0\n",
    "        for particle in sim_readers:\n",
    "            try:\n",
    "                eta, hu, hv, t_tmp = particle.getStateAtTime(t)\n",
    "                if np.any(np.isnan(eta)):\n",
    "                    print(\"Found nan for particle \" + str(actual_ensemble_size))\n",
    "                    raise RuntimeError()\n",
    "                var_eta += (mean_eta - eta)**2\n",
    "                var_hu += (mean_hu - hu)**2\n",
    "                var_hv += (mean_hv - hv)**2\n",
    "                actual_ensemble_size += 1\n",
    "            except RuntimeError:\n",
    "                pass\n",
    "                # Ignore not found RuntimeError\n",
    "\n",
    "        var_eta = np.sqrt(var_eta)/(actual_ensemble_size - 1)\n",
    "        var_hu  = np.sqrt(var_hu)/(actual_ensemble_size - 1)\n",
    "        var_hv  = np.sqrt(var_hv)/(actual_ensemble_size - 1)\n",
    "        \n",
    "        imshow3(var_eta, var_hu, var_hv, \n",
    "                title='Variance after ' + str(sec_to_days(t)) + ' days', color_bar_from_zero=True,\n",
    "                save_filename='ensemble_var_day_' + day_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for t in times:\n",
    "    plotStatisticalFields(t, truth_reader, sim_readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_eta, true_hu, true_hv, t_tmp = truth_reader.getStateAtTime(days_to_sec(10))\n",
    "imshow3(true_eta, true_hu, true_hv, title='10 day true state')\n",
    "plotStatisticalFields(days_to_sec(10), truth_reader, sim_readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eta, hu, hv, t_tmp = sim_readers[0].getStateAtTime(days_to_sec(3.25))\n",
    "#imshow3(eta, hu, hv, title='State after 3.25 days particle 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance under drifters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles = len(nc_files)\n",
    "num_days = 7\n",
    "\n",
    "particle_infos = [None]*num_particles\n",
    "\n",
    "\n",
    "skipVariancePlots = True\n",
    "\n",
    "i = 0\n",
    "for particle in range(num_particles):\n",
    "    filenames = file_filter(result_dir, ext='bz2', \n",
    "                            prefix='particle_info_' + str(particle).zfill(4))\n",
    "    infos = [None]*num_days\n",
    "    for day in range(num_days):\n",
    "        \n",
    "        if not skipVariancePlots or i == 0:\n",
    "            infos[day] = ParticleInfo.ParticleInfo()\n",
    "            infos[day].read_pickle(filenames[day])\n",
    "        if particle == 0:\n",
    "            print(filenames[day])\n",
    "    particle_infos[particle] = infos\n",
    "    print(\".\"+str(i)+\".\", end='')\n",
    "    i += 1\n",
    "    \n",
    "#print(particle_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "info_example = particle_infos[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = file_filter(result_dir, ext='bz2', \n",
    "                            prefix='particle_info_' + str(0).zfill(4))\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "print(\".........\")\n",
    "filenames.sort()\n",
    "for filename in filenames:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_per_day = [None]*num_days\n",
    "\n",
    "#for day in range(num_days):\n",
    "\n",
    "sample_times = info_example.get_sample_times()\n",
    "\n",
    "drifter_id = 4\n",
    "\n",
    "variance_eta_first_day = np.zeros((num_drifters,len(sample_times)))\n",
    "variance_hu_first_day = np.zeros((num_drifters,len(sample_times)))\n",
    "variance_hv_first_day = np.zeros((num_drifters,len(sample_times)))\n",
    "\n",
    "mean_eta_first_day = np.zeros((num_drifters,len(sample_times)))\n",
    "mean_hu_first_day = np.zeros((num_drifters,len(sample_times)))\n",
    "mean_hv_first_day = np.zeros((num_drifters,len(sample_times)))\n",
    "\n",
    "day = 2\n",
    "\n",
    "\n",
    "for particle_id in range(num_particles):\n",
    "    \n",
    "    if skipVariancePlots:\n",
    "        if particle_id == 0:\n",
    "            print('skipping the creation of variance plots')\n",
    "        break\n",
    "    \n",
    "    sample_file = 'particle_info_' + str(particle_id).zfill(4) + \"_\" + str(day).zfill(2) + \".bz2\"\n",
    "    sample_path = os.path.join(result_dir, sample_file)\n",
    "    #\"particle_info_0000_06.bz2\"\n",
    "    \n",
    "    try:\n",
    "\n",
    "        info = ParticleInfo.ParticleInfo()\n",
    "        info.read_pickle(sample_path)\n",
    "\n",
    "        for t_id in range(len(sample_times)):\n",
    "\n",
    "            time = sample_times[t_id] + days_to_sec(day)\n",
    "\n",
    "            state_samples = info.get_state_samples(time)\n",
    "\n",
    "            #state_samples = particle_infos[particle_id][0].get_state_samples(sample_times[t_id])\n",
    "\n",
    "            for drifter_id in range(num_drifters):\n",
    "                mean_eta_first_day[drifter_id, t_id] += state_samples[drifter_id, 0]\n",
    "                mean_hu_first_day[drifter_id, t_id] += state_samples[drifter_id, 1]\n",
    "                mean_hv_first_day[drifter_id, t_id] += state_samples[drifter_id, 2]\n",
    "\n",
    "                variance_eta_first_day[drifter_id, t_id] += state_samples[drifter_id, 0]**2\n",
    "                variance_hu_first_day[drifter_id, t_id] += state_samples[drifter_id, 1]**2\n",
    "                variance_hv_first_day[drifter_id, t_id] += state_samples[drifter_id, 2]**2\n",
    "\n",
    "        print(\".\"+str(particle_id)+\".\", end='')\n",
    "        \n",
    "        \n",
    "    \n",
    "    except AssertionError as ae:\n",
    "        print('\\nParticle ' + str(particle_id) + ' failed')\n",
    "        print(ae)\n",
    "        \n",
    "    \n",
    "        \n",
    "            \n",
    "            \n",
    "mean_eta_first_day /= num_particles\n",
    "mean_hu_first_day /= num_particles\n",
    "mean_hv_first_day /= num_particles        \n",
    "        \n",
    "variance_eta_first_day = variance_eta_first_day/num_particles - mean_eta_first_day**2\n",
    "variance_hu_first_day = variance_hu_first_day/num_particles - mean_hu_first_day**2\n",
    "variance_hv_first_day = variance_hv_first_day/num_particles - mean_hv_first_day**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "for drifter_id in range(0, 64, 4):\n",
    "    plt.plot(sec_to_days(sample_times), variance_hu_first_day[drifter_id,:])\n",
    "#plt.plot(sample_times, variance_hv_first_day[4,:])\n",
    "#plt.plot(sample_times, variance_eta_first_day[4,:])\n",
    "if not skipVariancePlots:\n",
    "    fig.savefig(result_dir + \"/\" + \"var_drifter_\" + str(drifter_id) + \"_day_3_hu.png\")\n",
    "    fig.savefig(result_dir + \"/\" + \"var_drifter_\" + str(drifter_id) + \"_day_3_hu.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "for drifter_id in range(0, 64, 4):\n",
    "    plt.plot(sec_to_days(sample_times), variance_hv_first_day[drifter_id,:])\n",
    "if not skipVariancePlots:\n",
    "    fig.savefig(result_dir + \"/\" + \"var_drifter_\" + str(drifter_id) + \"_day_3_hv.png\")\n",
    "    fig.savefig(result_dir + \"/\" + \"var_drifter_\" + str(drifter_id) + \"_day_3_hv.pdf\")\n",
    "#plt.plot(sample_times, variance_hv_first_day[4,:])\n",
    "#plt.plot(sample_times, variance_eta_first_day[4,:])\n",
    "15*15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "for drifter_id in range(0, 64, 4):\n",
    "    plt.plot(sec_to_days(sample_times), variance_eta_first_day[drifter_id,:])\n",
    "    #plt.plot(sample_times, variance_hv_first_day[4,:])\n",
    "    \n",
    "if not skipVariancePlots:\n",
    "    fig.savefig(result_dir + \"/\" + \"var_drifter_\" + str(drifter_id) + \"_day_3_eta.png\")\n",
    "    fig.savefig(result_dir + \"/\" + \"var_drifter_\" + str(drifter_id) + \"_day_3_eta.pdf\")\n",
    "#plt.plot(sample_times, variance_eta_first_day[4,:])\n",
    "15*15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_infos[0][5].state_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for creating forecast plot\n",
    "\n",
    "def createForecastCanvas(true_sim_reader, num_canvases=1):\n",
    "    \"\"\"\n",
    "    true_sim_reader: The SimReader object containing nx, ny, etc\n",
    "    \"\"\"   \n",
    "    \n",
    "    nx = true_sim_reader.get('nx')\n",
    "    ny = true_sim_reader.get('ny')\n",
    "    dx = true_sim_reader.get('dx')\n",
    "    dy = true_sim_reader.get('dy')\n",
    "    \n",
    "    emptyData =np.ma.masked_where(np.zeros((ny, nx)) > 1, \n",
    "                                      np.zeros((ny, nx)))\n",
    "    \n",
    "    if num_canvases == 1:\n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "        ax = plt.subplot(111)\n",
    "        \n",
    "        ax.imshow(emptyData, origin=\"lower\", \n",
    "                  extent=[0, nx*dx, 0, ny*dy], cmap='binary')\n",
    "\n",
    "        return ax\n",
    "    \n",
    "    elif num_canvases < 4:\n",
    "        fig, axs = plt.subplots(1,num_canvases, figsize=(7*num_canvases, 7))\n",
    "    \n",
    "        for ax in axs:\n",
    "            ax.imshow(emptyData, origin=\"lower\", \n",
    "                      extent=[0, nx*dx, 0, ny*dy], cmap='binary')\n",
    "            ax.set_ylim([0, ny*dy])\n",
    "            ax.set_xlim([0, nx*dx])\n",
    "        \n",
    "        return axs\n",
    "    assert (num_canvases < 4), 'Function not implemented for more than 3 canvases'\n",
    "\n",
    "def forecastPlot(ax, true_paths, ensemble_paths, color_id=0):\n",
    "    \"\"\"\n",
    "    ax: Axis object to draw trajectories in\n",
    "    true_path: A single list of paths that represents the truth\n",
    "    ensemble_paths: Multiple lists of paths that represents the forecast\n",
    "    color_id: integer representing a pre-defined color combination.\n",
    "    \"\"\"\n",
    "\n",
    "    color_combinations = [\n",
    "        # [true color, forecast color]\n",
    "        ['xkcd:dark grey blue', 'xkcd:light blue grey'],\n",
    "        ['xkcd:viridian', 'xkcd:foam green']\n",
    "    ]\n",
    "    \n",
    "    assert(color_id < len(color_combinations)), 'Invalid color_id'\n",
    "    \n",
    "    true_color = color_combinations[color_id][0]\n",
    "    forecast_color = color_combinations[color_id][1]\n",
    "\n",
    "    # Plot forecast paths \n",
    "    for paths in ensemble_paths:\n",
    "        for path in paths:\n",
    "            ax.plot(path[:,0], path[:,1], color=forecast_color, alpha=0.3)\n",
    "        \n",
    "        # Mark end position of forecast\n",
    "        end_position   = paths[-1][-1,:]\n",
    "        circ_end_forecast = matplotlib.patches.Circle((end_position[0], end_position[1]), \n",
    "                                                          2000, fill=False, zorder=10)\n",
    "        ax.add_patch(circ_end_forecast)\n",
    "\n",
    "    \n",
    "    # Plot true path\n",
    "    for path in true_paths:\n",
    "        ax.plot(path[:,0], path[:,1], color=true_color, zorder=5)\n",
    "\n",
    "    # Mark start and end of true path\n",
    "    start_pos = true_paths[0][0,:]\n",
    "    end_pos   = true_paths[-1][-1,:]\n",
    "    circ_start = matplotlib.patches.Circle((start_pos[0], start_pos[1]), \n",
    "                                           6000, fill=False, zorder=10)\n",
    "    ax.add_patch(circ_start)\n",
    "    circ_end = matplotlib.patches.Circle((end_pos[0], end_pos[1]), \n",
    "                                         6000, fill=False, zorder=10)\n",
    "    ax.add_patch(circ_end)\n",
    "\n",
    "    \n",
    "def plotThreeDayForecast(true_observations, ensemble_observations, drifter_id):\n",
    "    \n",
    "    start_time_forecast = days_to_sec(10)\n",
    "    try:\n",
    "        start_time_forecast = ensemble_observations[0].get_observation_times()[0]\n",
    "    except e:\n",
    "        pass\n",
    "    \n",
    "    true_drifter_id = drifterSet[drifter_id]\n",
    "    \n",
    "    print('true_observations.get_num_drifters(applyDrifterSet=False, ignoreBuoys=True)', \n",
    "           true_observations.get_num_drifters(applyDrifterSet=False, ignoreBuoys=True))\n",
    "    print('ensemble_observations[0].get_num_drifters(applyDrifterSet=False, ignoreBuoys=True)', \n",
    "           ensemble_observations[0].get_num_drifters(applyDrifterSet=False, ignoreBuoys=True))\n",
    "    \n",
    "    if true_observations.get_num_drifters(applyDrifterSet=False, ignoreBuoys=True) == \\\n",
    "       ensemble_observations[0].get_num_drifters(applyDrifterSet=False, ignoreBuoys=True):\n",
    "        print('using the same drifter id')\n",
    "        drifter_id = true_drifter_id\n",
    "    \n",
    "    axs = createForecastCanvas(truth_reader, 3)\n",
    "    \n",
    "    for forecast_days in range(1,4):\n",
    "        title=  str(forecast_days) + ' days forecast for drifter ' + str(true_drifter_id)\n",
    "        print('generating ' + title)\n",
    "        end_time_forecast = start_time_forecast + days_to_sec(forecast_days)\n",
    "        \n",
    "        true_paths = true_observations.get_drifter_path(true_drifter_id, \n",
    "                                                        start_time_forecast,\n",
    "                                                        end_time_forecast)\n",
    "\n",
    "        forecast_paths = [None]*len(ensemble_observations)\n",
    "        for i in range(len(forecast_paths)):\n",
    "            forecast_paths[i] = ensemble_observations[i].get_drifter_path(drifter_id,  \n",
    "                                                                          start_time_forecast,\n",
    "                                                                          end_time_forecast)\n",
    "        \n",
    "        ax_id = forecast_days-1\n",
    "        forecastPlot(axs[ax_id], true_paths, forecast_paths)\n",
    "        axs[ax_id].set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    forecast_filename = \"trajectory_forecast_drifter_\" + str(true_drifter_id).zfill(2)\n",
    "    \n",
    "    plt.savefig(result_dir + \"/\" + forecast_filename + \".png\")\n",
    "    plt.savefig(result_dir + \"/\" + forecast_filename + \".pdf\")\n",
    "\n",
    "def plotShortRangeForecast(true_observations, ensemble_observations, drifter_id):\n",
    "    \n",
    "    start_time_forecast = days_to_sec(10)\n",
    "    try:\n",
    "        start_time_forecast = ensemble_observations[0].get_observation_times()[0]\n",
    "    except e:\n",
    "        pass\n",
    "    \n",
    "    true_drifter_id = drifterSet[drifter_id]\n",
    "    \n",
    "    if true_observations.get_num_drifters(applyDrifterSet=False, ignoreBuoys=True) == \\\n",
    "       ensemble_observations[0].get_num_drifters(applyDrifterSet=False, ignoreBuoys=True):\n",
    "        drifter_id = true_drifter_id\n",
    "    \n",
    "    axs = createForecastCanvas(truth_reader, 3)\n",
    "    \n",
    "    forecast_days_array = [0.25, 0.5, 1]\n",
    "    for ax_id in range(3):\n",
    "        \n",
    "        forecast_days = forecast_days_array[ax_id]\n",
    "        hours = int(24*forecast_days)\n",
    "        \n",
    "        title=  str(hours) + ' hour forecast for drifter ' + str(true_drifter_id)\n",
    "        print('generating ' + title)\n",
    "\n",
    "        end_time_forecast = start_time_forecast + days_to_sec(forecast_days)\n",
    "        \n",
    "        true_paths = true_observations.get_drifter_path(true_drifter_id, \n",
    "                                                        start_time_forecast,\n",
    "                                                        end_time_forecast)\n",
    "\n",
    "        forecast_paths = [None]*len(ensemble_observations)\n",
    "        for i in range(len(forecast_paths)):\n",
    "            forecast_paths[i] = ensemble_observations[i].get_drifter_path(drifter_id,  \n",
    "                                                                          start_time_forecast,\n",
    "                                                                          end_time_forecast)\n",
    "        \n",
    "        forecastPlot(axs[ax_id], true_paths, forecast_paths)\n",
    "        axs[ax_id].set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    forecast_filename = \"trajectory_forecast_drifter_\" + str(true_drifter_id).zfill(2) + \"_short_range\"\n",
    "    \n",
    "    plt.savefig(result_dir + \"/\" + forecast_filename + \".png\")\n",
    "    plt.savefig(result_dir + \"/\" + forecast_filename + \".pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Observation)\n",
    "\n",
    "# Read truth observation file:\n",
    "true_observations = Observation.Observation()\n",
    "true_observations.read_pickle(true_obs_file)\n",
    "\n",
    "# Read observation files from the ensemble:\n",
    "\n",
    "ensemble_observations = [None]*len(obs_files)\n",
    "for i in range(len(obs_files)):\n",
    "    ensemble_observations[i] = Observation.Observation()\n",
    "    ensemble_observations[i].read_pickle(obs_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nc_files = file_filter(result_dir, ext='nc')\n",
    "#obs_files = file_filter(result_dir, ext='bz2', prefix='forecast')\n",
    "#particle_info_files = file_filter(result_dir, ext='bz2', prefix='particle_info')\n",
    "\n",
    "\n",
    "start_time_forecast = days_to_sec(10)\n",
    "end_time_forecast = days_to_sec(11)\n",
    "obs_times = true_observations.get_observation_times()\n",
    "\n",
    "drifter_id = 0\n",
    "true_drifter_id = drifterSet[drifter_id]\n",
    "\n",
    "print(\"Number of obs_times: \", len(obs_times))\n",
    "print(\"Obs interval (s) (assuming 10 days): \", (10*24*60*60)/len(obs_times))\n",
    "print(\"Day of first obs_time:  \", sec_to_days(obs_times[0]))\n",
    "print(\"Day of second obs_time: \", sec_to_days(obs_times[1]))\n",
    "print(\"Day of last obs_time:   \", sec_to_days(obs_times[-1]))\n",
    "\n",
    "print(\"Time diff first to second (in s):        \", obs_times[1]-obs_times[0])\n",
    "print(\"Time diff last to second to last (in s): \", obs_times[-1]-obs_times[-2])\n",
    "\n",
    "print(\"Number of relevant time steps (3 day forecast): \", 3*len(obs_times)/10)\n",
    "\n",
    "print('\\nReading true path')\n",
    "true_paths = true_observations.get_drifter_path(true_drifter_id, days_to_sec(10), end_time_forecast)\n",
    "print('True path obtained')\n",
    "\n",
    "\n",
    "print('\\nReading ' + str(len(ensemble_observations)) + ' ensemble paths')\n",
    "forecast_paths = [None]*len(ensemble_observations)\n",
    "for i in range(len(forecast_paths)):\n",
    "    forecast_paths[i] = ensemble_observations[i].get_drifter_path(drifter_id, days_to_sec(10), end_time_forecast)\n",
    "    print(\".\"+str(i)+\".\", end='')\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = createForecastCanvas(truth_reader)\n",
    "forecastPlot(ax, true_paths, forecast_paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = createForecastCanvas(truth_reader)\n",
    "forecastPlot(ax, true_paths, forecast_paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for drifter in range(len(drifterSet)):\n",
    "    plotThreeDayForecast(true_observations, ensemble_observations, drifter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for drifter in range(len(drifterSet)):\n",
    "    plotShortRangeForecast(true_observations, ensemble_observations, drifter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_obs = ensemble_observations[0]\n",
    "sample_obs.get_num_drifters(), sample_obs.drifterSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(230)"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:gpuocean]",
   "language": "python",
   "name": "conda-env-gpuocean-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
