{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "This software is a part of GPU Ocean.\n",
    "\n",
    "Copyright (C) 2019  SINTEF Digital\n",
    "\n",
    "Producing plots of data assimilation experiments by post-processing the\n",
    "files produced by scripts/run_experiment.py\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing of Data Assimilation experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "from mpl_toolkits.axes_grid1.colorbar import colorbar\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "from importlib import reload\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../../')))\n",
    "\n",
    "#Set large figure sizes\n",
    "rc('figure', figsize=(16.0, 12.0))\n",
    "rc('animation', html='html5')\n",
    "rc('text', usetex=True)\n",
    "\n",
    "\n",
    "#Import our simulator\n",
    "from SWESimulators import IPythonMagic, SimReader, Observation, ParticleInfo\n",
    "from SWESimulators import DataAssimilationUtils as dautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cuda_context_handler gpu_ctx\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create output directory for images\n",
    "#imgdir = 'double_jet'\n",
    "#filename_prefix = imgdir + \"/\" + datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\") + \"_\"\n",
    "#os.makedirs(imgdir, exist_ok=True)\n",
    "#print(\"Saving images to \" + imgdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the folder containing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_dir = os.path.abspath('scripts/da_experiment_2019_05_06-14_35_19_IEWPF2s_success/')\n",
    "result_dir = os.path.abspath('/media/havahol/Seagate Backup Plus Drive/gpu_ocean/' + \\\n",
    "                             #'da_experiment_2019_05_28-15_35_12_IEWPF2s_obsvar_1/')\n",
    "                             #'may_buoy_truth/da_experiment_2019_05_29-16_16_34_buoys_IEWPF')\n",
    "                             #'may_buoy_truth/da_experiment_2019_06_03-11_43_42_drifters_IEWPF_obsvar_1_N40')\n",
    "                             #'may_buoy_truth/da_experiment_2019_06_03-14_06_15_drifters_IEWPF_obsvar_1_N100')\n",
    "                             #'may_buoy_truth/da_experiment_2019_06_21-15_51_18_drifters_IEWPF_obsvar_5_N100')\n",
    "                             #'may_buoy_truth/da_experiment_2019_06_03-17_26_55_dry_run_N100')\n",
    "                             #'may_buoy_truth/da_experiment_2019_06_04-10_16_04_all_drifters_IEWPF_obsvar_1_N100')\n",
    "                             #'may_buoy_truth/da_experiment_2019_06_04-15_27_14_buoys_south_IEWPF')\n",
    "                             #'may_buoy_truth/da_experiment_2019_06_04-22_55_06_buoys_west_IEWPF')\n",
    "                             #'da_experiment_2019_06_04-22_34_37')\n",
    "                             #\n",
    "                             #'june_25_truth/all_forecasts_2019_06_25-13_13_46/da_experiment_2019_06_25-13_13_48-dry_run')\n",
    "                             #'june_25_truth/all_forecasts_2019_06_25-13_13_46/da_experiment_2019_06_25-14_35_13-10drifters')\n",
    "                             #'june_25_truth/all_forecasts_2019_06_25-13_13_46/da_experiment_2019_06_25-16_05_17-alldrifters')\n",
    "                             #'june_25_truth/all_forecasts_2019_06_25-13_13_46/da_experiment_2019_06_25-17_59_44-all-buoys')\n",
    "                             'june_25_truth/all_forecasts_2019_06_25-13_13_46/da_experiment_2019_06_25-21_08_44-western_buoys')\n",
    "                             #'june_25_truth/all_forecasts_2019_06_25-13_13_46/da_experiment_2019_06_25-23_25_47-southern_buoys')\n",
    "print(result_dir)\n",
    "\n",
    "#main_title = \"No data assimilation\"\n",
    "#main_title = \"Ten drifters\"\n",
    "#main_title = \"All drifters\"\n",
    "#main_title = \"All buoys\"\n",
    "main_title = \"West buoys\"\n",
    "#main_title = \"South buoys\"\n",
    "\n",
    "#truth_folder = \"double_jet_truth\"\n",
    "truth_folder = os.path.join(result_dir, \"truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def file_filter(path_to_dir, ext=None, prefix=None, abspath=True):\n",
    "    filtered_files = os.listdir(path_to_dir)\n",
    "    if prefix:\n",
    "        filtered_files = list(file for file in filtered_files if file.startswith(prefix))\n",
    "    if ext:\n",
    "        filtered_files = list(file for file in filtered_files if file.endswith(ext))\n",
    "    if abspath:\n",
    "        filtered_files= list(os.path.join(path_to_dir, file)  for file in filtered_files)\n",
    "\n",
    "    filtered_files.sort()\n",
    "    return filtered_files\n",
    "\n",
    "\n",
    "nc_files = file_filter(result_dir, ext='nc')\n",
    "obs_files = file_filter(result_dir, ext='bz2', prefix='forecast')\n",
    "particle_info_files = file_filter(result_dir, ext='bz2', prefix='particle_info')\n",
    "print(\"number of nc_files:            \", len(nc_files))\n",
    "print(\"number of obs_files:           \", len(obs_files))\n",
    "print(\"number of particle_info_files: \", len(particle_info_files))\n",
    "\n",
    "if False:\n",
    "    print(len(nc_files), nc_files)\n",
    "    print()\n",
    "    print(len(obs_files), obs_files)\n",
    "    print()\n",
    "    print(len(particle_info_files), particle_info_files)\n",
    "    \n",
    "# Truth:\n",
    "true_nc = truth_folder + \"/double_jet_case_truth.nc\"\n",
    "true_obs_file = truth_folder + \"/drifter_observations.pickle\"\n",
    "    \n",
    "ensemble_size = len(nc_files)\n",
    "num_drifters=64\n",
    "\n",
    "\n",
    "#drifterSet = [ 4,  9, 14, 29, 33, 39, 44, 50, 56, 54]\n",
    "#drifterSet = [ 4,  9, 14, 26, 31, 37, 50, 62, 54]\n",
    "drifterSet = [ 2,  7, 12, 24, 29, 35, 41, 48, 53, 60]\n",
    "\n",
    "if result_dir.find(\"april\") > -1:\n",
    "    drifterSet = [4, 12, 20, 28, 36, 44, 52, 60]\n",
    "elif result_dir.find(\"may_buoy\") > -1:\n",
    "    drifterSet = [ 4,  9, 14, 29, 33, 39, 44, 50, 56, 54]\n",
    "\n",
    "unobservedDrifterSet = [ 4,  9, 14, 26, 31, 37, 50, 62, 54]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read netCDF files\n",
    "reload(SimReader)\n",
    "\n",
    "truth_reader = SimReader.SimNetCDFReader(true_nc)\n",
    "sim_readers = [None]*ensemble_size\n",
    "for particle_id in range(ensemble_size):\n",
    "    sim_readers[particle_id] = SimReader.SimNetCDFReader(nc_files[particle_id])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(im, interpolation=\"None\", title=None, figsize=(4,4), interior=False):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    if interior:\n",
    "        im = plt.imshow(im[2:-2,2:-2], interpolation=interpolation, origin='lower')\n",
    "    else:\n",
    "        im = plt.imshow(im, interpolation=interpolation, origin='lower')\n",
    "    \n",
    "    plt.colorbar()\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "        \n",
    "def imshow3(eta, hu, hv, interpolation=\"None\", title=None, figsize=(12.5,3.4), # (12.5, 3.4)\n",
    "            color_bar_from_zero=False, save_filename=None, constant_range=False):\n",
    "    \n",
    "    fig, axs = plt.subplots(1,3, figsize=figsize)\n",
    "    \n",
    "    #fig = plt.figure(figsize=figsize)\n",
    "\n",
    "    #gs = fig.add_gridspec(1,10)#, sharey=True)\n",
    "    #axs = [None, None, None]\n",
    "    #axs[0] = fig.add_subplot(gs[0, 1:4])\n",
    "    #axs[1] = fig.add_subplot(gs[0, 4:7])\n",
    "    #axs[2] = fig.add_subplot(gs[0, 7:10])\n",
    "    \n",
    "    eta_max = np.max(np.abs(eta))\n",
    "    huv_max = max(np.max(np.abs(hu)), np.max(np.abs(hv)))\n",
    "    \n",
    "    if constant_range:\n",
    "        eta_max = 3.5\n",
    "        huv_max = 625\n",
    "    \n",
    "    eta_cmap = 'BrBG'\n",
    "    huv_cmap = 'RdBu'\n",
    "    \n",
    "    eta_min = -eta_max\n",
    "    huv_min = -huv_max\n",
    "    if color_bar_from_zero:\n",
    "        eta_min, huv_min = 0, 0\n",
    "        if constant_range:\n",
    "            eta_max = 0.12\n",
    "            huv_max = 50\n",
    "        \n",
    "        eta_cmap = 'BuGn'\n",
    "        huv_cmap = 'Blues'\n",
    "        \n",
    "    nx = truth_reader.get('nx')\n",
    "    ny = truth_reader.get('ny')\n",
    "    dx = truth_reader.get('dx')\n",
    "    dy = truth_reader.get('dy')\n",
    "    extent=np.array([0, nx*dx, 0, ny*dy]) / 1000\n",
    "    \n",
    "    \n",
    "    fontsize = 18\n",
    "    def addColorbar(ax, im, title):\n",
    "        ax_divider = make_axes_locatable(ax)\n",
    "        ax_cb = ax_divider.append_axes(\"top\", size=\"10%\", pad=\"5%\")\n",
    "        cbar = colorbar(im, cax=ax_cb, orientation=\"horizontal\")\n",
    "        ax_cb.xaxis.set_ticks_position(\"top\")\n",
    "        ax_cb.set_title(title, fontsize=fontsize)\n",
    "    \n",
    "    eta_im = axs[0].imshow(eta, interpolation=interpolation, origin='lower', \n",
    "                           vmin=eta_min, vmax=eta_max, extent=extent, cmap=eta_cmap) #GnBu')\n",
    "    addColorbar(axs[0], eta_im, \"$\\eta$ [m]\")\n",
    "    \n",
    "    hu_im = axs[1].imshow(hu, interpolation=interpolation, origin='lower', \n",
    "                          vmin=huv_min, vmax=huv_max, extent=extent, cmap=huv_cmap)\n",
    "    addColorbar(axs[1], hu_im, \"$hu$ [m$^2$/s]\")\n",
    "    \n",
    "    \n",
    "    hv_im = axs[2].imshow(hv, interpolation=interpolation, origin='lower',\n",
    "                          vmin=huv_min, vmax=huv_max, extent=extent, cmap=huv_cmap)\n",
    "    addColorbar(axs[2], hv_im, \"$hv$ [m$^2$/s]\")\n",
    "    \n",
    "    axs[0].set_ylabel(main_title, labelpad=3, fontsize=fontsize)\n",
    "    \n",
    "    #for ax in axs:\n",
    "    #    ax.set_xlabel(\"$x$ [km]\")\n",
    "    #    ax.set_ylabel(\"$y$ [km]\")\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.suptitle(r\"\\textbf{\"+title+\"}\", y=1.1) #, fontsize=14)\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    if save_filename is not None:\n",
    "        fig.savefig(result_dir + \"/\" + save_filename + \".png\", bbox_inches='tight')\n",
    "        fig.savefig(result_dir + \"/\" + save_filename + \".pdf\", bbox_inches='tight')\n",
    "        \n",
    "        \n",
    "    \n",
    "def days_to_sec(days):\n",
    "    return days*24*60*60\n",
    "\n",
    "def sec_to_days(secs):\n",
    "    return secs/(24*60*60)\n",
    "\n",
    "def truth_time_step(t):\n",
    "    t = t - days_to_sec(3)\n",
    "    return int(t/(60*60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean and variance for different timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the timestamps for particle zero:\n",
    "example_sim_reader = sim_readers[0]\n",
    "times = example_sim_reader.getTimes()\n",
    "print(sec_to_days(times.data))\n",
    "print('Hopefully these values are only full days')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def plotStatisticalFields(t, truth_reader, sim_readers, save=True):\n",
    "\n",
    "    day_string = str(int(sec_to_days(t))).zfill(2)\n",
    "    print('plotting statistical features at day ' + day_string)\n",
    "    \n",
    "    \n",
    "    true_eta, true_hu, true_hv, t_tmp = truth_reader.getStateAtTime(t)\n",
    "    #imshow3(true_eta, true_hu, true_hv, title='True state after ' + str(sec_to_days(t)) + ' days')\n",
    "    \n",
    "    depth = truth_reader.getH()[0,0]\n",
    "    max_true_velocity = np.max(np.sqrt(true_hu*true_hu + true_hv*true_hv)/depth)\n",
    "    print('   max true velocity: ' + str(max_true_velocity))\n",
    "    \n",
    "    mean_eta, mean_hu, mean_hv = np.zeros_like(true_eta), np.zeros_like(true_hu), np.zeros_like(true_hv)\n",
    "    var_eta, var_hu, var_hv = np.zeros_like(true_eta), np.zeros_like(true_hu), np.zeros_like(true_hv)\n",
    "    #rmse_eta, rmse_hu, rmse_hv = np.zeros_like(true_eta), np.zeros_like(true_hu), np.zeros_like(true_hv)\n",
    "    actual_ensemble_size = 0\n",
    "    for particle in sim_readers:\n",
    "        try:\n",
    "            eta, hu, hv, t_tmp = particle.getStateAtTime(t)\n",
    "            if np.any(np.isnan(eta)):\n",
    "                print(\"Found nan for particle \" + str(actual_ensemble_size))\n",
    "                raise RuntimeError()\n",
    "            mean_eta += eta\n",
    "            mean_hu += hu\n",
    "            mean_hv += hv\n",
    "            #var_eta += eta*eta\n",
    "            #var_hu += hu*hu\n",
    "            #var_hv += hv*hv\n",
    "            actual_ensemble_size += 1\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "            # Ignore not found RuntimeError\n",
    "    mean_eta /= actual_ensemble_size\n",
    "    mean_hu /= actual_ensemble_size\n",
    "    mean_hv /= actual_ensemble_size\n",
    "    \n",
    "    #var_eta = var_eta/actual_ensemble_size - mean_eta*mean_eta\n",
    "    #var_hu  = var_hu/actual_ensemble_size -mean_hu*mean_hu\n",
    "    #var_hv  = var_hv/actual_ensemble_size -mean_hv*mean_hv\n",
    "    \n",
    "    title = main_title + ': Ensemble mean after ' + str(sec_to_days(t)) + ' days'\n",
    "    imshow3(mean_eta, mean_hu, mean_hv, title=title,\n",
    "            save_filename='ensemble_mean_day_' + day_string, constant_range=True)\n",
    "    \n",
    "    if True:\n",
    "        actual_ensemble_size = 0\n",
    "        for particle in sim_readers:\n",
    "            try:\n",
    "                eta, hu, hv, t_tmp = particle.getStateAtTime(t)\n",
    "                if np.any(np.isnan(eta)):\n",
    "                    print(\"Found nan for particle \" + str(actual_ensemble_size))\n",
    "                    raise RuntimeError()\n",
    "                var_eta += (mean_eta - eta)**2\n",
    "                var_hu += (mean_hu - hu)**2\n",
    "                var_hv += (mean_hv - hv)**2\n",
    "                actual_ensemble_size += 1\n",
    "            except RuntimeError:\n",
    "                pass\n",
    "                # Ignore not found RuntimeError\n",
    "\n",
    "        var_eta = np.sqrt(var_eta)/(actual_ensemble_size - 1)\n",
    "        var_hu  = np.sqrt(var_hu)/(actual_ensemble_size - 1)\n",
    "        var_hv  = np.sqrt(var_hv)/(actual_ensemble_size - 1)\n",
    "        \n",
    "        title = main_title + ': Variance after ' + str(sec_to_days(t)) + ' days'\n",
    "        \n",
    "        imshow3(var_eta, var_hu, var_hv, \n",
    "                title=title, color_bar_from_zero=True, constant_range=True,\n",
    "                save_filename='ensemble_var_day_' + day_string)\n",
    "\n",
    "\n",
    "true_eta, true_hu, true_hv, t_tmp = truth_reader.getStateAtTime(days_to_sec(10))\n",
    "imshow3(true_eta, true_hu, true_hv, title='10 day true state', constant_range=True,\n",
    "        save_filename='true_state_day_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " \n",
    "#for t in times:\n",
    "#    plotStatisticalFields(t, truth_reader, sim_readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "true_eta, true_hu, true_hv, t_tmp = truth_reader.getStateAtTime(days_to_sec(10))\n",
    "imshow3(true_eta, true_hu, true_hv, title='10 day true state', constant_range=True,\n",
    "        save_filename='true_state_day_10')\n",
    "plotStatisticalFields(days_to_sec(10), truth_reader, sim_readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eta, hu, hv, t_tmp = sim_readers[0].getStateAtTime(days_to_sec(3.25))\n",
    "#imshow3(eta, hu, hv, title='State after 3.25 days particle 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance under drifters\n",
    "\n",
    "We use the following definition of the root mean square error (RMSE):\n",
    "$$ RMSE = \\sqrt{(H(\\bar{\\psi}) - y)^2}$$\n",
    "\n",
    "And standard deviation:\n",
    "$$ \\sigma = \\sqrt{\\frac{1}{N_e-1} \\sum_{i=0}^{N_e} (\\psi_i - \\bar{\\psi})^2}$$\n",
    "\n",
    "\n",
    "The RMSE is therefore only accessible for observed parameters, and at observation times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles = len(nc_files)\n",
    "num_days = 3\n",
    "\n",
    "particle_infos = [None]*num_particles\n",
    "\n",
    "\n",
    "skipVariancePlots = True\n",
    "\n",
    "i = 0\n",
    "for particle in range(num_particles):\n",
    "    filenames = file_filter(result_dir, ext='bz2', \n",
    "                            prefix='particle_info_' + str(particle).zfill(4))\n",
    "    infos = [None]*num_days\n",
    "    for day in range(num_days):\n",
    "        \n",
    "        if not skipVariancePlots or i == 0:\n",
    "            infos[day] = ParticleInfo.ParticleInfo()\n",
    "            infos[day].read_pickle(filenames[day])\n",
    "        if particle == 0:\n",
    "            print(filenames[day])\n",
    "    particle_infos[particle] = infos\n",
    "    print(\".\"+str(i)+\".\", end='')\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "#print(particle_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "info_example = particle_infos[0][0]\n",
    "print(info_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = file_filter(result_dir, ext='bz2', \n",
    "                            prefix='particle_info_' + str(0).zfill(4))\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "print(\".........\")\n",
    "filenames.sort()\n",
    "for filename in filenames:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read truth observation file:\n",
    "observation_type = dautils.ObservationType.UnderlyingFlow\n",
    "\n",
    "if info_example.get_num_drifters() > 64:\n",
    "    observation_type = dautils.ObservationType.StaticBuoys\n",
    "    \n",
    "equilibrium_depth = truth_reader.getH()[0,0]\n",
    "nx = truth_reader.get('nx')\n",
    "ny = truth_reader.get('ny')\n",
    "domain_size_x = nx*truth_reader.get('dx')\n",
    "domain_size_y = ny*truth_reader.get('dy')\n",
    "\n",
    "\n",
    "\n",
    "true_observations = Observation.Observation(observation_type=observation_type,\n",
    "                                            domain_size_x=domain_size_x,\n",
    "                                            domain_size_y=domain_size_y,\n",
    "                                            nx=nx, ny=ny)\n",
    "true_observations.read_pickle(true_obs_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_obs_file)\n",
    "info_example.get_num_drifters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_per_day = [None]*num_days\n",
    "\n",
    "#for day in range(num_days):\n",
    "\n",
    "sample_times = info_example.get_sample_times()\n",
    "\n",
    "drifter_id = 4\n",
    "\n",
    "stddev_eta_first_day = np.zeros((num_drifters,len(sample_times)))\n",
    "stddev_hu_first_day = np.zeros((num_drifters,len(sample_times)))\n",
    "stddev_hv_first_day = np.zeros((num_drifters,len(sample_times)))\n",
    "\n",
    "mean_eta_first_day = np.zeros((num_drifters,len(sample_times)))\n",
    "mean_hu_first_day = np.zeros((num_drifters,len(sample_times)))\n",
    "mean_hv_first_day = np.zeros((num_drifters,len(sample_times)))\n",
    "\n",
    "rmse_hu_first_day = np.zeros((num_drifters,len(sample_times)//5))\n",
    "rmse_hv_first_day = np.zeros((num_drifters,len(sample_times)//5))\n",
    "\n",
    "# How many days to skip\n",
    "#skip_days = 2\n",
    "skip_days = 0\n",
    "\n",
    "\n",
    "for particle_id in range(num_particles):\n",
    "    \n",
    "    if skipVariancePlots:\n",
    "        if particle_id == 0:\n",
    "            print('skipping the creation of variance plots')\n",
    "        break\n",
    "    \n",
    "    sample_file = 'particle_info_' + str(particle_id).zfill(4) + \"_\" + str(skip_days).zfill(2) + \".bz2\"\n",
    "    sample_path = os.path.join(result_dir, sample_file)\n",
    "    #\"particle_info_0000_06.bz2\"\n",
    "    \n",
    "    try:\n",
    "\n",
    "        #info = ParticleInfo.ParticleInfo()\n",
    "        #info.read_pickle(sample_path)\n",
    "        info = particle_infos[particle_id][skip_days]\n",
    "        rmse_id = -1\n",
    "\n",
    "        for t_id in range(len(sample_times)):\n",
    "\n",
    "            time = sample_times[t_id] + days_to_sec(skip_days)\n",
    "\n",
    "            state_samples = info.get_state_samples(time)\n",
    "            #print('state_samples.shape: ', state_samples.shape)\n",
    "            \n",
    "            state_observation = None\n",
    "            if (particle_id == num_particles - 1) and (time % 300 == 0):\n",
    "                state_observation = true_observations.get_observation(time, equilibrium_depth)\n",
    "                #print('state_observation.shape: ', state_observation.shape)\n",
    "                #print(state_observation[60,:])\n",
    "                #soudeihfgi\n",
    "                rmse_id += 1\n",
    "            \n",
    "\n",
    "            #state_samples = particle_infos[particle_id][0].get_state_samples(sample_times[t_id])\n",
    "\n",
    "            for drifter_id in range(num_drifters):\n",
    "                mean_eta_first_day[drifter_id, t_id] += state_samples[drifter_id, 0]/num_particles\n",
    "                mean_hu_first_day[drifter_id, t_id] += state_samples[drifter_id, 1]/num_particles\n",
    "                mean_hv_first_day[drifter_id, t_id] += state_samples[drifter_id, 2]/num_particles\n",
    "\n",
    "                #if state_observation is not None:\n",
    "                #    rmse_hu_first_day[drifter_id, rmse_id] += (state_samples[drifter_id, 1] - state_observation[drifter_id, 2])**2\n",
    "                #    rmse_hv_first_day[drifter_id, rmse_id] += (state_samples[drifter_id, 2] - state_observation[drifter_id, 3])**2\n",
    "                    \n",
    "                #variance_eta_first_day[drifter_id, t_id] += state_samples[drifter_id, 0]**2\n",
    "                #variance_hu_first_day[drifter_id, t_id] += state_samples[drifter_id, 1]**2\n",
    "                #variance_hv_first_day[drifter_id, t_id] += state_samples[drifter_id, 2]**2\n",
    "                \n",
    "                if state_observation is not None:\n",
    "                    rmse_hu_first_day[drifter_id, rmse_id] = np.sqrt((mean_hu_first_day[drifter_id, t_id] - \n",
    "                                                                      state_observation[drifter_id, 2])**2)\n",
    "                    rmse_hv_first_day[drifter_id, rmse_id] = np.sqrt((mean_hv_first_day[drifter_id, t_id] - \n",
    "                                                                      state_observation[drifter_id, 3])**2)\n",
    "                \n",
    "        \n",
    "        print(\".\"+str(particle_id)+\".\", end='')\n",
    "        \n",
    "        \n",
    "    \n",
    "    except AssertionError as ae:\n",
    "        print('\\nParticle ' + str(particle_id) + ' failed')\n",
    "        print(ae)\n",
    "        \n",
    "print('')\n",
    "print('Std.dev.:')\n",
    "for particle_id in range(num_particles):\n",
    "    \n",
    "    if skipVariancePlots:\n",
    "        if particle_id == 0:\n",
    "            print('skipping the creation of variance plots')\n",
    "        break\n",
    "    try:\n",
    "\n",
    "        info = particle_infos[particle_id][skip_days]\n",
    "\n",
    "        for t_id in range(len(sample_times)):\n",
    "\n",
    "            time = sample_times[t_id] + days_to_sec(skip_days)\n",
    "\n",
    "            state_samples = info.get_state_samples(time)\n",
    "\n",
    "            for drifter_id in range(num_drifters):\n",
    "                stddev_eta_first_day[drifter_id, t_id] += (state_samples[drifter_id, 0] -\n",
    "                                                           mean_eta_first_day[drifter_id, t_id])**2\n",
    "                stddev_hu_first_day[drifter_id, t_id] += (state_samples[drifter_id, 1] -\n",
    "                                                          mean_hu_first_day[drifter_id, t_id])**2\n",
    "                stddev_hv_first_day[drifter_id, t_id] += (state_samples[drifter_id, 2] - \n",
    "                                                          mean_hv_first_day[drifter_id, t_id])**2\n",
    "   \n",
    "        print(\".\"+str(particle_id)+\".\", end='')\n",
    "        \n",
    "        \n",
    "    except AssertionError as ae:\n",
    "        print('\\nParticle ' + str(particle_id) + ' failed')\n",
    "        print(ae)\n",
    "\n",
    "if not skipVariancePlots:\n",
    "    stddev_eta_first_day[drifter_id, t_id] = np.sqrt(stddev_eta_first_day/(num_particles-1))\n",
    "    stddev_hu_first_day[drifter_id, t_id] = np.sqrt(stddev_hu_first_day/(num_particles-1))\n",
    "    stddev_hv_first_day[drifter_id, t_id] = np.sqrt(stddev_hv_first_day/(num_particles-1))\n",
    "\n",
    "    #mean_eta_first_day /= num_particles\n",
    "    #mean_hu_first_day /= num_particles\n",
    "    #mean_hv_first_day /= num_particles        \n",
    "\n",
    "    #variance_eta_first_day = variance_eta_first_day/num_particles - mean_eta_first_day**2\n",
    "    #variance_hu_first_day = variance_hu_first_day/num_particles - mean_hu_first_day**2\n",
    "    #variance_hv_first_day = variance_hv_first_day/num_particles - mean_hv_first_day**2\n",
    "\n",
    "    #rmse_hu_first_day = np.sqrt((1/num_particles)*rmse_hu_first_day)\n",
    "    #rmse_hv_first_day = np.sqrt((1/num_particles)*rmse_hv_first_day)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stddev_eta_first_day = np.sqrt(stddev_eta_first_day/(num_particles-1))\n",
    "stddev_hu_first_day = np.sqrt(stddev_hu_first_day/(num_particles-1))\n",
    "stddev_hv_first_day = np.sqrt(stddev_hv_first_day/(num_particles-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skipVariancePlots:\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    for drifter_id in range(0, 64, 4):\n",
    "        plt.plot(sec_to_days(sample_times[4::5]), rmse_hu_first_day[drifter_id,:])\n",
    "    plt.xlabel('time (days)')\n",
    "    plt.ylabel('RMSE hu')\n",
    "    plt.grid()\n",
    "    plt.ylim([-1, 35])\n",
    "    plt.plot(sec_to_days(sample_times[4::5]), np.ones_like(sec_to_days(sample_times[4::5])), ':k')\n",
    "    #plt.plot(sample_times, variance_hv_first_day[4,:])\n",
    "    #plt.plot(sample_times, variance_eta_first_day[4,:])\n",
    "    if not skipVariancePlots:\n",
    "        if true_observations.observation_type == dautils.ObservationType.StaticBuoys:\n",
    "            fig.savefig(result_dir + \"/\" + \"rmse_buoys_day_3_hu.png\")\n",
    "            fig.savefig(result_dir + \"/\" + \"rmse_buoys_day_3_hu.pdf\")\n",
    "        else:\n",
    "            fig.savefig(result_dir + \"/\" + \"rmse_drifters_day_3_hu.png\")\n",
    "            fig.savefig(result_dir + \"/\" + \"rmse_drifters_day_3_hu.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skipVariancePlots:\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    for drifter_id in range(0, 64, 4):\n",
    "        plt.plot(sec_to_days(sample_times[4::5]), rmse_hv_first_day[drifter_id,:])\n",
    "    plt.xlabel('time (days)')\n",
    "    plt.ylabel('RMSE hv')\n",
    "    plt.grid()\n",
    "    plt.ylim([-1, 35])\n",
    "    plt.plot(sec_to_days(sample_times[4::5]), np.ones_like(sec_to_days(sample_times[4::5])), ':k')\n",
    "    #plt.plot(sample_times, variance_hv_first_day[4,:])\n",
    "    #plt.plot(sample_times, variance_eta_first_day[4,:])\n",
    "    if not skipVariancePlots:\n",
    "        if true_observations.observation_type == dautils.ObservationType.StaticBuoys:\n",
    "            fig.savefig(result_dir + \"/\" + \"rmse_buoys_day_3_hv.png\")\n",
    "            fig.savefig(result_dir + \"/\" + \"rmse_buoys_day_3_hv.pdf\")\n",
    "        else:\n",
    "            fig.savefig(result_dir + \"/\" + \"rmse_drifters_day_3_hv.png\")\n",
    "            fig.savefig(result_dir + \"/\" + \"rmse_drifters_day_3_hv.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skipVariancePlots:\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    for drifter_id in range(0, 64, 4):\n",
    "        plt.plot(sec_to_days(sample_times), stddev_hu_first_day[drifter_id,:])\n",
    "    plt.xlabel('time (days)')\n",
    "    plt.ylabel('stddev hu')\n",
    "    plt.grid()\n",
    "    #plt.plot(sample_times, variance_hv_first_day[4,:])\n",
    "    #plt.plot(sample_times, variance_eta_first_day[4,:])\n",
    "    if not skipVariancePlots:\n",
    "        if true_observations.observation_type == dautils.ObservationType.StaticBuoys:\n",
    "            fig.savefig(result_dir + \"/\" + \"stddev_buoys_day_3_hu.png\")\n",
    "            fig.savefig(result_dir + \"/\" + \"stddev_buoys_day_3_hu.pdf\")\n",
    "        else:\n",
    "            fig.savefig(result_dir + \"/\" + \"stddev_drifters_day_3_hu.png\")\n",
    "            fig.savefig(result_dir + \"/\" + \"stddev_drifters_day_3_hu.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skipVariancePlots:\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    for drifter_id in range(0, 64, 4):\n",
    "        plt.plot(sec_to_days(sample_times), stddev_hv_first_day[drifter_id,:])\n",
    "    plt.xlabel('time (days)')\n",
    "    plt.ylabel('stddev hv')\n",
    "    plt.ylim([-1, 35])\n",
    "    plt.grid()\n",
    "\n",
    "    #plt.plot(sample_times, variance_hv_first_day[4,:])\n",
    "    #plt.plot(sample_times, variance_eta_first_day[4,:])\n",
    "    if not skipVariancePlots:\n",
    "        if true_observations.observation_type == dautils.ObservationType.StaticBuoys:\n",
    "            fig.savefig(result_dir + \"/\" + \"stddev_buoys_day_3_hv.png\")\n",
    "            fig.savefig(result_dir + \"/\" + \"stddev_buoys_day_3_hv.pdf\")\n",
    "        else:\n",
    "            fig.savefig(result_dir + \"/\" + \"stddev_drifters_day_3_hv.png\")\n",
    "            fig.savefig(result_dir + \"/\" + \"stddev_drifters_day_3_hv.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skipVariancePlots:\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    for drifter_id in range(0, 64, 4):\n",
    "        plt.plot(sec_to_days(sample_times), variance_eta_first_day[drifter_id,:])\n",
    "        #plt.plot(sample_times, variance_hv_first_day[4,:])\n",
    "\n",
    "    plt.xlabel('time (days)')\n",
    "    plt.ylabel('stddev eta')\n",
    "    #plt.plot(sample_times, variance_hv_first_day[4,:])\n",
    "    #plt.plot(sample_times, variance_eta_first_day[4,:])\n",
    "    if not skipVariancePlots:\n",
    "        if true_observations.observation_type == dautils.ObservationType.StaticBuoys:\n",
    "            fig.savefig(result_dir + \"/\" + \"stddev_buoys_day_3_eta.png\")\n",
    "            fig.savefig(result_dir + \"/\" + \"stddev_buoys_day_3_eta.pdf\")\n",
    "        else:\n",
    "            fig.savefig(result_dir + \"/\" + \"stddev_drifters_day_3_eta.png\")\n",
    "            fig.savefig(result_dir + \"/\" + \"stddev_drifters_day_3_eta.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#particle_infos[0][5].state_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function for creating forecast plot\n",
    "\n",
    "fontsize = 18\n",
    "\n",
    "\n",
    "def createForecastCanvas(true_sim_reader, num_canvases=1):\n",
    "    \"\"\"\n",
    "    true_sim_reader: The SimReader object containing nx, ny, etc\n",
    "    \"\"\"   \n",
    "    \n",
    "    nx = true_sim_reader.get('nx')\n",
    "    ny = true_sim_reader.get('ny')\n",
    "    dx = true_sim_reader.get('dx')\n",
    "    dy = true_sim_reader.get('dy')\n",
    "    extent=np.array([0, nx*dx, 0, ny*dy])/1000\n",
    "    \n",
    "    emptyData =np.ma.masked_where(np.zeros((ny, nx)) > 1, \n",
    "                                      np.zeros((ny, nx)))\n",
    "    \n",
    "    if num_canvases == 1:\n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "        ax = plt.subplot(111)\n",
    "        \n",
    "        ax.imshow(emptyData, origin=\"lower\", \n",
    "                  extent=extent, cmap='binary')\n",
    "\n",
    "        return ax\n",
    "    \n",
    "    elif num_canvases < 4:\n",
    "        fig, axs = plt.subplots(1,num_canvases, figsize=(12.5,3.4)) # Used in the mean figure: figsize=(12.5,3.4)\n",
    "    \n",
    "        for ax in axs:\n",
    "            ax.imshow(emptyData, origin=\"lower\", \n",
    "                      extent=extent, cmap='binary')\n",
    "            ax.set_ylim([0, extent[3]])\n",
    "            #ax.set_ylabel(\"$y$ [km]\")\n",
    "            ax.set_xlim([0, extent[1]])\n",
    "            #ax.set_xlabel(\"$x$ [km]\")\n",
    "            \n",
    "        axs[0].set_ylabel(main_title, labelpad=5, fontsize=fontsize)\n",
    "\n",
    "        return axs\n",
    "    assert (num_canvases < 4), 'Function not implemented for more than 3 canvases'\n",
    "\n",
    "def forecastPlot(ax, true_paths, ensemble_paths, color_id=0, \n",
    "                 forecast_point_size=2, truth_point_size=6):\n",
    "    \"\"\"\n",
    "    ax: Axis object to draw trajectories in\n",
    "    true_path: A single list of paths that represents the truth\n",
    "    ensemble_paths: Multiple lists of paths that represents the forecast\n",
    "    color_id: integer representing a pre-defined color combination.\n",
    "    \"\"\"\n",
    "\n",
    "    color_combinations = [\n",
    "        # [true color, forecast color]\n",
    "        ['xkcd:dark grey blue', 'xkcd:light blue grey'],\n",
    "        ['xkcd:viridian', 'xkcd:foam green']\n",
    "    ]\n",
    "    \n",
    "    assert(color_id < len(color_combinations)), 'Invalid color_id'\n",
    "    \n",
    "    true_color = color_combinations[color_id][0]\n",
    "    forecast_color = color_combinations[color_id][1]\n",
    "\n",
    "    # Plot forecast paths \n",
    "    for paths in ensemble_paths:\n",
    "        for path in paths:\n",
    "            ax.plot(path[:,0], path[:,1], color=forecast_color, alpha=0.3)\n",
    "        \n",
    "        # Mark end position of forecast\n",
    "        end_position   = paths[-1][-1,:]\n",
    "        circ_end_forecast = matplotlib.patches.Circle((end_position[0], end_position[1]), \n",
    "                                                      forecast_point_size, \n",
    "                                                      fill=False, zorder=10)\n",
    "        ax.add_patch(circ_end_forecast)\n",
    "\n",
    "    \n",
    "    # Plot true path\n",
    "    for path in true_paths:\n",
    "        ax.plot(path[:,0], path[:,1], color=true_color, zorder=5)\n",
    "\n",
    "    # Mark start and end of true path\n",
    "    start_pos = true_paths[0][0,:]\n",
    "    end_pos   = true_paths[-1][-1,:]\n",
    "    circ_start = matplotlib.patches.Circle((start_pos[0], start_pos[1]), \n",
    "                                           truth_point_size,\n",
    "                                           fill=False, zorder=10)\n",
    "    ax.add_patch(circ_start)\n",
    "    circ_end = matplotlib.patches.Circle((end_pos[0], end_pos[1]), \n",
    "                                         truth_point_size,\n",
    "                                         fill=False, zorder=10)\n",
    "    ax.add_patch(circ_end)\n",
    "\n",
    "    \n",
    "def plotThreeDayForecast(true_observations, ensemble_observations, drifter_id, drifterSet):\n",
    "    \n",
    "    start_time_forecast = days_to_sec(10)\n",
    "    try:\n",
    "        start_time_forecast = ensemble_observations[0].get_observation_times()[0]\n",
    "    except e:\n",
    "        pass\n",
    "    \n",
    "    true_drifter_id = drifterSet[drifter_id]\n",
    "    \n",
    "    print('true_observations.get_num_drifters(applyDrifterSet=False, ignoreBuoys=True)', \n",
    "           true_observations.get_num_drifters(applyDrifterSet=False, ignoreBuoys=True))\n",
    "    print('ensemble_observations[0].get_num_drifters(applyDrifterSet=False, ignoreBuoys=True)', \n",
    "           ensemble_observations[0].get_num_drifters(applyDrifterSet=False, ignoreBuoys=True))\n",
    "    \n",
    "    if true_observations.get_num_drifters(applyDrifterSet=False, ignoreBuoys=True) == \\\n",
    "       ensemble_observations[0].get_num_drifters(applyDrifterSet=False, ignoreBuoys=True):\n",
    "        print('using the same drifter id')\n",
    "        drifter_id = true_drifter_id\n",
    "    \n",
    "    axs = createForecastCanvas(truth_reader, 3)\n",
    "    \n",
    "    for forecast_days in range(1,4):\n",
    "        title = str(forecast_days) + ' days forecast' # for drifter ' + str(true_drifter_id)\n",
    "        if forecast_days == 1:\n",
    "            title = str(forecast_days) + ' day forecast'\n",
    "        #title = title + \" (\" + main_title + \")\" \n",
    "        print('generating ' + title)\n",
    "        end_time_forecast = start_time_forecast + days_to_sec(forecast_days)\n",
    "        \n",
    "        true_paths = true_observations.get_drifter_path(true_drifter_id, \n",
    "                                                        start_time_forecast,\n",
    "                                                        end_time_forecast)\n",
    "\n",
    "        forecast_paths = [None]*len(ensemble_observations)\n",
    "        for i in range(len(forecast_paths)):\n",
    "            forecast_paths[i] = ensemble_observations[i].get_drifter_path(drifter_id,  \n",
    "                                                                          start_time_forecast,\n",
    "                                                                          end_time_forecast)\n",
    "        \n",
    "        ax_id = forecast_days-1\n",
    "        forecastPlot(axs[ax_id], true_paths, forecast_paths)\n",
    "        #axs[ax_id].set_title(title)\n",
    "        axs[ax_id].set_title(title, fontsize=fontsize)\n",
    "    \n",
    "    suptitle = 'Forecast drifter ' + str(true_drifter_id) + ' using ' + main_title\n",
    "    plt.suptitle(suptitle, y=1.1)\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    forecast_filename = \"trajectory_forecast_drifter_\" + str(true_drifter_id).zfill(2)\n",
    "    \n",
    "    plt.savefig(result_dir + \"/\" + forecast_filename + \".png\", bbox_inches='tight')\n",
    "    plt.savefig(result_dir + \"/\" + forecast_filename + \".pdf\", bbox_inches='tight')\n",
    "\n",
    "def plotShortRangeForecast(true_observations, ensemble_observations, drifter_id, drifterSet):\n",
    "    \n",
    "    start_time_forecast = days_to_sec(10)\n",
    "    try:\n",
    "        start_time_forecast = ensemble_observations[0].get_observation_times()[0]\n",
    "    except e:\n",
    "        pass\n",
    "    \n",
    "    true_drifter_id = drifterSet[drifter_id]\n",
    "    \n",
    "    if true_observations.get_num_drifters(applyDrifterSet=False, ignoreBuoys=True) == \\\n",
    "       ensemble_observations[0].get_num_drifters(applyDrifterSet=False, ignoreBuoys=True):\n",
    "        drifter_id = true_drifter_id\n",
    "    \n",
    "    keepDomainSize = False\n",
    "    axs = None\n",
    "    if keepDomainSize:\n",
    "        axs = createForecastCanvas(truth_reader, 3)\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12.5,3.4))\n",
    "    \n",
    "    forecast_days_array = [0.25, 0.5, 1]\n",
    "    \n",
    "    #min_x = true_observations.\n",
    "    for ax_id in range(3):\n",
    "        \n",
    "        forecast_days = forecast_days_array[ax_id]\n",
    "        hours = int(24*forecast_days)\n",
    "        \n",
    "        title=  str(hours) + ' hour forecast' # for drifter ' + str(true_drifter_id)\n",
    "        #title = title + \" (\" + main_title + \")\" \n",
    "        print('generating ' + title)\n",
    "\n",
    "        end_time_forecast = start_time_forecast + days_to_sec(forecast_days)\n",
    "        \n",
    "        true_paths = true_observations.get_drifter_path(true_drifter_id, \n",
    "                                                        start_time_forecast,\n",
    "                                                        end_time_forecast,\n",
    "                                                        keepDomainSize=keepDomainSize)\n",
    "\n",
    "        forecast_paths = [None]*len(ensemble_observations)\n",
    "        for i in range(len(forecast_paths)):\n",
    "            forecast_paths[i] = ensemble_observations[i].get_drifter_path(drifter_id,  \n",
    "                                                                          start_time_forecast,\n",
    "                                                                          end_time_forecast,\n",
    "                                                                          keepDomainSize=keepDomainSize)\n",
    "        \n",
    "        forecastPlot(axs[ax_id], true_paths, forecast_paths,\n",
    "                     truth_point_size=3, forecast_point_size=1)\n",
    "        #axs[ax_id].set_title(title)\n",
    "        axs[ax_id].set_title(title, fontsize=fontsize)\n",
    "        #axs[ax_id].set_ylabel(\"$y$ [km]\")\n",
    "        #axs[ax_id].set_xlabel(\"$x$ [km]\")\n",
    "    \n",
    "    if true_drifter_id == 24:\n",
    "        axs[2].set_xlim([340, 660])\n",
    "        axs[2].set_ylim([95, 370])\n",
    "    print(axs[2].get_ylim())\n",
    "    for ax in axs[:2]:\n",
    "        ax.set_ylim(axs[2].get_ylim())\n",
    "        ax.set_xlim(axs[2].get_xlim())\n",
    "    axs[0].set_ylabel(main_title, labelpad=5, fontsize=fontsize)\n",
    "\n",
    "    suptitle = 'Forecast drifter ' + str(true_drifter_id) + ' using ' + main_title\n",
    "    plt.suptitle(suptitle, y=1.1)\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    forecast_filename = \"trajectory_forecast_drifter_\" + str(true_drifter_id).zfill(2) + \"_short_range\"\n",
    "    if not keepDomainSize:\n",
    "        forecast_filename = \"local_\" + forecast_filename\n",
    "    \n",
    "    plt.savefig(result_dir + \"/\" + forecast_filename + \".png\", bbox_inches='tight')\n",
    "    #plt.savefig(result_dir + \"/\" + forecast_filename + \"_dpi600.png\", dpi=600)\n",
    "    plt.savefig(result_dir + \"/\" + forecast_filename + \".pdf\", bbox_inches='tight')\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#plotShortRangeForecast(true_observations, ensemble_observations, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Observation)\n",
    "\n",
    "# Read truth observation file:\n",
    "true_observations = Observation.Observation(domain_size_x=domain_size_x, \n",
    "                                            domain_size_y=domain_size_y, \n",
    "                                            nx=nx, ny=ny)\n",
    "true_observations.read_pickle(true_obs_file)\n",
    "\n",
    "# Read observation files from the ensemble:\n",
    "\n",
    "ensemble_observations = [None]*len(obs_files)\n",
    "for i in range(len(obs_files)):\n",
    "    ensemble_observations[i] = Observation.Observation(domain_size_x=domain_size_x, \n",
    "                                                       domain_size_y=domain_size_y, \n",
    "                                                       nx=nx, ny=ny)\n",
    "    ensemble_observations[i].read_pickle(obs_files[i])\n",
    "    print(\".\"+str(i)+\".\", end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nc_files = file_filter(result_dir, ext='nc')\n",
    "#obs_files = file_filter(result_dir, ext='bz2', prefix='forecast')\n",
    "#particle_info_files = file_filter(result_dir, ext='bz2', prefix='particle_info')\n",
    "\n",
    "\n",
    "start_time_forecast = days_to_sec(10)\n",
    "end_time_forecast = days_to_sec(11)\n",
    "obs_times = true_observations.get_observation_times()\n",
    "\n",
    "drifter_id = 0\n",
    "true_drifter_id = drifterSet[drifter_id]\n",
    "\n",
    "print(\"Number of obs_times: \", len(obs_times))\n",
    "print(\"Obs interval (s) (assuming 10 days): \", (10*24*60*60)/len(obs_times))\n",
    "print(\"Day of first obs_time:  \", sec_to_days(obs_times[0]))\n",
    "print(\"Day of second obs_time: \", sec_to_days(obs_times[1]))\n",
    "print(\"Day of last obs_time:   \", sec_to_days(obs_times[-1]))\n",
    "\n",
    "print(\"Time diff first to second (in s):        \", obs_times[1]-obs_times[0])\n",
    "print(\"Time diff last to second to last (in s): \", obs_times[-1]-obs_times[-2])\n",
    "\n",
    "print(\"Number of relevant time steps (3 day forecast): \", 3*len(obs_times)/10)\n",
    "\n",
    "print('\\nReading true path')\n",
    "true_paths = true_observations.get_drifter_path(true_drifter_id, days_to_sec(10), end_time_forecast)\n",
    "print('True path obtained')\n",
    "\n",
    "\n",
    "print('\\nReading ' + str(len(ensemble_observations)) + ' ensemble paths')\n",
    "forecast_paths = [None]*len(ensemble_observations)\n",
    "for i in range(len(forecast_paths)):\n",
    "    forecast_paths[i] = ensemble_observations[i].get_drifter_path(drifter_id, days_to_sec(10), end_time_forecast)\n",
    "    print(\".\"+str(i)+\".\", end='')\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = createForecastCanvas(truth_reader, 3)\n",
    "forecastPlot(ax[0], true_paths, forecast_paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = createForecastCanvas(truth_reader)\n",
    "forecastPlot(ax, true_paths, forecast_paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4*24*60*60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for drifter in range(len(drifterSet)):\n",
    "    plotThreeDayForecast(true_observations, ensemble_observations, drifter, drifterSet)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for drifter in range(len(drifterSet)):\n",
    "    plotShortRangeForecast(true_observations, ensemble_observations, drifter, drifterSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for drifter in range(len(unobservedDrifterSet)):\n",
    "    plotThreeDayForecast(true_observations, ensemble_observations, drifter, unobservedDrifterSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for drifter in range(len(unobservedDrifterSet)):\n",
    "    plotShortRangeForecast(true_observations, ensemble_observations, drifter, unobservedDrifterSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_obs = ensemble_observations[0]\n",
    "sample_obs.get_num_drifters(), sample_obs.drifterSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:gpuocean] *",
   "language": "python",
   "name": "conda-env-gpuocean-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}